{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo \n",
    "import io \n",
    "import pandas as pd \n",
    "import pickle \n",
    "import datetime \n",
    "import time \n",
    "import gzip \n",
    "import lzma \n",
    "import pytz \n",
    "import pyarrow as pa \n",
    "import pyarrow.parquet as pq \n",
    "import numpy as np \n",
    "import re\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db', version=3): \n",
    "        self.db_name = db_name \n",
    "        self.uri = uri \n",
    "        self.client = pymongo.MongoClient(self.uri) \n",
    "        self.db = self.client[self.db_name] \n",
    "        self.chunk_size = 20000 \n",
    "        self.symbol_column = symbol_column \n",
    "        self.date_column = 'date' \n",
    "        self.version = version\n",
    "\n",
    "    def parse_uri(self, uri): \n",
    "        # mongodb://user:password@example.com \n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"date must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid date type: \" + str(type(x)))\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "        return query\n",
    "\n",
    "    def read_tick(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name] \n",
    "        query = self.build_query(start_date, end_date, symbol) \n",
    "        if not query: \n",
    "            print('cannot read the whole table') \n",
    "            return None  \n",
    "        segs = [] \n",
    "        for x in collection.find(query): \n",
    "            x['data'] = self.deser(x['data'], x['ver']) \n",
    "            segs.append(x) \n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start'])) \n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def read_daily(self, table_name, start_date=None, end_date=None, skey=None, index_id=None, interval=None, index_name=None, col=None, return_sdi=True): \n",
    "        collection = self.db[table_name]\n",
    "        # Build projection \n",
    "        prj = {'_id': 0} \n",
    "        if col is not None: \n",
    "            if return_sdi: \n",
    "                col = ['skey', 'date', 'index_id'] + col \n",
    "            for col_name in col: \n",
    "                prj[col_name] = 1 \n",
    "        # Build query \n",
    "        query = {} \n",
    "        if skey is not None: \n",
    "            query['skey'] = {'$in': skey} \n",
    "        if interval is not None: \n",
    "            query['interval'] = {'$in': interval} \n",
    "        if index_id is not None: \n",
    "            query['index_id'] = {'$in': index_id}    \n",
    "        if index_name is not None:\n",
    "            n = '' \n",
    "            for name in index_name: \n",
    "                try: \n",
    "                    name = re.compile('[\\u4e00-\\u9fff]+').findall(name)[0] \n",
    "                    if len(n) == 0: \n",
    "                        n = n = \"|\".join(name) \n",
    "                    else: \n",
    "                        n = n + '|' + \"|\".join(name) \n",
    "                except: \n",
    "                    if len(n) == 0: \n",
    "                        n = name \n",
    "                    else: \n",
    "                        n = n + '|' + name \n",
    "            query['index_name'] = {'$regex': n}\n",
    "        if start_date is not None: \n",
    "            if end_date is not None: \n",
    "                query['date'] = {'$gte': start_date, '$lte': end_date} \n",
    "            else: \n",
    "                query['date'] = {'$gte': start_date} \n",
    "        elif end_date is not None: \n",
    "            query['date'] = {'$lte': end_date} \n",
    "        # Load data \n",
    "        cur = collection.find(query, prj) \n",
    "        df = pd.DataFrame.from_records(cur) \n",
    "        if df.empty: \n",
    "            df = pd.DataFrame() \n",
    "        else:\n",
    "            if 'index_id' in df.columns:\n",
    "                df = df.sort_values(by=['date', 'index_id', 'skey']).reset_index(drop=True)\n",
    "            else:\n",
    "                df = df.sort_values(by=['date','skey']).reset_index(drop=True)\n",
    "        return df \n",
    " \n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = self.version\n",
    "            ser_data = self.ser(df_seg, version)\n",
    "            seg = {'ver': version, 'data': ser_data, 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        elif version == 3:\n",
    "            # 32-bit number needs more space than 64-bit for parquet\n",
    "            for col_name in s.columns:\n",
    "                col = s[col_name]\n",
    "                if col.dtype == np.int32:\n",
    "                    s[col_name] = s[col_name].astype(np.int64)\n",
    "                elif col.dtype == np.uint32:\n",
    "                    s[col_name] = s[col_name].astype(np.uint64)\n",
    "            tbl = pa.Table.from_pandas(s)\n",
    "            f = io.BytesIO()\n",
    "            pq.write_table(tbl, f, use_dictionary=False, compression='ZSTD', compression_level=0)\n",
    "            f.seek(0)\n",
    "            data = f.read()\n",
    "            return data\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        elif version == 3:\n",
    "            f = io.BytesIO()\n",
    "            f.write(s)\n",
    "            f.seek(0)\n",
    "            return pq.read_table(f, use_threads=False).to_pandas()\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170301\n",
      "20170302\n",
      "20170303\n",
      "20170306\n",
      "20170307\n",
      "20170308\n",
      "20170309\n",
      "20170310\n",
      "20170313\n",
      "20170314\n",
      "20170315\n",
      "20170316\n",
      "20170317\n",
      "20170320\n",
      "20170321\n",
      "20170322\n",
      "20170323\n",
      "20170324\n",
      "20170327\n",
      "20170328\n",
      "20170329\n",
      "20170330\n",
      "2002616\n",
      "20170331\n",
      "20170405\n",
      "20170406\n",
      "20170407\n",
      "20170410\n",
      "20170411\n",
      "20170412\n",
      "20170413\n",
      "20170414\n",
      "20170417\n",
      "20170418\n",
      "20170419\n",
      "20170420\n",
      "20170421\n",
      "20170424\n",
      "20170425\n",
      "20170426\n",
      "20170427\n",
      "20170428\n",
      "20170502\n",
      "20170503\n",
      "20170504\n",
      "20170505\n",
      "20170508\n",
      "20170509\n",
      "20170510\n",
      "20170511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170512\n",
      "20170515\n",
      "20170516\n",
      "20170517\n",
      "20170518\n",
      "20170519\n",
      "20170522\n",
      "20170523\n",
      "20170524\n",
      "20170525\n",
      "20170526\n",
      "20170531\n",
      "20170601\n",
      "20170602\n",
      "20170605\n",
      "20170606\n",
      "20170607\n",
      "20170608\n",
      "20170609\n",
      "20170612\n",
      "20170613\n",
      "20170614\n",
      "20170615\n",
      "20170616\n",
      "20170619\n",
      "20170620\n",
      "20170621\n",
      "20170622\n",
      "20170623\n",
      "20170626\n",
      "20170627\n",
      "20170628\n",
      "20170629\n",
      "20170630\n",
      "20170703\n",
      "20170704\n",
      "20170705\n",
      "20170706\n",
      "20170707\n",
      "20170710\n",
      "20170711\n",
      "20170712\n",
      "20170713\n",
      "20170714\n",
      "20170717\n",
      "20170718\n",
      "20170719\n",
      "20170720\n",
      "20170721\n",
      "20170724\n",
      "20170725\n",
      "20170726\n",
      "20170727\n",
      "20170728\n",
      "20170731\n",
      "20170801\n",
      "20170802\n",
      "20170803\n",
      "20170804\n",
      "20170807\n",
      "20170808\n",
      "20170809\n",
      "20170810\n",
      "20170811\n",
      "20170814\n",
      "20170815\n",
      "20170816\n",
      "20170817\n",
      "20170818\n",
      "20170821\n",
      "20170822\n",
      "20170823\n",
      "20170824\n",
      "20170825\n",
      "20170828\n",
      "20170829\n",
      "20170830\n",
      "20170831\n",
      "20170901\n",
      "20170904\n",
      "20170905\n",
      "20170906\n",
      "20170907\n",
      "20170908\n",
      "20170911\n",
      "20170912\n",
      "20170913\n",
      "20170914\n",
      "20170915\n",
      "20170918\n",
      "20170919\n",
      "20170920\n",
      "20170921\n",
      "20170922\n",
      "20170925\n",
      "20170926\n",
      "20170927\n",
      "20170928\n",
      "20170929\n",
      "20171009\n",
      "20171010\n",
      "20171011\n",
      "20171012\n",
      "20171013\n",
      "20171016\n",
      "20171017\n",
      "20171018\n",
      "20171019\n",
      "20171020\n",
      "20171023\n",
      "20171024\n",
      "20171025\n",
      "20171026\n",
      "20171027\n",
      "20171030\n",
      "20171031\n",
      "20171101\n",
      "20171102\n",
      "20171103\n",
      "20171106\n",
      "20171107\n",
      "20171108\n",
      "20171109\n",
      "20171110\n",
      "20171113\n",
      "20171114\n",
      "20171115\n",
      "20171116\n",
      "20171117\n",
      "20171120\n",
      "20171121\n",
      "20171122\n",
      "20171123\n",
      "20171124\n",
      "20171127\n",
      "20171128\n",
      "20171129\n",
      "20171130\n",
      "20171201\n",
      "20171204\n",
      "20171205\n",
      "20171206\n",
      "20171207\n",
      "20171208\n",
      "20171211\n",
      "20171212\n",
      "20171213\n",
      "20171214\n",
      "20171215\n",
      "20171218\n",
      "2000155\n",
      "20171219\n",
      "20171220\n",
      "20171221\n",
      "20171222\n",
      "20171225\n",
      "20171226\n",
      "20171227\n",
      "20171228\n",
      "20171229\n",
      "20180102\n",
      "20180103\n",
      "20180104\n",
      "20180105\n",
      "20180108\n",
      "20180109\n",
      "20180110\n",
      "20180111\n",
      "20180112\n",
      "20180115\n",
      "20180116\n",
      "20180117\n",
      "20180118\n",
      "20180119\n",
      "20180122\n",
      "20180123\n",
      "20180124\n",
      "20180125\n",
      "20180126\n",
      "20180129\n",
      "2300197\n",
      "20180130\n",
      "20180131\n",
      "20180201\n",
      "20180202\n",
      "20180205\n",
      "20180206\n",
      "20180207\n",
      "20180208\n",
      "20180209\n",
      "20180212\n",
      "20180213\n",
      "20180214\n",
      "20180222\n",
      "20180223\n",
      "20180226\n",
      "20180227\n",
      "20180228\n",
      "20180301\n",
      "20180302\n",
      "20180305\n",
      "20180306\n",
      "20180307\n",
      "20180308\n",
      "20180309\n",
      "20180312\n",
      "20180313\n",
      "20180314\n",
      "20180315\n",
      "20180316\n",
      "20180319\n",
      "20180320\n",
      "20180321\n",
      "20180322\n",
      "20180323\n",
      "20180326\n",
      "20180327\n",
      "20180328\n",
      "20180329\n",
      "20180330\n",
      "20180402\n",
      "20180403\n",
      "20180404\n",
      "20180409\n",
      "20180410\n",
      "20180411\n",
      "20180412\n",
      "20180413\n",
      "20180416\n",
      "20180417\n",
      "20180418\n",
      "20180419\n",
      "20180420\n",
      "20180423\n",
      "20180424\n",
      "20180425\n",
      "20180426\n",
      "20180427\n",
      "20180502\n",
      "20180503\n",
      "20180504\n",
      "20180507\n",
      "20180508\n",
      "20180509\n",
      "20180510\n",
      "20180511\n",
      "20180514\n",
      "20180515\n",
      "20180516\n",
      "20180517\n",
      "20180518\n",
      "20180521\n",
      "20180522\n",
      "20180523\n",
      "20180524\n",
      "20180525\n",
      "20180528\n",
      "20180529\n",
      "20180530\n",
      "20180531\n",
      "20180601\n",
      "20180604\n",
      "20180605\n",
      "20180606\n",
      "20180607\n",
      "20180608\n",
      "20180611\n",
      "20180612\n",
      "20180613\n",
      "20180614\n",
      "20180615\n",
      "20180619\n",
      "20180620\n",
      "20180621\n",
      "20180622\n",
      "2002114\n",
      "20180625\n",
      "20180626\n",
      "20180627\n",
      "20180628\n",
      "20180629\n",
      "20180702\n",
      "20180703\n",
      "20180704\n",
      "20180705\n",
      "20180706\n",
      "20180709\n",
      "20180710\n",
      "20180711\n",
      "20180712\n",
      "20180713\n",
      "20180716\n",
      "20180717\n",
      "20180718\n",
      "20180719\n",
      "20180720\n",
      "20180723\n",
      "2002680\n",
      "20180724\n",
      "20180725\n",
      "20180726\n",
      "20180727\n",
      "20180730\n",
      "20180731\n",
      "20180801\n",
      "20180802\n",
      "20180803\n",
      "20180806\n",
      "20180807\n",
      "20180808\n",
      "20180809\n",
      "20180810\n",
      "20180813\n",
      "20180814\n",
      "20180815\n",
      "20180816\n",
      "20180817\n",
      "20180820\n",
      "20180821\n",
      "20180822\n",
      "20180823\n",
      "20180824\n",
      "20180827\n",
      "20180828\n",
      "2000950\n",
      "20180829\n",
      "20180830\n",
      "20180831\n",
      "20180903\n",
      "20180904\n",
      "20180905\n",
      "20180906\n",
      "20180907\n",
      "20180910\n",
      "20180911\n",
      "20180912\n",
      "20180913\n",
      "20180914\n",
      "20180917\n",
      "20180918\n",
      "20180919\n",
      "20180920\n",
      "20180921\n",
      "20180925\n",
      "20180926\n",
      "20180927\n",
      "20180928\n",
      "20181008\n",
      "20181009\n",
      "20181010\n",
      "20181011\n",
      "20181012\n",
      "20181015\n",
      "20181016\n",
      "20181017\n",
      "20181018\n",
      "20181019\n",
      "20181022\n",
      "20181023\n",
      "20181024\n",
      "2002766\n",
      "2300131\n",
      "2300207\n",
      "2300350\n",
      "20181025\n",
      "20181026\n",
      "20181029\n",
      "20181030\n",
      "20181031\n",
      "20181101\n",
      "20181102\n",
      "20181105\n",
      "20181106\n",
      "20181107\n",
      "20181108\n",
      "20181109\n",
      "20181112\n",
      "20181113\n",
      "20181114\n",
      "20181115\n",
      "20181116\n",
      "20181119\n",
      "20181120\n",
      "20181121\n",
      "20181122\n",
      "20181123\n",
      "20181126\n",
      "20181127\n",
      "20181128\n",
      "20181129\n",
      "20181130\n",
      "20181203\n",
      "20181204\n",
      "20181205\n",
      "20181206\n",
      "20181207\n",
      "20181210\n",
      "20181211\n",
      "20181212\n",
      "20181213\n",
      "20181214\n",
      "20181217\n",
      "20181218\n",
      "20181219\n",
      "20181220\n",
      "20181221\n",
      "20181224\n",
      "20181225\n",
      "20181226\n",
      "20181227\n",
      "20181228\n",
      "20190102\n",
      "20190103\n",
      "20190104\n",
      "20190107\n",
      "20190108\n",
      "20190109\n",
      "20190110\n",
      "20190111\n",
      "20190114\n",
      "20190115\n",
      "20190116\n",
      "20190117\n",
      "20190118\n",
      "20190121\n",
      "20190122\n",
      "20190123\n",
      "20190124\n",
      "20190125\n",
      "20190128\n",
      "20190129\n",
      "20190130\n",
      "20190131\n",
      "20190201\n",
      "20190211\n",
      "20190212\n",
      "20190213\n",
      "20190214\n",
      "20190215\n",
      "20190218\n",
      "20190219\n",
      "20190220\n",
      "20190221\n",
      "20190222\n",
      "20190225\n",
      "20190226\n",
      "20190227\n",
      "20190228\n",
      "20190301\n",
      "20190304\n",
      "20190305\n",
      "20190306\n",
      "20190307\n",
      "20190308\n",
      "20190311\n",
      "20190312\n",
      "20190313\n",
      "20190314\n",
      "20190315\n",
      "20190318\n",
      "20190319\n",
      "20190320\n",
      "20190321\n",
      "20190322\n",
      "20190325\n",
      "20190326\n",
      "20190327\n",
      "20190328\n",
      "20190329\n",
      "20190401\n",
      "20190402\n",
      "20190403\n",
      "20190404\n",
      "20190408\n",
      "20190409\n",
      "20190410\n",
      "20190411\n",
      "20190412\n",
      "20190415\n",
      "20190416\n",
      "20190417\n",
      "20190418\n",
      "20190419\n",
      "20190422\n",
      "20190423\n",
      "20190424\n",
      "20190425\n",
      "20190426\n",
      "20190429\n",
      "20190430\n",
      "20190506\n",
      "20190507\n",
      "20190508\n",
      "20190509\n",
      "20190510\n",
      "20190513\n",
      "20190514\n",
      "20190515\n",
      "20190516\n",
      "20190517\n",
      "20190520\n",
      "20190521\n",
      "20190522\n",
      "20190523\n",
      "20190524\n",
      "20190527\n",
      "20190528\n",
      "20190529\n",
      "20190530\n",
      "20190531\n",
      "20190603\n",
      "20190604\n",
      "20190605\n",
      "20190606\n",
      "20190610\n",
      "20190611\n",
      "20190612\n",
      "20190613\n",
      "20190614\n",
      "20190617\n",
      "20190618\n",
      "20190619\n",
      "20190620\n",
      "20190621\n",
      "20190624\n",
      "20190625\n",
      "20190626\n",
      "20190627\n",
      "20190628\n",
      "20190701\n",
      "20190702\n",
      "20190703\n",
      "20190704\n",
      "20190705\n",
      "20190708\n",
      "20190709\n",
      "20190710\n",
      "20190711\n",
      "20190712\n",
      "20190715\n",
      "20190716\n",
      "20190717\n",
      "20190718\n",
      "20190719\n",
      "20190722\n",
      "20190723\n",
      "20190724\n",
      "20190725\n",
      "20190726\n",
      "20190729\n",
      "20190730\n",
      "20190731\n",
      "20190801\n",
      "20190802\n",
      "20190805\n",
      "20190806\n",
      "20190807\n",
      "20190808\n",
      "20190809\n",
      "20190812\n",
      "20190813\n",
      "20190814\n",
      "20190815\n",
      "20190816\n",
      "20190819\n",
      "20190820\n",
      "20190821\n",
      "20190822\n",
      "20190823\n",
      "20190826\n",
      "20190827\n",
      "20190828\n",
      "20190829\n",
      "20190830\n",
      "20190902\n",
      "20190903\n",
      "20190904\n",
      "20190905\n",
      "20190906\n",
      "20190909\n",
      "20190910\n",
      "20190911\n",
      "20190912\n",
      "20190916\n",
      "20190917\n",
      "20190918\n",
      "20190919\n",
      "20190920\n",
      "20190923\n",
      "20190924\n",
      "20190925\n",
      "20190926\n",
      "20190927\n",
      "20190930\n",
      "20191008\n",
      "20191009\n",
      "20191010\n",
      "20191011\n",
      "20191014\n",
      "20191015\n",
      "20191016\n",
      "20191017\n",
      "20191018\n",
      "20191021\n",
      "20191022\n",
      "20191023\n",
      "20191024\n",
      "20191025\n",
      "20191028\n",
      "20191029\n",
      "20191030\n",
      "20191031\n",
      "20191101\n",
      "20191104\n",
      "20191105\n",
      "20191106\n",
      "20191107\n",
      "20191108\n",
      "20191111\n",
      "20191112\n",
      "20191113\n",
      "20191114\n",
      "20191115\n",
      "20191118\n",
      "20191119\n",
      "20191120\n",
      "20191121\n",
      "20191122\n",
      "20191125\n",
      "20191126\n",
      "20191127\n",
      "20191128\n",
      "20191129\n",
      "20191202\n",
      "20191203\n",
      "20191204\n",
      "20191205\n",
      "20191206\n",
      "20191209\n",
      "20191210\n",
      "20191211\n",
      "20191212\n",
      "20191213\n",
      "20191216\n",
      "20191217\n",
      "20191218\n",
      "20191219\n",
      "20191220\n",
      "20191223\n",
      "20191224\n",
      "20191225\n",
      "20191226\n",
      "20191227\n",
      "2300773\n",
      "20191230\n",
      "20191231\n",
      "20200102\n",
      "20200103\n",
      "20200106\n",
      "20200107\n",
      "20200108\n",
      "20200109\n",
      "20200110\n",
      "20200113\n",
      "20200114\n",
      "20200115\n",
      "20200116\n",
      "20200117\n",
      "20200120\n",
      "20200121\n",
      "20200122\n",
      "20200123\n",
      "20200203\n",
      "20200204\n",
      "20200205\n",
      "20200206\n",
      "20200207\n",
      "20200210\n",
      "20200211\n",
      "20200212\n",
      "20200213\n",
      "20200214\n",
      "20200217\n",
      "20200218\n",
      "20200219\n",
      "20200220\n",
      "20200221\n",
      "20200224\n",
      "20200225\n",
      "20200226\n",
      "20200227\n",
      "20200228\n",
      "20200302\n",
      "20200303\n",
      "20200304\n",
      "20200305\n",
      "20200306\n",
      "20200309\n",
      "20200310\n",
      "20200311\n",
      "20200312\n",
      "20200313\n",
      "20200316\n",
      "20200317\n",
      "20200318\n",
      "20200319\n",
      "20200320\n",
      "20200323\n",
      "20200324\n",
      "20200325\n",
      "20200326\n",
      "20200327\n",
      "20200330\n",
      "20200331\n",
      "20200401\n",
      "20200402\n",
      "20200403\n",
      "20200407\n",
      "20200408\n",
      "20200409\n",
      "20200410\n",
      "20200413\n",
      "20200414\n"
     ]
    }
   ],
   "source": [
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "\n",
    "pd.set_option('max_columns', 200)\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "\n",
    "startDate = 20170301\n",
    "endDate = 20200731\n",
    "mdOrderLog = db1.read_tick('md_order', start_date=startDate, end_date=endDate, symbol=[2000001])\n",
    "datelist = mdOrderLog['date'].unique()\n",
    "save = {}\n",
    "save['date'] = []\n",
    "save['secid'] = []\n",
    "ss = pd.read_csv('/mnt/ShareWithServer/result/shangshi.csv')\n",
    "ss['skey'] = np.where(ss['证券代码'].str[-2:] == 'SZ', ss['证券代码'].str[:6].astype(int) + 2000000, ss['证券代码'].str[:6].astype(int) + 1000000)\n",
    "ss['date'] = (ss['上市日期'].str[:4] + ss['上市日期'].str[5:7] + ss['上市日期'].str[8:10]).astype(int)\n",
    "for d in datelist:\n",
    "    print(d)\n",
    "    sl1 = db1.read_daily('index_memb', index_id=[1000852], start_date=20170901, end_date=20201203)['skey'].unique()\n",
    "    sl1 = sl1[sl1 > 2000000]\n",
    "    data1 = db1.read_tick('md_snapshot_l2', start_date=str(d), end_date=str(d), symbol=list(sl1))\n",
    "    sl1 = data1['skey'].unique()\n",
    "    for s in sl1:\n",
    "        mbd = db1.read_tick('md_snapshot_mbd', start_date=str(d), end_date=str(d), symbol=s)\n",
    "        if mbd is None:\n",
    "            if ss[ss['skey'] == s]['date'].iloc[0] == d:\n",
    "                continue\n",
    "            else:\n",
    "                save['date'].append(d)\n",
    "                save['secid'].append(s)\n",
    "                print(s)\n",
    "                continue\n",
    "        try:\n",
    "            assert(mbd.shape[1] == 82)\n",
    "        except:\n",
    "            assert('datetime' in mbd.columns) \n",
    "            list1 = list(mbd.columns)\n",
    "            list1.remove('datetime')\n",
    "            mbd = mbd[list1]\n",
    "            assert(mbd.shape[1] == 82)\n",
    "            db1.write('md_snapshot_mbd', mbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200414\n",
      "20200415\n",
      "20200416\n",
      "20200417\n",
      "20200420\n",
      "20200421\n",
      "20200422\n",
      "20200423\n",
      "20200424\n",
      "20200427\n",
      "20200428\n",
      "20200429\n",
      "20200430\n",
      "20200506\n",
      "20200507\n",
      "20200508\n",
      "20200511\n",
      "20200512\n",
      "20200513\n",
      "20200514\n",
      "20200515\n",
      "20200518\n",
      "20200519\n",
      "20200520\n",
      "20200521\n",
      "20200522\n",
      "20200525\n",
      "20200526\n",
      "20200527\n",
      "20200528\n",
      "20200529\n",
      "20200601\n",
      "20200602\n",
      "20200603\n",
      "20200604\n",
      "20200605\n",
      "20200608\n",
      "20200609\n",
      "20200610\n",
      "20200611\n",
      "20200612\n",
      "20200615\n",
      "20200616\n",
      "20200617\n",
      "20200618\n",
      "20200619\n",
      "20200622\n",
      "20200623\n",
      "20200624\n",
      "20200629\n",
      "20200630\n",
      "20200701\n",
      "20200702\n",
      "20200703\n",
      "20200706\n",
      "20200707\n",
      "20200708\n",
      "20200709\n",
      "20200710\n",
      "20200713\n",
      "20200714\n",
      "20200715\n",
      "20200716\n",
      "20200717\n",
      "20200720\n",
      "20200721\n",
      "20200722\n",
      "20200723\n",
      "20200724\n",
      "20200728\n",
      "20200729\n",
      "20200730\n",
      "20200731\n"
     ]
    }
   ],
   "source": [
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "\n",
    "pd.set_option('max_columns', 200)\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "\n",
    "startDate = 20200414\n",
    "endDate = 20200731\n",
    "mdOrderLog = db1.read_tick('md_order', start_date=startDate, end_date=endDate, symbol=[2000001])\n",
    "datelist = mdOrderLog['date'].unique()\n",
    "save = {}\n",
    "save['date'] = []\n",
    "save['secid'] = []\n",
    "ss = pd.read_csv('/mnt/ShareWithServer/result/shangshi.csv')\n",
    "ss['skey'] = np.where(ss['证券代码'].str[-2:] == 'SZ', ss['证券代码'].str[:6].astype(int) + 2000000, ss['证券代码'].str[:6].astype(int) + 1000000)\n",
    "ss['date'] = (ss['上市日期'].str[:4] + ss['上市日期'].str[5:7] + ss['上市日期'].str[8:10]).astype(int)\n",
    "for d in datelist:\n",
    "    print(d)\n",
    "    sl1 = db1.read_daily('index_memb', index_id=[1000852], start_date=20170901, end_date=20201203)['skey'].unique()\n",
    "    sl1 = sl1[sl1 > 2000000]\n",
    "    data1 = db1.read_tick('md_snapshot_l2', start_date=str(d), end_date=str(d), symbol=list(sl1))\n",
    "    sl1 = data1['skey'].unique()\n",
    "    for s in sl1:\n",
    "        mbd = db1.read_tick('md_snapshot_mbd', start_date=str(d), end_date=str(d), symbol=s)\n",
    "        if mbd is None:\n",
    "            if ss[ss['skey'] == s]['date'].iloc[0] == d:\n",
    "                continue\n",
    "            else:\n",
    "                save['date'].append(d)\n",
    "                save['secid'].append(s)\n",
    "                print(s)\n",
    "                continue\n",
    "        try:\n",
    "            assert(mbd.shape[1] == 82)\n",
    "        except:\n",
    "            assert('datetime' in mbd.columns) \n",
    "            list1 = list(mbd.columns)\n",
    "            list1.remove('datetime')\n",
    "            mbd = mbd[list1]\n",
    "            assert(mbd.shape[1] == 82)\n",
    "            db1.write('md_snapshot_mbd', mbd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:202: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:43.015386\n",
      "0:00:33.397582\n",
      "20180102 unzip finished\n",
      "0:00:44.753384\n",
      "0:01:14.747916\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:20.422879\n",
      "0:00:36.201283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "355  1601360  20180102    49.0   50.57   47.8      50.57     45.97   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "355      0.970913     0.100065      0.037972       0.013023        0.010651   \n",
      "\n",
      "       d_volume    d_amount_x   TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "355  24117001.0  1.194709e+09  0.06072    0.0    1.0   1.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "355   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "355         NaN      NaN  \n",
      "0:00:03.463660\n",
      "no massive missing\n",
      "0:02:03.588669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:03.964164\n",
      "0:00:34.639618\n",
      "20180103 unzip finished\n",
      "0:00:55.203986\n",
      "0:01:26.408463\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:07.238519\n",
      "0:00:34.414378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "355  1601360  20180103    53.0   55.63  52.61      55.63     50.57   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "355      0.970913     0.100059      0.128169       0.008848        0.009557   \n",
      "\n",
      "       d_volume   d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "355  18047055.0  982933573.0  0.045438    0.0    1.0   1.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "355   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "355         NaN      NaN  \n",
      "0:00:03.841662\n",
      "no massive missing\n",
      "0:01:56.928565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:01.187527\n",
      "0:00:33.521045\n",
      "20180104 unzip finished\n",
      "0:00:53.772197\n",
      "0:01:23.891970\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:44.619880\n",
      "0:00:34.171105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "353  1601360  20180104    61.0   61.19   59.6      61.19     55.63   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "353      0.970913     0.099946      0.375984       0.004584        0.002094   \n",
      "\n",
      "      d_volume   d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  isDT  \\\n",
      "353  7024221.0  427732585.0  0.017685    0.0    1.0   1.0    0.0    0.0   0.0   \n",
      "\n",
      "     tmrHalted  haltedDays  marketShares  totalShares  d_close_y  d_amount_y  \\\n",
      "353        0.0         0.0   397182443.0  397182443.0        NaN         NaN   \n",
      "\n",
      "     auction  \n",
      "353      NaN  \n",
      "0:00:03.435277\n",
      "no massive missing\n",
      "0:01:57.361907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180104"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:52.186773\n",
      "0:00:50.839435\n",
      "20180105 unzip finished\n",
      "0:00:49.213145\n",
      "0:01:21.873915\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:05.703518\n",
      "0:00:36.284069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "352  1601360  20180105    66.5    66.5  55.07      55.42     61.19   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "352      0.970913    -0.094296      0.227736      -0.000044        0.000279   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "352  72643793.0  4.249961e+09  0.182898    0.0    0.0   0.0    0.0    1.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "352   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "352         NaN      NaN  \n",
      "0:00:03.651628\n",
      "no massive missing\n",
      "0:02:23.647805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:57.963886\n",
      "0:00:56.445913\n",
      "20180108 unzip finished\n",
      "0:00:50.136321\n",
      "0:01:23.351826\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:05.545950\n",
      "0:00:37.125929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "352  1601360  20180108   54.55    55.4  52.33      53.36     55.42   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "352      0.970913    -0.037171      0.160757       0.004508        0.001592   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "352  40804367.0  2.184401e+09  0.102735    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "352   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "352         NaN      NaN  \n",
      "0:00:04.195892\n",
      "no massive missing\n",
      "0:02:00.092629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180108"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:54.900770\n",
      "0:00:37.986971\n",
      "20180109 unzip finished\n",
      "0:00:48.256442\n",
      "0:01:22.022929\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:38.624784\n",
      "0:00:34.362868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "354  1601360  20180109    53.0    53.1  51.34      52.53     53.36   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "354      0.970913    -0.015555      0.038758      -0.000068       -0.001607   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "354  28344914.0  1.479833e+09  0.071365    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "354   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "354         NaN      NaN  \n",
      "0:00:03.676630\n",
      "no massive missing\n",
      "0:02:02.994094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:06.140901\n",
      "0:00:37.566596\n",
      "20180110 unzip finished\n",
      "0:00:49.127424\n",
      "0:01:20.810261\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:16.999317\n",
      "0:00:39.474348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "354  1601360  20180110   53.19   54.01  50.07      51.11     52.53   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "354      0.970913    -0.027032     -0.081251      -0.006176       -0.005289   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "354  38493554.0  1.997918e+09  0.096917    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "354   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "354         NaN      NaN  \n",
      "0:00:03.953773\n",
      "no massive missing\n",
      "0:02:02.963840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180110"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.129270\n",
      "0:00:33.774570\n",
      "20180111 unzip finished\n",
      "0:00:49.467670\n",
      "0:01:21.498924\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:52.431278\n",
      "0:00:48.997659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "357  1601360  20180111   50.93   53.75  49.03      52.52     51.11   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "357      0.970913     0.027588      -0.14169       0.003122        0.005129   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "357  39093172.0  2.008223e+09  0.098426    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "357   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "357         NaN      NaN  \n",
      "0:00:03.801945\n",
      "no massive missing\n",
      "0:01:57.308696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.588210\n",
      "0:00:33.819992\n",
      "20180112 unzip finished\n",
      "0:00:49.515659\n",
      "0:01:19.372116\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:44.590670\n",
      "0:00:39.740366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "355  1601360  20180112   51.85   52.14   50.1      50.21     52.52   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "355      0.970913    -0.043983     -0.094009      -0.004134        -0.00663   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "355  25743348.0  1.311933e+09  0.064815    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "355   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "355         NaN      NaN  \n",
      "0:00:03.472360\n",
      "no massive missing\n",
      "0:01:53.008763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.855967\n",
      "0:00:34.942725\n",
      "20180115 unzip finished\n",
      "0:00:49.900361\n",
      "0:01:22.413015\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:04.133223\n",
      "0:00:39.678783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "356  1601360  20180115   48.62    49.2  46.27      47.05     50.21   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "356      0.970913    -0.062936     -0.118253      -0.022814       -0.027852   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "356  27161903.0  1.300160e+09  0.068386    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "356   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "356         NaN      NaN  \n",
      "0:00:03.508670\n",
      "no massive missing\n",
      "0:02:19.856561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:12.877170\n",
      "0:00:35.746374\n",
      "20180116 unzip finished\n",
      "0:00:51.244993\n",
      "0:01:18.270539\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:56.336613\n",
      "0:00:35.974635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "355  1601360  20180116    46.8    49.0  46.21      48.21     47.05   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "355      0.970913     0.024655     -0.082239       0.007637        0.004527   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "355  21086023.0  1.010841e+09  0.053089    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "355   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "355         NaN      NaN  \n",
      "0:00:03.561738\n",
      "no massive missing\n",
      "0:01:55.389934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:05.452682\n",
      "0:00:36.038319\n",
      "20180117 unzip finished\n",
      "0:00:50.694076\n",
      "0:01:29.048547\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:10.318053\n",
      "0:00:36.607980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "354  1601360  20180117    47.2   49.86  46.91      48.27     48.21   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "354      0.970913     0.001245     -0.055566      -0.005344       -0.002559   \n",
      "\n",
      "       d_volume   d_amount_x   TORate  allZT  hasZT  isZT  allDT  hasDT  isDT  \\\n",
      "354  20240477.0  984998524.0  0.05096    0.0    0.0   0.0    0.0    0.0   0.0   \n",
      "\n",
      "     tmrHalted  haltedDays  marketShares  totalShares  d_close_y  d_amount_y  \\\n",
      "354        0.0         0.0   397182443.0  397182443.0        NaN         NaN   \n",
      "\n",
      "     auction  \n",
      "354      NaN  \n",
      "0:00:03.644461\n",
      "no massive missing\n",
      "0:02:07.000655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:00.150956\n",
      "0:00:40.108626\n",
      "20180118 unzip finished\n",
      "0:00:49.534265\n",
      "0:01:24.139264\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:07.468107\n",
      "0:00:42.747416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "354  1601360  20180118   47.61   50.64  47.28      49.53     48.27   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "354      0.970913     0.026103     -0.056931       0.003086        0.001782   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "354  22698685.0  1.115041e+09  0.057149    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "354   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "354         NaN      NaN  \n",
      "0:00:03.695854\n",
      "no massive missing\n",
      "0:02:31.876399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180118"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:00.990174\n",
      "0:00:37.845230\n",
      "20180119 unzip finished\n",
      "0:00:49.210500\n",
      "0:01:21.536296\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:03.763573\n",
      "0:00:35.611650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "353  1601360  20180119   49.42    50.0  47.71      47.94     49.53   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "353      0.970913    -0.032102      -0.04521      -0.002294       -0.002433   \n",
      "\n",
      "       d_volume   d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "353  18219939.0  889073693.0  0.045873    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "353   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "353         NaN      NaN  \n",
      "0:00:03.352571\n",
      "no massive missing\n",
      "0:01:53.682159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.158661\n",
      "0:00:37.440910\n",
      "20180122 unzip finished\n",
      "0:00:50.231210\n",
      "0:01:24.923191\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:12.669521\n",
      "0:00:36.770258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "354  1601360  20180122    47.1   47.44   45.5      46.49     47.94   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "354      0.970913    -0.030246     -0.011902       0.011998        0.010988   \n",
      "\n",
      "       d_volume   d_amount_x   TORate  allZT  hasZT  isZT  allDT  hasDT  isDT  \\\n",
      "354  15942930.0  742261255.0  0.04014    0.0    0.0   0.0    0.0    0.0   0.0   \n",
      "\n",
      "     tmrHalted  haltedDays  marketShares  totalShares  d_close_y  d_amount_y  \\\n",
      "354        0.0         0.0   397182443.0  397182443.0        NaN         NaN   \n",
      "\n",
      "     auction  \n",
      "354      NaN  \n",
      "0:00:03.564463\n",
      "no massive missing\n",
      "0:02:00.740909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180122"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.218564\n",
      "0:00:45.749030\n",
      "20180123 unzip finished\n",
      "0:00:52.560583\n",
      "0:01:22.872976\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:03.112587\n",
      "0:00:46.126095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "354  1601360  20180123    46.6    47.3  45.86      46.39     46.49   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "354      0.970913    -0.002151     -0.037752       0.001159        0.000774   \n",
      "\n",
      "       d_volume   d_amount_x   TORate  allZT  hasZT  isZT  allDT  hasDT  isDT  \\\n",
      "354  10223540.0  476271128.0  0.02574    0.0    0.0   0.0    0.0    0.0   0.0   \n",
      "\n",
      "     tmrHalted  haltedDays  marketShares  totalShares  d_close_y  d_amount_y  \\\n",
      "354        0.0         0.0   397182443.0  397182443.0        NaN         NaN   \n",
      "\n",
      "     auction  \n",
      "354      NaN  \n",
      "0:00:05.365771\n",
      "no massive missing\n",
      "0:02:05.701466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.488964\n",
      "0:00:36.474301\n",
      "20180124 unzip finished\n",
      "0:00:47.727702\n",
      "0:01:21.097804\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:06.427826\n",
      "0:00:35.849015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "355  1601360  20180124    46.3   47.78   45.9      47.08     46.39   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "355      0.970913     0.014874     -0.024653       0.006184        0.007469   \n",
      "\n",
      "       d_volume   d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "355  14004193.0  656790229.0  0.035259    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "355   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "355         NaN      NaN  \n",
      "0:00:04.437467\n",
      "no massive missing\n",
      "0:02:12.575945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.235722\n",
      "0:00:35.567000\n",
      "20180125 unzip finished\n",
      "0:00:50.217521\n",
      "0:01:24.552564\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:23.010632\n",
      "0:00:36.247220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "354  1601360  20180125    46.9    47.5  46.06      46.12     47.08   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "354      0.970913    -0.020391     -0.068847      -0.001812       -0.001382   \n",
      "\n",
      "       d_volume   d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "354  12428410.0  580615701.0  0.031291    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "354   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "354         NaN      NaN  \n",
      "0:00:03.671117\n",
      "no massive missing\n",
      "0:01:59.633739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:06.138066\n",
      "0:00:49.221209\n",
      "20180126 unzip finished\n",
      "0:01:04.264870\n",
      "0:01:21.427592\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:43.407521\n",
      "0:00:39.526466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "353  1601360  20180126    45.8    46.6  45.11      45.45     46.12   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "353      0.970913    -0.014527      -0.05194       0.000143       -0.000938   \n",
      "\n",
      "       d_volume   d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "353  11679159.0  534878432.0  0.029405    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "353   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "353         NaN      NaN  \n",
      "0:00:03.621334\n",
      "no massive missing\n",
      "0:01:53.171796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180126"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.717407\n",
      "0:00:37.691783\n",
      "20180129 unzip finished\n",
      "0:00:49.290086\n",
      "0:01:21.371884\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:00.005031\n",
      "0:00:39.097928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "352  1601360  20180129    46.2    49.8   45.6      48.64     45.45   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "352      0.970913     0.070187      0.046247      -0.011553       -0.011839   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "352  24606194.0  1.171856e+09  0.061952    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "352   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "352         NaN      NaN  \n",
      "0:00:03.481674\n",
      "no massive missing\n",
      "0:02:02.330258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180129"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:01.277673\n",
      "0:00:32.442771\n",
      "20180130 unzip finished\n",
      "0:00:45.022674\n",
      "0:01:15.613778\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:36.590601\n",
      "0:00:32.052070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "352  1601360  20180130    49.0    53.5   49.0       53.5     48.64   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "352      0.970913     0.099918      0.153266       0.000564       -0.002472   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "352  37399423.0  1.921412e+09  0.094162    0.0    1.0   1.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "352   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "352         NaN      NaN  \n",
      "0:00:03.766391\n",
      "no massive missing\n",
      "0:01:52.652841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:57.318519\n",
      "0:00:35.325771\n",
      "20180131 unzip finished\n",
      "0:00:53.077153\n",
      "0:01:21.569212\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:32.803614\n",
      "0:00:35.859898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "352  1601360  20180131    55.0   55.88   51.2      51.26      53.5   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "352      0.970913    -0.041869      0.088785      -0.019657       -0.023613   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "352  37234004.0  1.980966e+09  0.093745    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "352   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "352         NaN      NaN  \n",
      "0:00:03.529195\n",
      "no massive missing\n",
      "0:01:54.711266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180131"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.485157\n",
      "0:00:38.043224\n",
      "20180201 unzip finished\n",
      "0:00:50.495402\n",
      "0:01:27.183063\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:40.980598\n",
      "0:00:39.631327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "352  1601360  20180201   49.97    51.6  49.01      50.03     51.26   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "352      0.970913    -0.023995      0.084779      -0.033057       -0.041902   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "352  21872506.0  1.099551e+09  0.055069    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "352   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "352         NaN      NaN  \n",
      "0:00:03.537701\n",
      "no massive missing\n",
      "0:02:04.424901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:02.908864\n",
      "0:00:36.833069\n",
      "20180202 unzip finished\n",
      "0:00:46.679972\n",
      "0:01:19.991600\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:37.049192\n",
      "0:00:34.579013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "352  1601360  20180202    54.0   55.03  52.02      55.03     50.03   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "352      0.970913      0.09994      0.210781        0.00336       -0.002856   \n",
      "\n",
      "       d_volume    d_amount_x   TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "352  25471230.0  1.380523e+09  0.06413    0.0    1.0   1.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "352   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "352         NaN      NaN  \n",
      "0:00:03.487282\n",
      "no massive missing\n",
      "0:01:57.269571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180202"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:57.112047\n",
      "0:00:38.323498\n",
      "20180205 unzip finished\n",
      "0:00:50.610337\n",
      "0:01:16.529130\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:20.606337\n",
      "0:00:33.051138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "349  1601360  20180205    55.0   60.53  53.88      60.53     55.03   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "349      0.970913     0.099945      0.244449      -0.001103       -0.004016   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "349  36025537.0  2.099217e+09  0.090703    0.0    1.0   1.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "349   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "349         NaN      NaN  \n",
      "0:00:03.370178\n",
      "no massive missing\n",
      "0:01:48.978285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180205"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.003377\n",
      "0:00:35.931579\n",
      "20180206 unzip finished\n",
      "0:00:48.497884\n",
      "0:01:24.887791\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:04.757888\n",
      "0:00:34.779609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "348  1601360  20180206    58.7   60.45  54.48      54.48     60.53   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "348      0.970913     -0.09995      0.018318      -0.049008       -0.049389   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "348  34965214.0  2.001063e+09  0.088033    0.0    0.0   0.0    0.0    1.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "348   1.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "348         NaN      NaN  \n",
      "0:00:03.811409\n",
      "no massive missing\n",
      "0:02:02.076709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:57.994687\n",
      "0:00:36.246882\n",
      "20180207 unzip finished\n",
      "0:00:47.348444\n",
      "0:01:21.113176\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:48.962519\n",
      "0:00:35.644776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "345  1601360  20180207    56.4   59.48   54.5      57.99     54.48   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "345      0.970913     0.064427      0.131291       0.001239        0.002538   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "345  38767633.0  2.228451e+09  0.097607    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "345   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "345         NaN      NaN  \n",
      "0:00:06.055754\n",
      "no massive missing\n",
      "0:01:56.307850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.639895\n",
      "0:00:33.042473\n",
      "20180208 unzip finished\n",
      "0:00:44.693414\n",
      "0:01:15.544889\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:12.108630\n",
      "0:00:31.424194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "342  1601360  20180208   56.88   60.89  55.15      57.17     57.99   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "342      0.970913     -0.01414      0.142714       0.009656        0.012985   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "342  36779918.0  2.155862e+09  0.092602    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "342   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "342         NaN      NaN  \n",
      "0:00:03.043570\n",
      "no massive missing\n",
      "0:02:11.576072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.112045\n",
      "0:00:36.266489\n",
      "20180209 unzip finished\n",
      "0:00:46.358076\n",
      "0:01:20.895286\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:43.394029\n",
      "0:00:37.998625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "342  1601360  20180209    53.8    54.7  51.45      51.45     57.17   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "342      0.970913    -0.100052     -0.065055      -0.036692       -0.029688   \n",
      "\n",
      "       d_volume    d_amount_x   TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "342  34030404.0  1.781182e+09  0.08568    0.0    0.0   0.0    0.0    1.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "342   1.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "342         NaN      NaN  \n",
      "0:00:03.774129\n",
      "no massive missing\n",
      "0:02:11.858865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180209"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:00.645668\n",
      "0:00:32.813443\n",
      "20180212 unzip finished\n",
      "0:00:53.792433\n",
      "0:01:14.753241\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:01.470282\n",
      "0:00:30.667769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "345  1601360  20180212    52.5    53.5  51.45      52.29     51.45   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "345      0.970913     0.016327     -0.136131       0.025959        0.024902   \n",
      "\n",
      "       d_volume   d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "345  18486114.0  972092458.0  0.046543    0.0    0.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "345   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "345         NaN      NaN  \n",
      "0:00:03.053613\n",
      "no massive missing\n",
      "0:01:46.905915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180212"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:01.090451\n",
      "0:00:32.032110\n",
      "20180213 unzip finished\n",
      "0:00:44.302908\n",
      "0:01:12.351336\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:47.012372\n",
      "0:00:35.765173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "347  1601360  20180213    53.8   57.52  53.11      57.52     52.29   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "347      0.970913     0.100019        0.0558       0.006642        0.002057   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "347  22514233.0  1.254491e+09  0.056685    0.0    1.0   1.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "347   0.0        0.0         0.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "347         NaN      NaN  \n",
      "0:00:03.001997\n",
      "no massive missing\n",
      "0:01:56.309228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180213"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:47.220960\n",
      "0:00:26.562092\n",
      "20180214 unzip finished\n",
      "0:01:04.186253\n",
      "0:01:07.743875\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:05.237253\n",
      "0:00:30.787980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "          ID      date  d_open  d_high  d_low  d_close_x  d_yclose  \\\n",
      "347  1601360  20180214    61.5   63.27   60.0      63.24     57.52   \n",
      "\n",
      "     d_cumprodCAA  d_dayReturn  d_5dayReturn  d_ICDayReturn  d_CSIDayReturn  \\\n",
      "347      0.970913     0.099444      0.090533       0.003117        0.002277   \n",
      "\n",
      "       d_volume    d_amount_x    TORate  allZT  hasZT  isZT  allDT  hasDT  \\\n",
      "347  40461380.0  2.522157e+09  0.101871    0.0    1.0   0.0    0.0    0.0   \n",
      "\n",
      "     isDT  tmrHalted  haltedDays  marketShares  totalShares  d_close_y  \\\n",
      "347   0.0        1.0         4.0   397182443.0  397182443.0        NaN   \n",
      "\n",
      "     d_amount_y  auction  \n",
      "347         NaN      NaN  \n",
      "0:00:02.885624\n",
      "no massive missing\n",
      "0:01:33.331304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180214"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:41.509046\n",
      "0:00:28.864419\n",
      "20180222 unzip finished\n",
      "0:01:02.502396\n",
      "0:01:10.397180\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:21.443441\n",
      "0:00:30.620530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:05.362424\n",
      "no massive missing\n",
      "0:01:39.085644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.286618\n",
      "0:00:29.152320\n",
      "20180223 unzip finished\n",
      "0:00:41.433828\n",
      "0:01:12.215682\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:08.743374\n",
      "0:00:32.822855\n",
      "0:00:03.043309\n",
      "no massive missing\n",
      "0:01:43.877048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180223"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.488846\n",
      "0:00:37.854517\n",
      "20180226 unzip finished\n",
      "0:00:48.109403\n",
      "0:01:18.870302\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:46.198213\n",
      "0:00:36.717075\n",
      "0:00:03.841862\n",
      "no massive missing\n",
      "0:01:50.022571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180226"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:02.646374\n",
      "0:00:33.355465\n",
      "20180227 unzip finished\n",
      "0:00:47.963010\n",
      "0:01:18.924711\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:02.121769\n",
      "0:00:39.363113\n",
      "0:00:03.369167\n",
      "no massive missing\n",
      "0:01:55.846071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.038574\n",
      "0:00:31.662830\n",
      "20180228 unzip finished\n",
      "0:00:43.869235\n",
      "0:01:15.640393\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:26.489553\n",
      "0:00:36.801058\n",
      "0:00:03.370081\n",
      "no massive missing\n",
      "0:01:54.726633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180228"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.383501\n",
      "0:00:35.400892\n",
      "20180301 unzip finished\n",
      "0:00:44.670761\n",
      "0:01:15.335078\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:00.571244\n",
      "0:00:33.105789\n",
      "0:00:03.233487\n",
      "no massive missing\n",
      "0:01:55.981440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.903780\n",
      "0:00:32.151316\n",
      "20180302 unzip finished\n",
      "0:00:45.281286\n",
      "0:01:14.049360\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:41.142115\n",
      "0:00:37.291512\n",
      "0:00:04.560152\n",
      "no massive missing\n",
      "0:01:48.756790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180302"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:50.058892\n",
      "0:00:30.634737\n",
      "20180305 unzip finished\n",
      "0:00:42.966607\n",
      "0:01:14.474525\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:59.353954\n",
      "0:00:33.707708\n",
      "0:00:03.609833\n",
      "no massive missing\n",
      "0:01:53.761258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180305"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:47.528561\n",
      "0:00:34.505711\n",
      "20180306 unzip finished\n",
      "0:00:51.553436\n",
      "0:01:21.643870\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:06.444778\n",
      "0:00:35.160764\n",
      "0:00:03.561383\n",
      "no massive missing\n",
      "0:01:55.978208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:54.033662\n",
      "0:00:34.182000\n",
      "20180307 unzip finished\n",
      "0:00:47.940642\n",
      "0:01:19.759108\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:57.194899\n",
      "0:00:36.698749\n",
      "0:00:03.419547\n",
      "no massive missing\n",
      "0:01:56.628482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:54.431571\n",
      "0:00:32.564836\n",
      "20180308 unzip finished\n",
      "0:00:47.616458\n",
      "0:01:19.283012\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:41.853588\n",
      "0:00:36.789127\n",
      "0:00:03.418232\n",
      "no massive missing\n",
      "0:01:55.247947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:02.799320\n",
      "0:00:36.579360\n",
      "20180309 unzip finished\n",
      "0:01:10.201361\n",
      "0:01:27.858067\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:20.854060\n",
      "0:00:39.984651\n",
      "0:00:06.254258\n",
      "no massive missing\n",
      "0:01:57.883748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:52.049004\n",
      "0:00:35.445076\n",
      "20180312 unzip finished\n",
      "0:00:49.701592\n",
      "0:01:30.766451\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:41.278783\n",
      "0:00:36.936428\n",
      "0:00:03.576963\n",
      "no massive missing\n",
      "0:02:06.040538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.309855\n",
      "0:00:34.474560\n",
      "20180313 unzip finished\n",
      "0:00:51.921077\n",
      "0:01:23.980949\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:30.194431\n",
      "0:00:38.048538\n",
      "0:00:03.633288\n",
      "no massive missing\n",
      "0:01:58.796981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180313"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:02.686214\n",
      "0:00:55.851874\n",
      "20180314 unzip finished\n",
      "0:00:49.940697\n",
      "0:01:27.944455\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:06.490251\n",
      "0:00:35.311004\n",
      "0:00:03.397086\n",
      "no massive missing\n",
      "0:01:56.900944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:54.196291\n",
      "0:00:33.195068\n",
      "20180315 unzip finished\n",
      "0:00:49.058599\n",
      "0:01:22.702761\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:36.452537\n",
      "0:00:36.178355\n",
      "0:00:03.599966\n",
      "no massive missing\n",
      "0:02:01.230424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:06.916906\n",
      "0:00:31.293031\n",
      "20180316 unzip finished\n",
      "0:00:47.254374\n",
      "0:01:25.003520\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:35.006689\n",
      "0:00:34.543460\n",
      "0:00:03.303739\n",
      "no massive missing\n",
      "0:01:51.348061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.774258\n",
      "0:00:32.361180\n",
      "20180319 unzip finished\n",
      "0:00:48.517648\n",
      "0:01:17.722154\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:27.902194\n",
      "0:00:33.037941\n",
      "0:00:03.271262\n",
      "no massive missing\n",
      "0:01:58.367499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180319"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:50.335709\n",
      "0:00:33.493001\n",
      "20180320 unzip finished\n",
      "0:00:48.059190\n",
      "0:01:19.627513\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:49.035092\n",
      "0:00:36.337053\n",
      "0:00:03.298648\n",
      "no massive missing\n",
      "0:01:51.613196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180320"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:52.819510\n",
      "0:00:39.969337\n",
      "20180321 unzip finished\n",
      "0:00:50.205938\n",
      "0:01:24.625344\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:43.553815\n",
      "0:00:41.504060\n",
      "0:00:03.681909\n",
      "no massive missing\n",
      "0:02:17.733310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180321"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:01.300348\n",
      "0:00:57.475450\n",
      "20180322 unzip finished\n",
      "0:00:48.297773\n",
      "0:01:23.121433\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:18.299119\n",
      "0:00:35.099366\n",
      "0:00:03.402229\n",
      "no massive missing\n",
      "0:02:09.537457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:04.808107\n",
      "0:00:39.541919\n",
      "20180323 unzip finished\n",
      "0:01:17.623378\n",
      "0:01:34.880431\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:11:08.778929\n",
      "0:00:44.232338\n",
      "0:00:03.752855\n",
      "no massive missing\n",
      "0:02:08.036634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180323"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:17.901951\n",
      "0:00:42.993759\n",
      "20180326 unzip finished\n",
      "0:00:49.297336\n",
      "0:01:34.906045\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "readPath = '/home/work516/day_stock/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SH' for i in dataPathLs])]]\n",
    "db = pd.DataFrame()\n",
    "for p in dataPathLs:\n",
    "    dayData = pd.read_csv(p, compression='gzip')\n",
    "    db = pd.concat([db, dayData])\n",
    "print(datetime.datetime.now() - startTm)\n",
    "\n",
    "year = \"2018\"\n",
    "startDate = '20180101'\n",
    "endDate = '20181231'\n",
    "readPath = '/mnt/usb/data/' + year + '/***/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i).split('_')[0] for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "date_list = pd.read_csv(\"/home/work516/KR_upload_code/trading_days.csv\")\n",
    "wr_ong = []\n",
    "mi_ss = []\n",
    "less = []\n",
    "\n",
    "for data in dataPathLs:\n",
    "    if len(np.array(glob.glob(data + '/SH/***'))) == 0:\n",
    "        if int(os.path.basename(data)) not in date_list[\"Date\"].values:\n",
    "            continue\n",
    "        else:\n",
    "            print(os.path.basename(data) + \" less data!!!!!!!!!!!!!!!!!\")\n",
    "            less.append(data)\n",
    "            continue\n",
    "    startTm = datetime.datetime.now()\n",
    "    date = os.path.basename(data)\n",
    "    rar_path = data + '/SH/snapshot.7z'\n",
    "    path = '/mnt/e/unzip_data/2018/SH'\n",
    "    path1 = path + '/' + date\n",
    "    un_path = path1\n",
    "    cmd = '7za x {} -o{}'.format(rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    print(date + ' unzip finished')\n",
    "\n",
    "    readPath = path1 + '/snapshot/***2/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[((dateLs >= 600000) & (dateLs <= 700000))]\n",
    "    SH = []\n",
    "    ll = []\n",
    "    startTm = datetime.datetime.now()\n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i, usecols = [0,1,3,5,7,9,10,11,15,17,18,19,20,21,22,23,25,26,28,29,30,31,32,33,37,39,40,41,\n",
    "                                          42,46,47,49,50])\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"StockID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        SH += [df]\n",
    "    del df\n",
    "    SH = pd.concat(SH).reset_index(drop=True)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"skey\"] = SH[\"StockID\"] + 1000000\n",
    "    SH.drop([\"StockID\"],axis=1,inplace=True)\n",
    "    SH[\"date\"] = int(SH[\"QuotTime\"].iloc[0]//1000000000)\n",
    "    SH[\"time\"] = (SH['QuotTime'] - int(SH['QuotTime'].iloc[0]//1000000000*1000000000)).astype(np.int64) * 1000\n",
    "    SH[\"clockAtArrival\"] = SH[\"QuotTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    SH.drop([\"QuotTime\"],axis=1,inplace=True)\n",
    "    SH['datetime'] = SH[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"BidPrice\"] = SH[\"BidPrice\"].apply(lambda x: [float(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferPrice\"] = SH[\"OfferPrice\"].apply(lambda x: [float(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"BidOrderQty\"] = SH[\"BidOrderQty\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferOrderQty\"] = SH[\"OfferOrderQty\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"BidNumOrders\"] = SH[\"BidNumOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferNumOrders\"] = SH[\"OfferNumOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        SH[\"bid\" + str(i) + 'p'] = SH[\"BidPrice\"].apply(lambda x: x[i-1],2)\n",
    "    SH.drop([\"BidPrice\"],axis=1,inplace=True)\n",
    "    print(\"1\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"ask\" + str(i) + 'p'] = SH[\"OfferPrice\"].apply(lambda x: x[i-1],2)\n",
    "    SH.drop([\"OfferPrice\"],axis=1,inplace=True)\n",
    "    print(\"2\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"bid\" + str(i) + 'q'] = SH[\"BidOrderQty\"].apply(lambda x: x[i-1])\n",
    "    SH.drop([\"BidOrderQty\"],axis=1,inplace=True)\n",
    "    print(\"3\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"ask\" + str(i) + 'q'] = SH[\"OfferOrderQty\"].apply(lambda x: x[i-1])\n",
    "    SH.drop([\"OfferOrderQty\"],axis=1,inplace=True)\n",
    "    print(\"4\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"bid\" + str(i) + 'n'] = SH[\"BidNumOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"bid\" + str(i) + 'n'] = SH[\"bid\" + str(i) + 'n'].astype('int32')\n",
    "    SH.drop([\"BidNumOrders\"],axis=1,inplace=True)\n",
    "    print(\"5\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"ask\" + str(i) + 'n'] = SH[\"OfferNumOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"ask\" + str(i) + 'n'] = SH[\"ask\" + str(i) + 'n'].astype('int32') \n",
    "    SH.drop([\"OfferNumOrders\"],axis=1,inplace=True)\n",
    "    print(\"6\")\n",
    "    \n",
    "    SH[\"BidOrders\"] = SH[\"BidOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferOrders\"] = SH[\"OfferOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "\n",
    "    for i in range(1, 51):\n",
    "        SH[\"bid1Top\" + str(i) + 'q'] = SH[\"BidOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"bid1Top\" + str(i) + 'q'] = SH[\"bid1Top\" + str(i) + 'q'].astype('int32') \n",
    "    SH.drop([\"BidOrders\"],axis=1,inplace=True)\n",
    "    print(\"7\")\n",
    "    \n",
    "    for i in range(1, 51):\n",
    "        SH[\"ask1Top\" + str(i) + 'q'] = SH[\"OfferOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"ask1Top\" + str(i) + 'q'] = SH[\"ask1Top\" + str(i) + 'q'].astype('int32') \n",
    "    SH.drop([\"OfferOrders\"],axis=1,inplace=True)\n",
    "    print(\"8\")\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH.columns = ['cum_trades_cnt', 'ask_trade_max_duration', 'total_bid_orders',\n",
    "       'cum_canceled_sell_amount', 'total_ask_quantity', 'cum_canceled_buy_orders',\n",
    "       'total_ask_vwap', 'cum_canceled_sell_volume', 'cum_volume', 'open',\n",
    "       'high', 'prev_close', 'low', 'total_bid_vwap',\n",
    "       'cum_canceled_sell_orders', 'total_ask_orders', 'total_ask_levels',\n",
    "       'total_bid_quantity', 'cum_canceled_buy_volume', 'bid_trade_max_duration',\n",
    "       'total_bid_levels', 'close', 'cum_amount', 'cum_canceled_buy_amount', 'skey', 'date', 'time', 'clockAtArrival',\n",
    "       'datetime', 'bid1p', 'bid2p', 'bid3p', 'bid4p', 'bid5p', 'bid6p',\n",
    "       'bid7p', 'bid8p', 'bid9p', 'bid10p', 'ask1p', 'ask2p', 'ask3p',\n",
    "       'ask4p', 'ask5p', 'ask6p', 'ask7p', 'ask8p', 'ask9p', 'ask10p',\n",
    "       'bid1q', 'bid2q', 'bid3q', 'bid4q', 'bid5q', 'bid6q', 'bid7q',\n",
    "       'bid8q', 'bid9q', 'bid10q', 'ask1q', 'ask2q', 'ask3q', 'ask4q',\n",
    "       'ask5q', 'ask6q', 'ask7q', 'ask8q', 'ask9q', 'ask10q', 'bid1n',\n",
    "       'bid2n', 'bid3n', 'bid4n', 'bid5n', 'bid6n', 'bid7n', 'bid8n',\n",
    "       'bid9n', 'bid10n', 'ask1n', 'ask2n', 'ask3n', 'ask4n', 'ask5n',\n",
    "       'ask6n', 'ask7n', 'ask8n', 'ask9n', 'ask10n', 'bid1Top1q',\n",
    "       'bid1Top2q', 'bid1Top3q', 'bid1Top4q', 'bid1Top5q', 'bid1Top6q',\n",
    "       'bid1Top7q', 'bid1Top8q', 'bid1Top9q', 'bid1Top10q', 'bid1Top11q',\n",
    "       'bid1Top12q', 'bid1Top13q', 'bid1Top14q', 'bid1Top15q',\n",
    "       'bid1Top16q', 'bid1Top17q', 'bid1Top18q', 'bid1Top19q',\n",
    "       'bid1Top20q', 'bid1Top21q', 'bid1Top22q', 'bid1Top23q',\n",
    "       'bid1Top24q', 'bid1Top25q', 'bid1Top26q', 'bid1Top27q',\n",
    "       'bid1Top28q', 'bid1Top29q', 'bid1Top30q', 'bid1Top31q',\n",
    "       'bid1Top32q', 'bid1Top33q', 'bid1Top34q', 'bid1Top35q',\n",
    "       'bid1Top36q', 'bid1Top37q', 'bid1Top38q', 'bid1Top39q',\n",
    "       'bid1Top40q', 'bid1Top41q', 'bid1Top42q', 'bid1Top43q',\n",
    "       'bid1Top44q', 'bid1Top45q', 'bid1Top46q', 'bid1Top47q',\n",
    "       'bid1Top48q', 'bid1Top49q', 'bid1Top50q', 'ask1Top1q', 'ask1Top2q',\n",
    "       'ask1Top3q', 'ask1Top4q', 'ask1Top5q', 'ask1Top6q', 'ask1Top7q',\n",
    "       'ask1Top8q', 'ask1Top9q', 'ask1Top10q', 'ask1Top11q', 'ask1Top12q',\n",
    "       'ask1Top13q', 'ask1Top14q', 'ask1Top15q', 'ask1Top16q',\n",
    "       'ask1Top17q', 'ask1Top18q', 'ask1Top19q', 'ask1Top20q',\n",
    "       'ask1Top21q', 'ask1Top22q', 'ask1Top23q', 'ask1Top24q',\n",
    "       'ask1Top25q', 'ask1Top26q', 'ask1Top27q', 'ask1Top28q',\n",
    "       'ask1Top29q', 'ask1Top30q', 'ask1Top31q', 'ask1Top32q',\n",
    "       'ask1Top33q', 'ask1Top34q', 'ask1Top35q', 'ask1Top36q',\n",
    "       'ask1Top37q', 'ask1Top38q', 'ask1Top39q', 'ask1Top40q',\n",
    "       'ask1Top41q', 'ask1Top42q', 'ask1Top43q', 'ask1Top44q',\n",
    "       'ask1Top45q', 'ask1Top46q', 'ask1Top47q', 'ask1Top48q',\n",
    "       'ask1Top49q', 'ask1Top50q']\n",
    "    SH = SH.fillna(0)\n",
    "#     SH[\"p1\"] = SH[\"bid1p\"] + SH[\"ask1p\"]\n",
    "#     tt = SH[(SH[\"cum_volume\"] > 0) & (SH[\"time\"] < 145700000000)].groupby(\"skey\")['p1'].min()\n",
    "#     SH.drop(\"p1\", axis=1, inplace=True)\n",
    "#     try:\n",
    "#         assert(tt[tt == 0].shape[0] == 0)\n",
    "#     except:\n",
    "#         display(tt[tt == 0])\n",
    "#     SH = SH[~((SH[\"bid1p\"] == 0) & (SH[\"ask1p\"] == 0))]\n",
    "    SH[\"ordering\"] = SH.groupby(\"skey\").cumcount()\n",
    "    SH[\"ordering\"] = SH[\"ordering\"] + 1\n",
    "    \n",
    "    SH[\"has_missing\"] = 0\n",
    "    \n",
    "    for col in [\"skey\", \"date\", \"cum_trades_cnt\", \"total_bid_orders\",\n",
    "        'total_ask_orders', 'total_bid_levels', 'total_ask_levels', 'cum_canceled_buy_orders','cum_canceled_sell_orders',\n",
    "            \"ordering\", 'bid_trade_max_duration', 'ask_trade_max_duration','has_missing']:\n",
    "        SH[col] = SH[col].astype('int32')\n",
    "    \n",
    "#     for cols in [\"prev_close\", 'open', \"high\", \"low\", \"close\", 'bid10p','bid9p','bid8p','bid7p','bid6p','bid5p','bid4p','bid3p',\n",
    "#              'bid2p','bid1p','ask1p','ask2p','ask3p','ask4p','ask5p','ask6p','ask7p','ask8p','ask9p','ask10p']:\n",
    "# #         SH[cols] = SH[cols].apply(lambda x: round(x, 2)).astype('float64')\n",
    "#         print(cols)\n",
    "#         print(SH[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "    \n",
    "#     for cols in ['cum_amount', \"cum_canceled_sell_amount\", \"cum_canceled_buy_amount\"]:\n",
    "# #         SH[cols] = SH[cols].apply(lambda x: round(x, 2)).astype('float64')\n",
    "#         print(cols)\n",
    "#         print(SH[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "        \n",
    "    for cols in ['total_bid_vwap', \"total_ask_vwap\"]:\n",
    "#         print(cols)\n",
    "#         print(SH[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "        SH[cols] = SH[cols].apply(lambda x: round(x, 3))\n",
    "        \n",
    "   \n",
    "    assert(sum(SH[SH[\"open\"] != 0].groupby(\"skey\")[\"open\"].nunique() != 1) == 0)\n",
    "    assert(sum(SH[SH[\"prev_close\"] != 0].groupby(\"skey\")[\"prev_close\"].nunique() != 1) == 0)\n",
    "    SH[\"prev_close\"] = np.where(SH[\"time\"] >= 91500000000, SH.groupby(\"skey\")[\"prev_close\"].transform(\"max\"), SH[\"prev_close\"]) \n",
    "    SH[\"open\"] = np.where(SH[\"cum_volume\"] > 0, SH.groupby(\"skey\")[\"open\"].transform(\"max\"), SH[\"open\"])\n",
    "    assert(sum(SH[SH[\"open\"] != 0].groupby(\"skey\")[\"open\"].nunique() != 1) == 0)\n",
    "    assert(sum(SH[SH[\"prev_close\"] != 0].groupby(\"skey\")[\"prev_close\"].nunique() != 1) == 0)\n",
    "    assert(SH[SH[\"cum_volume\"] > 0][\"open\"].min() > 0)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    # check 1\n",
    "    startTm = datetime.datetime.now()\n",
    "    da_te = str(SH[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    db1[\"ID\"] = db1[\"ID\"].str[2:].astype(int) + 1000000\n",
    "    db1[\"date\"] = (db1[\"date\"].str[:4] + db1[\"date\"].str[5:7] + db1[\"date\"].str[8:]).astype(int)\n",
    "    SH[\"cum_max\"] = SH.groupby(\"skey\")[\"cum_volume\"].transform(max)\n",
    "    s2 = SH[SH[\"cum_volume\"] == SH[\"cum_max\"]].groupby(\"skey\").first().reset_index()\n",
    "    dd = SH[SH[\"cum_volume\"] == SH[\"cum_max\"]].groupby(\"skey\")[\"time\"].first().reset_index()\n",
    "    SH.drop(\"cum_max\", axis=1, inplace=True)\n",
    "    s2 = s2.rename(columns={\"skey\": \"ID\", 'open':\"d_open\", \"prev_close\":\"d_yclose\",\"high\":\"d_high\", \"low\":\"d_low\", \"close\":\"d_close\", \"cum_volume\":\"d_volume\", \"cum_amount\":\"d_amount\"})\n",
    "    if SH[\"date\"].iloc[0] < 20180820:\n",
    "        s2[\"auction\"] = 0\n",
    "    else:\n",
    "        dd[\"auction\"] = np.where(dd[\"time\"]<=145700000000, 0, 1)\n",
    "        dd = dd.rename(columns={\"skey\": \"ID\"})\n",
    "        s2 = pd.merge(s2, dd[[\"ID\", \"auction\"]], on=\"ID\")\n",
    "    s2 = s2[[\"ID\", \"date\", \"d_open\", \"d_yclose\", \"d_high\", \"d_low\", \"d_close\", \"d_volume\", \"d_amount\", \"auction\"]]\n",
    "    re = pd.merge(db1, s2, on=[\"ID\", \"date\", \"d_open\", \"d_yclose\",\"d_high\", \"d_low\", \"d_volume\"], how=\"outer\")\n",
    "    try:\n",
    "        assert(sum(re[\"d_amount_y\"].isnull()) == 0)\n",
    "    except:\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(re[re[\"d_amount_y\"].isnull()])\n",
    "        wr_ong += [re[re[\"d_amount_y\"].isnull()]]\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    # check 2\n",
    "    # first part\n",
    "    startTm = datetime.datetime.now()\n",
    "    date = pd.DataFrame(pd.date_range(start='2019-06-10 08:30:00', end='2019-06-10 18:00:00', freq='s'), columns=[\"Orig\"])\n",
    "    date[\"time\"] = date[\"Orig\"].apply(lambda x: int(x.strftime(\"%H%M%S\"))*1000)\n",
    "    date[\"group\"] = date[\"time\"]//10000\n",
    "    SH[\"group\"] = SH[\"time\"]//10000000\n",
    "    gl = date[((date[\"time\"] >= 93000000) & (date[\"time\"] <= 113000000))|((date[\"time\"] >= 130000000) & (date[\"time\"] <= 150000000))][\"group\"].unique()\n",
    "    l = set(gl) - set(SH[\"group\"].unique())\n",
    "    SH[\"has_missing1\"] = 0 \n",
    "    if len(l) != 0:\n",
    "        print(\"massive missing\")\n",
    "        print(l)\n",
    "        SH[\"order\"] = SH.groupby([\"skey\", \"time\"]).cumcount()\n",
    "        for i in l:\n",
    "            SH[\"t\"] = SH[SH[\"group\"] > i].groupby(\"StockID\")[\"time\"].transform(\"min\")\n",
    "            SH[\"has_missing1\"] = np.where((SH[\"time\"] == SH[\"t\"]) & (SH[\"order\"] == 0), 1, 0)\n",
    "        SH.drop([\"order\", \"t\", \"group\"], axis=1, inplace=True)   \n",
    "    else:\n",
    "        print(\"no massive missing\")\n",
    "        SH.drop([\"group\"], axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # second part\n",
    "\n",
    "    SH[\"time_interval\"] = SH.groupby(\"skey\")[\"datetime\"].apply(lambda x: x - x.shift(1))\n",
    "    SH[\"time_interval\"] = SH[\"time_interval\"].apply(lambda x: x.seconds)\n",
    "    SH[\"tn_update\"] = SH.groupby(\"skey\")[\"cum_trades_cnt\"].apply(lambda x: x-x.shift(1))\n",
    "\n",
    "    f1 = SH[(SH[\"time\"] >= 93000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "    f1 = f1.rename(columns={\"time\": \"time1\"})\n",
    "    f2 = SH[(SH[\"time\"] >= 130000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "    f2 = f2.rename(columns={\"time\": \"time2\"})\n",
    "    f3 = SH[(SH[\"time\"] >= 150000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "    f3 = f3.rename(columns={\"time\": \"time3\"})\n",
    "    SH = pd.merge(SH, f1, on=\"skey\", how=\"left\")\n",
    "    del f1\n",
    "    SH = pd.merge(SH, f2, on=\"skey\", how=\"left\")\n",
    "    del f2\n",
    "    SH = pd.merge(SH, f3, on=\"skey\", how=\"left\")\n",
    "    del f3\n",
    "    p99 = SH[(SH[\"time\"] > 93000000000) & (SH[\"time\"] < 145700000000) & (SH[\"time\"] != SH[\"time2\"]) & (SH[\"tn_update\"] != 0)]\\\n",
    "    .groupby(\"skey\")[\"tn_update\"].apply(lambda x: x.describe([0.99])[\"99%\"]).reset_index()\n",
    "    p99 = p99.rename(columns={\"tn_update\":\"99%\"})\n",
    "    SH = pd.merge(SH, p99, on=\"skey\", how=\"left\")\n",
    "\n",
    "    SH[\"has_missing2\"] = 0\n",
    "    SH[\"has_missing2\"] = np.where((SH[\"time_interval\"] > 60) & (SH[\"tn_update\"] > SH[\"99%\"]) & \n",
    "         (SH[\"time\"] > SH[\"time1\"]) & (SH[\"time\"] != SH[\"time2\"]) & (SH[\"time\"] != SH[\"time3\"]) & (SH[\"time\"] != 100000000000), 1, 0)\n",
    "    SH.drop([\"time_interval\", \"tn_update\", \"time1\", \"time2\", \"time3\", \"99%\"], axis=1, inplace=True) \n",
    "\n",
    "    SH[\"has_missing\"] = np.where((SH[\"has_missing1\"] == 1) | (SH[\"has_missing2\"] == 1), 1, 0)\n",
    "    SH.drop([\"has_missing1\", \"has_missing2\"], axis=1, inplace=True) \n",
    "    if SH[SH[\"has_missing\"] == 1].shape[0] != 0:\n",
    "        print(\"has missing!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(SH[SH[\"has_missing\"] == 1].shape[0])\n",
    "        mi_ss += [SH[SH[\"has_missing\"] == 1]]\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"has_missing\"] = SH[\"has_missing\"].astype('int32')\n",
    "    SH = SH[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ordering\", \"has_missing\", \"cum_trades_cnt\", \"cum_volume\", \"cum_amount\", \"prev_close\",\n",
    "                            \"open\", \"high\", \"low\", \"close\", 'bid10p','bid9p','bid8p','bid7p','bid6p','bid5p','bid4p','bid3p','bid2p','bid1p',\n",
    "                            'ask1p','ask2p','ask3p','ask4p','ask5p','ask6p','ask7p','ask8p','ask9p','ask10p', 'bid10q','bid9q','bid8q',\n",
    "                             'bid7q','bid6q','bid5q','bid4q','bid3q','bid2q','bid1q', 'ask1q','ask2q','ask3q','ask4q','ask5q','ask6q',\n",
    "                             'ask7q','ask8q','ask9q','ask10q', 'bid10n', 'bid9n', 'bid8n', 'bid7n', 'bid6n', 'bid5n', 'bid4n', 'bid3n', 'bid2n', 'bid1n', \n",
    "                             'ask1n', 'ask2n', 'ask3n', 'ask4n', 'ask5n', 'ask6n','ask7n', 'ask8n', 'ask9n', 'ask10n','bid1Top1q','bid1Top2q','bid1Top3q','bid1Top4q','bid1Top5q','bid1Top6q',\n",
    "        'bid1Top7q','bid1Top8q','bid1Top9q','bid1Top10q','bid1Top11q','bid1Top12q','bid1Top13q','bid1Top14q','bid1Top15q','bid1Top16q','bid1Top17q','bid1Top18q',\n",
    "        'bid1Top19q','bid1Top20q','bid1Top21q','bid1Top22q','bid1Top23q','bid1Top24q','bid1Top25q','bid1Top26q','bid1Top27q','bid1Top28q','bid1Top29q',\n",
    "        'bid1Top30q','bid1Top31q','bid1Top32q','bid1Top33q','bid1Top34q','bid1Top35q','bid1Top36q','bid1Top37q','bid1Top38q','bid1Top39q','bid1Top40q',\n",
    "        'bid1Top41q','bid1Top42q','bid1Top43q','bid1Top44q','bid1Top45q','bid1Top46q','bid1Top47q','bid1Top48q','bid1Top49q','bid1Top50q', 'ask1Top1q',\n",
    "        'ask1Top2q','ask1Top3q','ask1Top4q','ask1Top5q','ask1Top6q','ask1Top7q','ask1Top8q','ask1Top9q','ask1Top10q','ask1Top11q','ask1Top12q','ask1Top13q',\n",
    "        'ask1Top14q','ask1Top15q','ask1Top16q','ask1Top17q','ask1Top18q','ask1Top19q','ask1Top20q','ask1Top21q','ask1Top22q','ask1Top23q',\n",
    "        'ask1Top24q','ask1Top25q','ask1Top26q','ask1Top27q','ask1Top28q','ask1Top29q','ask1Top30q','ask1Top31q','ask1Top32q','ask1Top33q',\n",
    "        'ask1Top34q','ask1Top35q','ask1Top36q','ask1Top37q','ask1Top38q','ask1Top39q','ask1Top40q','ask1Top41q','ask1Top42q','ask1Top43q',\n",
    "        'ask1Top44q','ask1Top45q','ask1Top46q','ask1Top47q','ask1Top48q','ask1Top49q','ask1Top50q',\"total_bid_quantity\", \"total_ask_quantity\",\"total_bid_vwap\", \"total_ask_vwap\",\n",
    "        \"total_bid_orders\",'total_ask_orders','total_bid_levels', 'total_ask_levels', 'bid_trade_max_duration', 'ask_trade_max_duration', 'cum_canceled_buy_orders', 'cum_canceled_buy_volume',\n",
    "        \"cum_canceled_buy_amount\", \"cum_canceled_sell_orders\", 'cum_canceled_sell_volume',\"cum_canceled_sell_amount\"]]\n",
    "    \n",
    "    display(SH[\"date\"].iloc[0])\n",
    "    print(\"SH finished\")\n",
    "    \n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    db1 = DB(\"192.168.10.223\", database_name, user, password)\n",
    "    db1.write('md_snapshot_l2', SH)\n",
    "    \n",
    "    del SH\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "wr_ong = pd.concat(wr_ong).reset_index(drop=True)\n",
    "print(wr_ong)\n",
    "mi_ss = pd.concat(mi_ss).reset_index(drop=True)\n",
    "print(mi_ss)\n",
    "print(less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:202: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:43.048232\n",
      "0:00:28.782384\n",
      "20180423 unzip finished\n",
      "0:00:43.953246\n",
      "0:01:13.287760\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:28.661853\n",
      "0:00:34.810634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03.640222\n",
      "no massive missing\n",
      "0:01:54.125213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180423"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:50.697655\n",
      "0:00:34.006565\n",
      "20180424 unzip finished\n",
      "0:00:47.226660\n",
      "0:01:16.658144\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:33.832992\n",
      "0:00:34.206678\n",
      "0:00:03.483725\n",
      "no massive missing\n",
      "0:01:55.676140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180424"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.737197\n",
      "0:00:31.039420\n",
      "20180425 unzip finished\n",
      "0:00:44.802168\n",
      "0:01:13.510359\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:27.308113\n",
      "0:00:34.002755\n",
      "0:00:03.724592\n",
      "no massive missing\n",
      "0:02:01.153771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180425"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.990784\n",
      "0:00:31.813449\n",
      "20180426 unzip finished\n",
      "0:00:51.127694\n",
      "0:01:21.209746\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:44.508383\n",
      "0:00:33.002551\n",
      "0:00:03.444120\n",
      "no massive missing\n",
      "0:02:07.570200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180426"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.899767\n",
      "0:00:33.140664\n",
      "20180427 unzip finished\n",
      "0:00:47.286841\n",
      "0:01:18.940786\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:19.034248\n",
      "0:00:34.220756\n",
      "0:00:03.450491\n",
      "no massive missing\n",
      "0:01:54.746312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180427"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:00.083512\n",
      "0:00:32.958514\n",
      "20180502 unzip finished\n",
      "0:00:50.469099\n",
      "0:01:14.186492\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:22.095928\n",
      "0:00:33.212865\n",
      "0:00:03.478875\n",
      "no massive missing\n",
      "0:02:00.910387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180502"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:01.942460\n",
      "0:00:34.115301\n",
      "20180503 unzip finished\n",
      "0:00:53.245601\n",
      "0:01:32.518773\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:52.705542\n",
      "0:00:33.958535\n",
      "0:00:03.380190\n",
      "no massive missing\n",
      "0:01:59.264490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:54.488810\n",
      "0:00:30.770113\n",
      "20180504 unzip finished\n",
      "0:00:47.834439\n",
      "0:01:28.193593\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:17.722752\n",
      "0:00:33.908648\n",
      "0:00:03.392411\n",
      "no massive missing\n",
      "0:01:51.697423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180504"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.867692\n",
      "0:00:31.766577\n",
      "20180507 unzip finished\n",
      "0:00:48.915766\n",
      "0:01:20.633263\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:58.389446\n",
      "0:00:34.003408\n",
      "0:00:03.461007\n",
      "no massive missing\n",
      "0:01:53.859876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180507"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:05.144736\n",
      "0:00:31.790690\n",
      "20180508 unzip finished\n",
      "0:00:44.929412\n",
      "0:01:17.341225\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:45.781909\n",
      "0:00:34.784764\n",
      "0:00:03.502191\n",
      "no massive missing\n",
      "0:01:54.623792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180508"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.335193\n",
      "0:00:35.301351\n",
      "20180509 unzip finished\n",
      "0:00:48.669539\n",
      "0:01:17.376023\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:30.935817\n",
      "0:00:32.854086\n",
      "0:00:03.325224\n",
      "no massive missing\n",
      "0:01:55.384693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180509"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:01.969562\n",
      "0:00:34.548970\n",
      "20180510 unzip finished\n",
      "0:00:49.804138\n",
      "0:01:17.933028\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:43.950966\n",
      "0:00:34.354736\n",
      "0:00:03.383886\n",
      "no massive missing\n",
      "0:01:54.761583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180510"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:03.609763\n",
      "0:00:32.592007\n",
      "20180511 unzip finished\n",
      "0:00:46.748581\n",
      "0:01:17.082213\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:35.593411\n",
      "0:00:32.647511\n",
      "0:00:03.235288\n",
      "no massive missing\n",
      "0:01:51.654085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180511"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.896022\n",
      "0:00:31.961656\n",
      "20180514 unzip finished\n",
      "0:00:47.695268\n",
      "0:01:16.283818\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:22.159980\n",
      "0:00:32.805402\n",
      "0:00:03.311641\n",
      "no massive missing\n",
      "0:01:53.406227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180514"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:57.705174\n",
      "0:00:32.677145\n",
      "20180515 unzip finished\n",
      "0:00:47.237057\n",
      "0:01:13.856061\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:24.792375\n",
      "0:00:32.438889\n",
      "0:00:03.265076\n",
      "no massive missing\n",
      "0:01:57.595769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180515"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.456596\n",
      "0:00:32.400949\n",
      "20180516 unzip finished\n",
      "0:00:48.044198\n",
      "0:01:17.614323\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:46.456496\n",
      "0:00:35.883120\n",
      "0:00:03.728829\n",
      "no massive missing\n",
      "0:02:02.506526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180516"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.023317\n",
      "0:00:31.840157\n",
      "20180517 unzip finished\n",
      "0:00:46.194675\n",
      "0:01:25.156235\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:35.927950\n",
      "0:00:36.130954\n",
      "0:00:03.650649\n",
      "no massive missing\n",
      "0:02:17.519263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180517"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.821253\n",
      "0:00:32.393095\n",
      "20180518 unzip finished\n",
      "0:00:48.264484\n",
      "0:01:16.894358\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:31.139710\n",
      "0:00:35.011011\n",
      "0:00:03.589702\n",
      "no massive missing\n",
      "0:01:56.607911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180518"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.913615\n",
      "0:00:33.854615\n",
      "20180521 unzip finished\n",
      "0:00:51.457753\n",
      "0:01:21.667382\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:31.519987\n",
      "0:00:39.061013\n",
      "0:00:03.748917\n",
      "no massive missing\n",
      "0:02:06.682962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180521"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.487288\n",
      "0:00:33.336541\n",
      "20180522 unzip finished\n",
      "0:00:48.995715\n",
      "0:01:18.588336\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:00.747306\n",
      "0:00:37.087886\n",
      "0:00:03.765287\n",
      "no massive missing\n",
      "0:02:11.295929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180522"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.173686\n",
      "0:00:33.514458\n",
      "20180523 unzip finished\n",
      "0:00:48.979464\n",
      "0:01:20.487374\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:11.099312\n",
      "0:00:36.377970\n",
      "0:00:03.666964\n",
      "no massive missing\n",
      "0:02:03.164211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:54.483405\n",
      "0:00:32.502087\n",
      "20180524 unzip finished\n",
      "0:00:47.108440\n",
      "0:01:15.549758\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:20.390106\n",
      "0:00:38.000479\n",
      "0:00:03.521744\n",
      "no massive missing\n",
      "0:01:57.239517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180524"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:03.387156\n",
      "0:00:36.000151\n",
      "20180525 unzip finished\n",
      "0:00:47.035872\n",
      "0:01:21.691292\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:08.758216\n",
      "0:00:38.026704\n",
      "0:00:03.829930\n",
      "no massive missing\n",
      "0:02:00.531022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180525"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.784423\n",
      "0:00:34.530218\n",
      "20180528 unzip finished\n",
      "0:00:47.288608\n",
      "0:01:24.429398\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:05.681552\n",
      "0:00:36.122152\n",
      "0:00:03.668984\n",
      "no massive missing\n",
      "0:01:59.862336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180528"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:57.507157\n",
      "0:00:33.639221\n",
      "20180529 unzip finished\n",
      "0:00:48.960497\n",
      "0:01:20.969378\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:40.073379\n",
      "0:00:34.036595\n",
      "0:00:03.472530\n",
      "no massive missing\n",
      "0:02:03.819735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180529"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:04.603246\n",
      "0:00:34.478177\n",
      "20180530 unzip finished\n",
      "0:00:52.054571\n",
      "0:01:33.624094\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:52.882060\n",
      "0:00:37.615705\n",
      "0:00:03.553744\n",
      "no massive missing\n",
      "0:02:01.002646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180530"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:04.168291\n",
      "0:00:33.917263\n",
      "20180531 unzip finished\n",
      "0:00:51.171873\n",
      "0:01:20.924850\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:58.820799\n",
      "0:00:35.207967\n",
      "0:00:03.520866\n",
      "no massive missing\n",
      "0:01:59.985471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180531"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.102108\n",
      "0:00:33.697653\n",
      "20180601 unzip finished\n",
      "0:00:46.889187\n",
      "0:01:21.064006\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:03.450824\n",
      "0:00:35.722242\n",
      "0:00:03.497223\n",
      "no massive missing\n",
      "0:01:58.781501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:01.968033\n",
      "0:00:31.715605\n",
      "20180604 unzip finished\n",
      "0:00:48.956461\n",
      "0:01:16.161053\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:24.496642\n",
      "0:00:35.860320\n",
      "0:00:03.460291\n",
      "no massive missing\n",
      "0:01:55.168687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180604"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.277950\n",
      "0:00:32.073577\n",
      "20180605 unzip finished\n",
      "0:00:46.004182\n",
      "0:01:19.256352\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:24.572202\n",
      "0:00:35.891467\n",
      "0:00:03.454731\n",
      "no massive missing\n",
      "0:01:59.505221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180605"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:04.495578\n",
      "0:00:31.869654\n",
      "20180606 unzip finished\n",
      "0:00:48.448127\n",
      "0:01:18.077061\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:40.106010\n",
      "0:00:34.102661\n",
      "0:00:03.453370\n",
      "no massive missing\n",
      "0:01:58.241745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180606"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:03.886238\n",
      "0:00:33.127873\n",
      "20180607 unzip finished\n",
      "0:00:47.834240\n",
      "0:01:18.589524\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:28.438282\n",
      "0:00:32.940046\n",
      "0:00:03.384412\n",
      "no massive missing\n",
      "0:01:53.985585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:08.345878\n",
      "0:00:36.702798\n",
      "20180608 unzip finished\n",
      "0:00:50.930827\n",
      "0:01:22.692651\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:56.825598\n",
      "0:00:35.012305\n",
      "0:00:03.486939\n",
      "no massive missing\n",
      "0:01:59.479406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180608"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.797721\n",
      "0:00:29.941311\n",
      "20180611 unzip finished\n",
      "0:00:43.280949\n",
      "0:01:14.890357\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:14.838773\n",
      "0:00:33.734759\n",
      "0:00:03.394619\n",
      "no massive missing\n",
      "0:02:00.504899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180611"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:57.802100\n",
      "0:00:31.594779\n",
      "20180612 unzip finished\n",
      "0:00:43.552413\n",
      "0:01:15.037350\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:15.135490\n",
      "0:00:33.483467\n",
      "0:00:03.362418\n",
      "no massive missing\n",
      "0:01:58.639306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180612"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:08.345793\n",
      "0:00:30.534716\n",
      "20180613 unzip finished\n",
      "0:00:46.539142\n",
      "0:01:13.676903\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:08.462218\n",
      "0:00:33.715444\n",
      "0:00:04.464895\n",
      "no massive missing\n",
      "0:01:50.945176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:00.730709\n",
      "0:00:32.121219\n",
      "20180614 unzip finished\n",
      "0:00:44.484710\n",
      "0:01:17.219937\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:36.251754\n",
      "0:00:37.829020\n",
      "0:00:03.416571\n",
      "no massive missing\n",
      "0:01:58.135997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180614"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:00.917200\n",
      "0:00:33.573273\n",
      "20180615 unzip finished\n",
      "0:00:46.737586\n",
      "0:01:21.769966\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:42.404340\n",
      "0:00:36.743238\n",
      "0:00:03.532170\n",
      "no massive missing\n",
      "0:02:06.192142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180615"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.705293\n",
      "0:00:36.145045\n",
      "20180619 unzip finished\n",
      "0:00:49.547579\n",
      "0:01:28.500245\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:24.271900\n",
      "0:00:39.449493\n",
      "0:00:03.815626\n",
      "no massive missing\n",
      "0:02:03.161872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:16.324905\n",
      "0:00:32.916496\n",
      "20180620 unzip finished\n",
      "0:00:46.350243\n",
      "0:01:17.599243\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:39.376480\n",
      "0:00:35.603636\n",
      "0:00:03.660988\n",
      "no massive missing\n",
      "0:01:57.692766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180620"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.773985\n",
      "0:00:33.394282\n",
      "20180621 unzip finished\n",
      "0:00:48.924268\n",
      "0:01:17.430065\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:27.231051\n",
      "0:00:34.035377\n",
      "0:00:03.471303\n",
      "no massive missing\n",
      "0:02:06.666182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180621"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:02.263609\n",
      "0:00:30.766807\n",
      "20180622 unzip finished\n",
      "0:00:45.484886\n",
      "0:01:15.038027\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:10.652236\n",
      "0:00:33.431648\n",
      "0:00:03.449407\n",
      "no massive missing\n",
      "0:02:01.700764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180622"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:02.358315\n",
      "0:00:28.981368\n",
      "20180625 unzip finished\n",
      "0:00:43.153904\n",
      "0:01:08.329659\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:39.338689\n",
      "0:00:30.397740\n",
      "0:00:03.173119\n",
      "no massive missing\n",
      "0:01:46.904750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:47.373372\n",
      "0:00:32.093665\n",
      "20180626 unzip finished\n",
      "0:00:45.397671\n",
      "0:01:12.175884\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:15.107104\n",
      "0:00:32.882747\n",
      "0:00:03.280485\n",
      "no massive missing\n",
      "0:02:02.103959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180626"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:57.249607\n",
      "0:00:30.997498\n",
      "20180627 unzip finished\n",
      "0:00:46.235524\n",
      "0:01:23.726682\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:05.053814\n",
      "0:00:34.022593\n",
      "0:00:03.388337\n",
      "no massive missing\n",
      "0:01:55.771571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180627"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.414146\n",
      "0:00:30.420975\n",
      "20180628 unzip finished\n",
      "0:00:42.217642\n",
      "0:01:09.024694\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:49.351258\n",
      "0:00:33.532260\n",
      "0:00:03.522375\n",
      "no massive missing\n",
      "0:01:55.580515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180628"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.654906\n",
      "0:00:33.094136\n",
      "20180629 unzip finished\n",
      "0:00:49.809762\n",
      "0:01:25.464953\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:36.072314\n",
      "0:00:38.223214\n",
      "0:00:05.897306\n",
      "no massive missing\n",
      "0:02:02.105958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180629"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:10.038580\n",
      "0:00:32.225682\n",
      "20180702 unzip finished\n",
      "0:00:47.991254\n",
      "0:01:16.152204\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:11.073375\n",
      "0:00:37.222552\n",
      "0:00:03.558953\n",
      "no massive missing\n",
      "0:01:59.924328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:03.296196\n",
      "0:00:32.004878\n",
      "20180703 unzip finished\n",
      "0:00:45.994525\n",
      "0:01:13.573817\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:20.904180\n",
      "0:00:35.665089\n",
      "0:00:03.578207\n",
      "no massive missing\n",
      "0:02:03.961051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180703"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:09.866262\n",
      "0:00:29.921431\n",
      "20180704 unzip finished\n",
      "0:00:44.948219\n",
      "0:01:14.743500\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:04.560713\n",
      "0:00:34.799020\n",
      "0:00:03.466397\n",
      "no massive missing\n",
      "0:01:57.592562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180704"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.739446\n",
      "0:00:30.466022\n",
      "20180705 unzip finished\n",
      "0:00:48.139210\n",
      "0:01:11.379145\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:57.851223\n",
      "0:00:34.586192\n",
      "0:00:03.492831\n",
      "no massive missing\n",
      "0:01:54.639837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180705"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:09.044332\n",
      "0:00:34.003448\n",
      "20180706 unzip finished\n",
      "0:00:50.821125\n",
      "0:01:25.762906\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:26.593136\n",
      "0:00:37.272204\n",
      "0:00:03.621323\n",
      "no massive missing\n",
      "0:01:59.385485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180706"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:06.137985\n",
      "0:00:30.778424\n",
      "20180709 unzip finished\n",
      "0:00:43.259638\n",
      "0:01:11.249636\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:04.340524\n",
      "0:00:32.195743\n",
      "0:00:03.495299\n",
      "no massive missing\n",
      "0:01:52.243210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180709"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:46.434039\n",
      "0:00:29.234149\n",
      "20180710 unzip finished\n",
      "0:00:43.016665\n",
      "0:01:10.459798\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:10.545825\n",
      "0:00:34.536381\n",
      "0:00:03.403830\n",
      "no massive missing\n",
      "0:01:54.319919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180710"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.033433\n",
      "0:00:30.086954\n",
      "20180711 unzip finished\n",
      "0:00:44.268761\n",
      "0:01:15.090288\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:15.878320\n",
      "0:00:34.024765\n",
      "0:00:03.436716\n",
      "no massive missing\n",
      "0:01:56.205083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180711"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.537304\n",
      "0:00:33.667391\n",
      "20180712 unzip finished\n",
      "0:00:48.396974\n",
      "0:01:15.358329\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:39.118339\n",
      "0:00:36.499809\n",
      "0:00:03.471947\n",
      "no massive missing\n",
      "0:02:03.800002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:50.373813\n",
      "0:00:29.506756\n",
      "20180713 unzip finished\n",
      "0:00:44.601745\n",
      "0:01:13.585070\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:55.743367\n",
      "0:00:32.425938\n",
      "0:00:03.317331\n",
      "no massive missing\n",
      "0:01:56.142917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180713"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.925572\n",
      "0:00:29.853744\n",
      "20180716 unzip finished\n",
      "0:00:45.031126\n",
      "0:01:13.972421\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:50.421483\n",
      "0:00:32.354876\n",
      "0:00:03.320020\n",
      "no massive missing\n",
      "0:01:48.352534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180716"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:54.415073\n",
      "0:00:30.298469\n",
      "20180717 unzip finished\n",
      "0:00:46.666812\n",
      "0:01:13.355055\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:58.663004\n",
      "0:00:33.215377\n",
      "0:00:03.414952\n",
      "no massive missing\n",
      "0:01:53.375768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180717"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:47.853433\n",
      "0:00:31.750563\n",
      "20180718 unzip finished\n",
      "0:00:47.353810\n",
      "0:01:14.605787\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:19.987516\n",
      "0:00:34.495608\n",
      "0:00:03.368071\n",
      "no massive missing\n",
      "0:01:53.945453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180718"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.564930\n",
      "0:00:30.357099\n",
      "20180719 unzip finished\n",
      "0:00:43.667549\n",
      "0:01:14.410078\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:11.476109\n",
      "0:00:33.585001\n",
      "0:00:03.423146\n",
      "no massive missing\n",
      "0:01:50.745942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180719"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.592050\n",
      "0:00:32.807224\n",
      "20180720 unzip finished\n",
      "0:00:44.359630\n",
      "0:01:16.353659\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:15.416565\n",
      "0:00:33.366332\n",
      "0:00:03.343372\n",
      "no massive missing\n",
      "0:01:50.184090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180720"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.787720\n",
      "0:00:32.979636\n",
      "20180723 unzip finished\n",
      "0:00:45.421110\n",
      "0:01:16.068456\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:39.134269\n",
      "0:00:34.024298\n",
      "0:00:03.324183\n",
      "no massive missing\n",
      "0:01:55.200521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180723"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:03.437123\n",
      "0:00:35.416212\n",
      "20180724 unzip finished\n",
      "0:00:49.949203\n",
      "0:01:25.124565\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:16.129039\n",
      "0:00:35.558959\n",
      "0:00:03.537369\n",
      "no massive missing\n",
      "0:02:03.002637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.348652\n",
      "0:00:32.834297\n",
      "20180725 unzip finished\n",
      "0:00:44.714233\n",
      "0:01:17.948013\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:53.057911\n",
      "0:00:35.399489\n",
      "0:00:03.554621\n",
      "no massive missing\n",
      "0:01:56.374470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180725"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:52.043883\n",
      "0:00:33.382226\n",
      "20180726 unzip finished\n",
      "0:00:46.503608\n",
      "0:01:20.437002\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:50.985365\n",
      "0:00:36.922867\n",
      "0:00:03.436379\n",
      "no massive missing\n",
      "0:02:01.370412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180726"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:00.795327\n",
      "0:00:31.028956\n",
      "20180727 unzip finished\n",
      "0:00:47.578255\n",
      "0:01:25.752874\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:15.102284\n",
      "0:00:34.383958\n",
      "0:00:03.535372\n",
      "no massive missing\n",
      "0:02:03.712239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180727"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:57.880622\n",
      "0:00:32.348700\n",
      "20180730 unzip finished\n",
      "0:00:45.862300\n",
      "0:01:17.906572\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:40.745503\n",
      "0:00:35.017312\n",
      "0:00:03.683680\n",
      "no massive missing\n",
      "0:01:59.414387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180730"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.603926\n",
      "0:00:30.318357\n",
      "20180731 unzip finished\n",
      "0:00:42.388836\n",
      "0:01:12.840136\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:06.779199\n",
      "0:00:32.154077\n",
      "0:00:03.249911\n",
      "no massive missing\n",
      "0:01:48.317832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180731"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:50.496576\n",
      "0:00:32.645259\n",
      "20180801 unzip finished\n",
      "0:00:46.611631\n",
      "0:01:16.245331\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:43.337073\n",
      "0:00:34.574334\n",
      "0:00:03.406463\n",
      "no massive missing\n",
      "0:01:56.599524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180801"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.018630\n",
      "0:00:35.359673\n",
      "20180802 unzip finished\n",
      "0:00:49.864980\n",
      "0:01:31.916134\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:01.373034\n",
      "0:00:38.925676\n",
      "0:00:03.642102\n",
      "no massive missing\n",
      "0:02:00.157609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180802"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:52.323834\n",
      "0:00:29.657391\n",
      "20180803 unzip finished\n",
      "0:00:40.782818\n",
      "0:01:20.495786\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:53.611875\n",
      "0:00:33.972255\n",
      "0:00:03.561446\n",
      "no massive missing\n",
      "0:01:50.411482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180803"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:57.858532\n",
      "0:00:31.077219\n",
      "20180806 unzip finished\n",
      "0:00:40.417504\n",
      "0:01:11.454201\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:52.009166\n",
      "0:00:35.501966\n",
      "0:00:03.444978\n",
      "no massive missing\n",
      "0:01:54.541356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180806"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:03.753624\n",
      "0:00:31.253747\n",
      "20180807 unzip finished\n",
      "0:00:44.257286\n",
      "0:01:16.992327\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:42.846704\n",
      "0:00:33.449282\n",
      "0:00:03.393543\n",
      "no massive missing\n",
      "0:01:57.683548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:50.638395\n",
      "0:00:31.678613\n",
      "20180808 unzip finished\n",
      "0:00:41.408558\n",
      "0:01:11.670838\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:00.935962\n",
      "0:00:34.018579\n",
      "0:00:03.389174\n",
      "no massive missing\n",
      "0:01:54.046893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180808"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.812016\n",
      "0:00:33.679183\n",
      "20180809 unzip finished\n",
      "0:00:46.931519\n",
      "0:01:19.710615\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:52.514829\n",
      "0:00:42.942047\n",
      "0:00:03.568556\n",
      "no massive missing\n",
      "0:02:06.297119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180809"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.879354\n",
      "0:00:28.562827\n",
      "20180810 unzip finished\n",
      "0:00:42.340792\n",
      "0:01:11.973312\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:49.686464\n",
      "0:00:33.473194\n",
      "0:00:03.462886\n",
      "no massive missing\n",
      "0:01:52.427036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180810"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.045679\n",
      "0:00:31.395862\n",
      "20180813 unzip finished\n",
      "0:00:47.151686\n",
      "0:01:15.311985\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:08.274463\n",
      "0:00:33.996549\n",
      "0:00:03.338223\n",
      "no massive missing\n",
      "0:01:55.289434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:47.576688\n",
      "0:00:30.933757\n",
      "20180814 unzip finished\n",
      "0:00:42.226392\n",
      "0:01:19.134818\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:35.989391\n",
      "0:00:31.929475\n",
      "0:00:03.177058\n",
      "no massive missing\n",
      "0:01:51.768985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180814"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.982486\n",
      "0:00:29.866482\n",
      "20180815 unzip finished\n",
      "0:00:39.192368\n",
      "0:01:11.898325\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:55.078378\n",
      "0:00:33.418926\n",
      "0:00:03.430008\n",
      "no massive missing\n",
      "0:01:51.031167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180815"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:05.623329\n",
      "0:00:29.536846\n",
      "20180816 unzip finished\n",
      "0:00:41.854464\n",
      "0:01:11.055968\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:33.757636\n",
      "0:00:34.218918\n",
      "0:00:05.432803\n",
      "no massive missing\n",
      "0:01:58.977184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180816"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.328663\n",
      "0:00:32.045838\n",
      "20180817 unzip finished\n",
      "0:00:43.901478\n",
      "0:01:09.132834\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:41.875696\n",
      "0:00:34.214792\n",
      "0:00:03.398446\n",
      "no massive missing\n",
      "0:01:58.462988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.993447\n",
      "0:00:30.280825\n",
      "20180820 unzip finished\n",
      "0:00:40.983336\n",
      "0:01:09.951525\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:58.461428\n",
      "0:00:33.144350\n",
      "0:00:03.719296\n",
      "massive missing\n",
      "{11300}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'StockID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-67ed627523d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mSH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"order\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skey\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mSH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"group\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"StockID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0mSH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_missing1\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"order\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mSH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"order\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"group\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\u001b[0m\n\u001b[1;32m   5808\u001b[0m             \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5809\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5810\u001b[0;31m             \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5811\u001b[0m         )\n\u001b[1;32m   5812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0mmutated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[1;32m    596\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'StockID'"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "readPath = '/home/work516/day_stock/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SH' for i in dataPathLs])]]\n",
    "db = pd.DataFrame()\n",
    "for p in dataPathLs:\n",
    "    dayData = pd.read_csv(p, compression='gzip')\n",
    "    db = pd.concat([db, dayData])\n",
    "print(datetime.datetime.now() - startTm)\n",
    "\n",
    "year = \"2018\"\n",
    "startDate = '20180423'\n",
    "endDate = '20181231'\n",
    "readPath = '/mnt/usb/data/' + year + '/***/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i).split('_')[0] for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "date_list = pd.read_csv(\"/home/work516/KR_upload_code/trading_days.csv\")\n",
    "wr_ong = []\n",
    "mi_ss = []\n",
    "less = []\n",
    "\n",
    "for data in dataPathLs:\n",
    "    if len(np.array(glob.glob(data + '/SH/***'))) == 0:\n",
    "        if int(os.path.basename(data)) not in date_list[\"Date\"].values:\n",
    "            continue\n",
    "        else:\n",
    "            print(os.path.basename(data) + \" less data!!!!!!!!!!!!!!!!!\")\n",
    "            less.append(data)\n",
    "            continue\n",
    "    startTm = datetime.datetime.now()\n",
    "    date = os.path.basename(data)\n",
    "    rar_path = data + '/SH/snapshot.7z'\n",
    "    path = '/mnt/e/unzip_data/2018/SH'\n",
    "    path1 = path + '/' + date\n",
    "    un_path = path1\n",
    "    cmd = '7za x {} -o{}'.format(rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    print(date + ' unzip finished')\n",
    "\n",
    "    readPath = path1 + '/snapshot/***2/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[((dateLs >= 600000) & (dateLs <= 700000))]\n",
    "    SH = []\n",
    "    ll = []\n",
    "    startTm = datetime.datetime.now()\n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i, usecols = [0,1,3,5,7,9,10,11,15,17,18,19,20,21,22,23,25,26,28,29,30,31,32,33,37,39,40,41,\n",
    "                                          42,46,47,49,50])\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"StockID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        SH += [df]\n",
    "    del df\n",
    "    SH = pd.concat(SH).reset_index(drop=True)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"skey\"] = SH[\"StockID\"] + 1000000\n",
    "    SH.drop([\"StockID\"],axis=1,inplace=True)\n",
    "    SH[\"date\"] = int(SH[\"QuotTime\"].iloc[0]//1000000000)\n",
    "    SH[\"time\"] = (SH['QuotTime'] - int(SH['QuotTime'].iloc[0]//1000000000*1000000000)).astype(np.int64) * 1000\n",
    "    SH[\"clockAtArrival\"] = SH[\"QuotTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    SH.drop([\"QuotTime\"],axis=1,inplace=True)\n",
    "    SH['datetime'] = SH[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"BidPrice\"] = SH[\"BidPrice\"].apply(lambda x: [float(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferPrice\"] = SH[\"OfferPrice\"].apply(lambda x: [float(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"BidOrderQty\"] = SH[\"BidOrderQty\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferOrderQty\"] = SH[\"OfferOrderQty\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"BidNumOrders\"] = SH[\"BidNumOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferNumOrders\"] = SH[\"OfferNumOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        SH[\"bid\" + str(i) + 'p'] = SH[\"BidPrice\"].apply(lambda x: x[i-1],2)\n",
    "    SH.drop([\"BidPrice\"],axis=1,inplace=True)\n",
    "    print(\"1\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"ask\" + str(i) + 'p'] = SH[\"OfferPrice\"].apply(lambda x: x[i-1],2)\n",
    "    SH.drop([\"OfferPrice\"],axis=1,inplace=True)\n",
    "    print(\"2\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"bid\" + str(i) + 'q'] = SH[\"BidOrderQty\"].apply(lambda x: x[i-1])\n",
    "    SH.drop([\"BidOrderQty\"],axis=1,inplace=True)\n",
    "    print(\"3\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"ask\" + str(i) + 'q'] = SH[\"OfferOrderQty\"].apply(lambda x: x[i-1])\n",
    "    SH.drop([\"OfferOrderQty\"],axis=1,inplace=True)\n",
    "    print(\"4\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"bid\" + str(i) + 'n'] = SH[\"BidNumOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"bid\" + str(i) + 'n'] = SH[\"bid\" + str(i) + 'n'].astype('int32')\n",
    "    SH.drop([\"BidNumOrders\"],axis=1,inplace=True)\n",
    "    print(\"5\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"ask\" + str(i) + 'n'] = SH[\"OfferNumOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"ask\" + str(i) + 'n'] = SH[\"ask\" + str(i) + 'n'].astype('int32') \n",
    "    SH.drop([\"OfferNumOrders\"],axis=1,inplace=True)\n",
    "    print(\"6\")\n",
    "    \n",
    "    SH[\"BidOrders\"] = SH[\"BidOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferOrders\"] = SH[\"OfferOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "\n",
    "    for i in range(1, 51):\n",
    "        SH[\"bid1Top\" + str(i) + 'q'] = SH[\"BidOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"bid1Top\" + str(i) + 'q'] = SH[\"bid1Top\" + str(i) + 'q'].astype('int32') \n",
    "    SH.drop([\"BidOrders\"],axis=1,inplace=True)\n",
    "    print(\"7\")\n",
    "    \n",
    "    for i in range(1, 51):\n",
    "        SH[\"ask1Top\" + str(i) + 'q'] = SH[\"OfferOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"ask1Top\" + str(i) + 'q'] = SH[\"ask1Top\" + str(i) + 'q'].astype('int32') \n",
    "    SH.drop([\"OfferOrders\"],axis=1,inplace=True)\n",
    "    print(\"8\")\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH.columns = ['cum_trades_cnt', 'ask_trade_max_duration', 'total_bid_orders',\n",
    "       'cum_canceled_sell_amount', 'total_ask_quantity', 'cum_canceled_buy_orders',\n",
    "       'total_ask_vwap', 'cum_canceled_sell_volume', 'cum_volume', 'open',\n",
    "       'high', 'prev_close', 'low', 'total_bid_vwap',\n",
    "       'cum_canceled_sell_orders', 'total_ask_orders', 'total_ask_levels',\n",
    "       'total_bid_quantity', 'cum_canceled_buy_volume', 'bid_trade_max_duration',\n",
    "       'total_bid_levels', 'close', 'cum_amount', 'cum_canceled_buy_amount', 'skey', 'date', 'time', 'clockAtArrival',\n",
    "       'datetime', 'bid1p', 'bid2p', 'bid3p', 'bid4p', 'bid5p', 'bid6p',\n",
    "       'bid7p', 'bid8p', 'bid9p', 'bid10p', 'ask1p', 'ask2p', 'ask3p',\n",
    "       'ask4p', 'ask5p', 'ask6p', 'ask7p', 'ask8p', 'ask9p', 'ask10p',\n",
    "       'bid1q', 'bid2q', 'bid3q', 'bid4q', 'bid5q', 'bid6q', 'bid7q',\n",
    "       'bid8q', 'bid9q', 'bid10q', 'ask1q', 'ask2q', 'ask3q', 'ask4q',\n",
    "       'ask5q', 'ask6q', 'ask7q', 'ask8q', 'ask9q', 'ask10q', 'bid1n',\n",
    "       'bid2n', 'bid3n', 'bid4n', 'bid5n', 'bid6n', 'bid7n', 'bid8n',\n",
    "       'bid9n', 'bid10n', 'ask1n', 'ask2n', 'ask3n', 'ask4n', 'ask5n',\n",
    "       'ask6n', 'ask7n', 'ask8n', 'ask9n', 'ask10n', 'bid1Top1q',\n",
    "       'bid1Top2q', 'bid1Top3q', 'bid1Top4q', 'bid1Top5q', 'bid1Top6q',\n",
    "       'bid1Top7q', 'bid1Top8q', 'bid1Top9q', 'bid1Top10q', 'bid1Top11q',\n",
    "       'bid1Top12q', 'bid1Top13q', 'bid1Top14q', 'bid1Top15q',\n",
    "       'bid1Top16q', 'bid1Top17q', 'bid1Top18q', 'bid1Top19q',\n",
    "       'bid1Top20q', 'bid1Top21q', 'bid1Top22q', 'bid1Top23q',\n",
    "       'bid1Top24q', 'bid1Top25q', 'bid1Top26q', 'bid1Top27q',\n",
    "       'bid1Top28q', 'bid1Top29q', 'bid1Top30q', 'bid1Top31q',\n",
    "       'bid1Top32q', 'bid1Top33q', 'bid1Top34q', 'bid1Top35q',\n",
    "       'bid1Top36q', 'bid1Top37q', 'bid1Top38q', 'bid1Top39q',\n",
    "       'bid1Top40q', 'bid1Top41q', 'bid1Top42q', 'bid1Top43q',\n",
    "       'bid1Top44q', 'bid1Top45q', 'bid1Top46q', 'bid1Top47q',\n",
    "       'bid1Top48q', 'bid1Top49q', 'bid1Top50q', 'ask1Top1q', 'ask1Top2q',\n",
    "       'ask1Top3q', 'ask1Top4q', 'ask1Top5q', 'ask1Top6q', 'ask1Top7q',\n",
    "       'ask1Top8q', 'ask1Top9q', 'ask1Top10q', 'ask1Top11q', 'ask1Top12q',\n",
    "       'ask1Top13q', 'ask1Top14q', 'ask1Top15q', 'ask1Top16q',\n",
    "       'ask1Top17q', 'ask1Top18q', 'ask1Top19q', 'ask1Top20q',\n",
    "       'ask1Top21q', 'ask1Top22q', 'ask1Top23q', 'ask1Top24q',\n",
    "       'ask1Top25q', 'ask1Top26q', 'ask1Top27q', 'ask1Top28q',\n",
    "       'ask1Top29q', 'ask1Top30q', 'ask1Top31q', 'ask1Top32q',\n",
    "       'ask1Top33q', 'ask1Top34q', 'ask1Top35q', 'ask1Top36q',\n",
    "       'ask1Top37q', 'ask1Top38q', 'ask1Top39q', 'ask1Top40q',\n",
    "       'ask1Top41q', 'ask1Top42q', 'ask1Top43q', 'ask1Top44q',\n",
    "       'ask1Top45q', 'ask1Top46q', 'ask1Top47q', 'ask1Top48q',\n",
    "       'ask1Top49q', 'ask1Top50q']\n",
    "    SH = SH.fillna(0)\n",
    "#     SH[\"p1\"] = SH[\"bid1p\"] + SH[\"ask1p\"]\n",
    "#     tt = SH[(SH[\"cum_volume\"] > 0) & (SH[\"time\"] < 145700000000)].groupby(\"skey\")['p1'].min()\n",
    "#     SH.drop(\"p1\", axis=1, inplace=True)\n",
    "#     try:\n",
    "#         assert(tt[tt == 0].shape[0] == 0)\n",
    "#     except:\n",
    "#         display(tt[tt == 0])\n",
    "#     SH = SH[~((SH[\"bid1p\"] == 0) & (SH[\"ask1p\"] == 0))]\n",
    "    SH[\"ordering\"] = SH.groupby(\"skey\").cumcount()\n",
    "    SH[\"ordering\"] = SH[\"ordering\"] + 1\n",
    "    \n",
    "    SH[\"has_missing\"] = 0\n",
    "    \n",
    "    for col in [\"skey\", \"date\", \"cum_trades_cnt\", \"total_bid_orders\",\n",
    "        'total_ask_orders', 'total_bid_levels', 'total_ask_levels', 'cum_canceled_buy_orders','cum_canceled_sell_orders',\n",
    "            \"ordering\", 'bid_trade_max_duration', 'ask_trade_max_duration','has_missing']:\n",
    "        SH[col] = SH[col].astype('int32')\n",
    "    \n",
    "#     for cols in [\"prev_close\", 'open', \"high\", \"low\", \"close\", 'bid10p','bid9p','bid8p','bid7p','bid6p','bid5p','bid4p','bid3p',\n",
    "#              'bid2p','bid1p','ask1p','ask2p','ask3p','ask4p','ask5p','ask6p','ask7p','ask8p','ask9p','ask10p']:\n",
    "# #         SH[cols] = SH[cols].apply(lambda x: round(x, 2)).astype('float64')\n",
    "#         print(cols)\n",
    "#         print(SH[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "    \n",
    "#     for cols in ['cum_amount', \"cum_canceled_sell_amount\", \"cum_canceled_buy_amount\"]:\n",
    "# #         SH[cols] = SH[cols].apply(lambda x: round(x, 2)).astype('float64')\n",
    "#         print(cols)\n",
    "#         print(SH[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "        \n",
    "    for cols in ['total_bid_vwap', \"total_ask_vwap\"]:\n",
    "#         print(cols)\n",
    "#         print(SH[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "        SH[cols] = SH[cols].apply(lambda x: round(x, 3))\n",
    "        \n",
    "   \n",
    "    assert(sum(SH[SH[\"open\"] != 0].groupby(\"skey\")[\"open\"].nunique() != 1) == 0)\n",
    "    assert(sum(SH[SH[\"prev_close\"] != 0].groupby(\"skey\")[\"prev_close\"].nunique() != 1) == 0)\n",
    "    SH[\"prev_close\"] = np.where(SH[\"time\"] >= 91500000000, SH.groupby(\"skey\")[\"prev_close\"].transform(\"max\"), SH[\"prev_close\"]) \n",
    "    SH[\"open\"] = np.where(SH[\"cum_volume\"] > 0, SH.groupby(\"skey\")[\"open\"].transform(\"max\"), SH[\"open\"])\n",
    "    assert(sum(SH[SH[\"open\"] != 0].groupby(\"skey\")[\"open\"].nunique() != 1) == 0)\n",
    "    assert(sum(SH[SH[\"prev_close\"] != 0].groupby(\"skey\")[\"prev_close\"].nunique() != 1) == 0)\n",
    "    assert(SH[SH[\"cum_volume\"] > 0][\"open\"].min() > 0)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    # check 1\n",
    "    startTm = datetime.datetime.now()\n",
    "    da_te = str(SH[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    db1[\"ID\"] = db1[\"ID\"].str[2:].astype(int) + 1000000\n",
    "    db1[\"date\"] = (db1[\"date\"].str[:4] + db1[\"date\"].str[5:7] + db1[\"date\"].str[8:]).astype(int)\n",
    "    SH[\"cum_max\"] = SH.groupby(\"skey\")[\"cum_volume\"].transform(max)\n",
    "    s2 = SH[SH[\"cum_volume\"] == SH[\"cum_max\"]].groupby(\"skey\").first().reset_index()\n",
    "    dd = SH[SH[\"cum_volume\"] == SH[\"cum_max\"]].groupby(\"skey\")[\"time\"].first().reset_index()\n",
    "    SH.drop(\"cum_max\", axis=1, inplace=True)\n",
    "    s2 = s2.rename(columns={\"skey\": \"ID\", 'open':\"d_open\", \"prev_close\":\"d_yclose\",\"high\":\"d_high\", \"low\":\"d_low\", \"close\":\"d_close\", \"cum_volume\":\"d_volume\", \"cum_amount\":\"d_amount\"})\n",
    "    if SH[\"date\"].iloc[0] < 20180820:\n",
    "        s2[\"auction\"] = 0\n",
    "    else:\n",
    "        dd[\"auction\"] = np.where(dd[\"time\"]<=145700000000, 0, 1)\n",
    "        dd = dd.rename(columns={\"skey\": \"ID\"})\n",
    "        s2 = pd.merge(s2, dd[[\"ID\", \"auction\"]], on=\"ID\")\n",
    "    s2 = s2[[\"ID\", \"date\", \"d_open\", \"d_yclose\", \"d_high\", \"d_low\", \"d_close\", \"d_volume\", \"d_amount\", \"auction\"]]\n",
    "    re = pd.merge(db1, s2, on=[\"ID\", \"date\", \"d_open\", \"d_yclose\",\"d_high\", \"d_low\", \"d_volume\"], how=\"outer\")\n",
    "    try:\n",
    "        assert(sum(re[\"d_amount_y\"].isnull()) == 0)\n",
    "    except:\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(re[re[\"d_amount_y\"].isnull()])\n",
    "        wr_ong += [re[re[\"d_amount_y\"].isnull()]]\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    # check 2\n",
    "    # first part\n",
    "    startTm = datetime.datetime.now()\n",
    "    date = pd.DataFrame(pd.date_range(start='2019-06-10 08:30:00', end='2019-06-10 18:00:00', freq='s'), columns=[\"Orig\"])\n",
    "    date[\"time\"] = date[\"Orig\"].apply(lambda x: int(x.strftime(\"%H%M%S\"))*1000)\n",
    "    date[\"group\"] = date[\"time\"]//10000\n",
    "    SH[\"group\"] = SH[\"time\"]//10000000\n",
    "    gl = date[((date[\"time\"] >= 93000000) & (date[\"time\"] <= 113000000))|((date[\"time\"] >= 130000000) & (date[\"time\"] <= 150000000))][\"group\"].unique()\n",
    "    l = set(gl) - set(SH[\"group\"].unique())\n",
    "    SH[\"has_missing1\"] = 0 \n",
    "    if len(l) != 0:\n",
    "        print(\"massive missing\")\n",
    "        print(l)\n",
    "        SH[\"order\"] = SH.groupby([\"skey\", \"time\"]).cumcount()\n",
    "        for i in l:\n",
    "            SH[\"t\"] = SH[SH[\"group\"] > i].groupby(\"StockID\")[\"time\"].transform(\"min\")\n",
    "            SH[\"has_missing1\"] = np.where((SH[\"time\"] == SH[\"t\"]) & (SH[\"order\"] == 0), 1, 0)\n",
    "        SH.drop([\"order\", \"t\", \"group\"], axis=1, inplace=True)   \n",
    "    else:\n",
    "        print(\"no massive missing\")\n",
    "        SH.drop([\"group\"], axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # second part\n",
    "\n",
    "    SH[\"time_interval\"] = SH.groupby(\"skey\")[\"datetime\"].apply(lambda x: x - x.shift(1))\n",
    "    SH[\"time_interval\"] = SH[\"time_interval\"].apply(lambda x: x.seconds)\n",
    "    SH[\"tn_update\"] = SH.groupby(\"skey\")[\"cum_trades_cnt\"].apply(lambda x: x-x.shift(1))\n",
    "\n",
    "    f1 = SH[(SH[\"time\"] >= 93000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "    f1 = f1.rename(columns={\"time\": \"time1\"})\n",
    "    f2 = SH[(SH[\"time\"] >= 130000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "    f2 = f2.rename(columns={\"time\": \"time2\"})\n",
    "    f3 = SH[(SH[\"time\"] >= 150000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "    f3 = f3.rename(columns={\"time\": \"time3\"})\n",
    "    SH = pd.merge(SH, f1, on=\"skey\", how=\"left\")\n",
    "    del f1\n",
    "    SH = pd.merge(SH, f2, on=\"skey\", how=\"left\")\n",
    "    del f2\n",
    "    SH = pd.merge(SH, f3, on=\"skey\", how=\"left\")\n",
    "    del f3\n",
    "    p99 = SH[(SH[\"time\"] > 93000000000) & (SH[\"time\"] < 145700000000) & (SH[\"time\"] != SH[\"time2\"]) & (SH[\"tn_update\"] != 0)]\\\n",
    "    .groupby(\"skey\")[\"tn_update\"].apply(lambda x: x.describe([0.99])[\"99%\"]).reset_index()\n",
    "    p99 = p99.rename(columns={\"tn_update\":\"99%\"})\n",
    "    SH = pd.merge(SH, p99, on=\"skey\", how=\"left\")\n",
    "\n",
    "    SH[\"has_missing2\"] = 0\n",
    "    SH[\"has_missing2\"] = np.where((SH[\"time_interval\"] > 60) & (SH[\"tn_update\"] > SH[\"99%\"]) & \n",
    "         (SH[\"time\"] > SH[\"time1\"]) & (SH[\"time\"] != SH[\"time2\"]) & (SH[\"time\"] != SH[\"time3\"]) & (SH[\"time\"] != 100000000000), 1, 0)\n",
    "    SH.drop([\"time_interval\", \"tn_update\", \"time1\", \"time2\", \"time3\", \"99%\"], axis=1, inplace=True) \n",
    "\n",
    "    SH[\"has_missing\"] = np.where((SH[\"has_missing1\"] == 1) | (SH[\"has_missing2\"] == 1), 1, 0)\n",
    "    SH.drop([\"has_missing1\", \"has_missing2\"], axis=1, inplace=True) \n",
    "    if SH[SH[\"has_missing\"] == 1].shape[0] != 0:\n",
    "        print(\"has missing!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(SH[SH[\"has_missing\"] == 1].shape[0])\n",
    "        mi_ss += [SH[SH[\"has_missing\"] == 1]]\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"has_missing\"] = SH[\"has_missing\"].astype('int32')\n",
    "    SH = SH[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ordering\", \"has_missing\", \"cum_trades_cnt\", \"cum_volume\", \"cum_amount\", \"prev_close\",\n",
    "                            \"open\", \"high\", \"low\", \"close\", 'bid10p','bid9p','bid8p','bid7p','bid6p','bid5p','bid4p','bid3p','bid2p','bid1p',\n",
    "                            'ask1p','ask2p','ask3p','ask4p','ask5p','ask6p','ask7p','ask8p','ask9p','ask10p', 'bid10q','bid9q','bid8q',\n",
    "                             'bid7q','bid6q','bid5q','bid4q','bid3q','bid2q','bid1q', 'ask1q','ask2q','ask3q','ask4q','ask5q','ask6q',\n",
    "                             'ask7q','ask8q','ask9q','ask10q', 'bid10n', 'bid9n', 'bid8n', 'bid7n', 'bid6n', 'bid5n', 'bid4n', 'bid3n', 'bid2n', 'bid1n', \n",
    "                             'ask1n', 'ask2n', 'ask3n', 'ask4n', 'ask5n', 'ask6n','ask7n', 'ask8n', 'ask9n', 'ask10n','bid1Top1q','bid1Top2q','bid1Top3q','bid1Top4q','bid1Top5q','bid1Top6q',\n",
    "        'bid1Top7q','bid1Top8q','bid1Top9q','bid1Top10q','bid1Top11q','bid1Top12q','bid1Top13q','bid1Top14q','bid1Top15q','bid1Top16q','bid1Top17q','bid1Top18q',\n",
    "        'bid1Top19q','bid1Top20q','bid1Top21q','bid1Top22q','bid1Top23q','bid1Top24q','bid1Top25q','bid1Top26q','bid1Top27q','bid1Top28q','bid1Top29q',\n",
    "        'bid1Top30q','bid1Top31q','bid1Top32q','bid1Top33q','bid1Top34q','bid1Top35q','bid1Top36q','bid1Top37q','bid1Top38q','bid1Top39q','bid1Top40q',\n",
    "        'bid1Top41q','bid1Top42q','bid1Top43q','bid1Top44q','bid1Top45q','bid1Top46q','bid1Top47q','bid1Top48q','bid1Top49q','bid1Top50q', 'ask1Top1q',\n",
    "        'ask1Top2q','ask1Top3q','ask1Top4q','ask1Top5q','ask1Top6q','ask1Top7q','ask1Top8q','ask1Top9q','ask1Top10q','ask1Top11q','ask1Top12q','ask1Top13q',\n",
    "        'ask1Top14q','ask1Top15q','ask1Top16q','ask1Top17q','ask1Top18q','ask1Top19q','ask1Top20q','ask1Top21q','ask1Top22q','ask1Top23q',\n",
    "        'ask1Top24q','ask1Top25q','ask1Top26q','ask1Top27q','ask1Top28q','ask1Top29q','ask1Top30q','ask1Top31q','ask1Top32q','ask1Top33q',\n",
    "        'ask1Top34q','ask1Top35q','ask1Top36q','ask1Top37q','ask1Top38q','ask1Top39q','ask1Top40q','ask1Top41q','ask1Top42q','ask1Top43q',\n",
    "        'ask1Top44q','ask1Top45q','ask1Top46q','ask1Top47q','ask1Top48q','ask1Top49q','ask1Top50q',\"total_bid_quantity\", \"total_ask_quantity\",\"total_bid_vwap\", \"total_ask_vwap\",\n",
    "        \"total_bid_orders\",'total_ask_orders','total_bid_levels', 'total_ask_levels', 'bid_trade_max_duration', 'ask_trade_max_duration', 'cum_canceled_buy_orders', 'cum_canceled_buy_volume',\n",
    "        \"cum_canceled_buy_amount\", \"cum_canceled_sell_orders\", 'cum_canceled_sell_volume',\"cum_canceled_sell_amount\"]]\n",
    "    \n",
    "    display(SH[\"date\"].iloc[0])\n",
    "    print(\"SH finished\")\n",
    "    \n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    db1 = DB(\"192.168.10.223\", database_name, user, password)\n",
    "    db1.write('md_snapshot_l2', SH)\n",
    "    \n",
    "    del SH\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "wr_ong = pd.concat(wr_ong).reset_index(drop=True)\n",
    "print(wr_ong)\n",
    "mi_ss = pd.concat(mi_ss).reset_index(drop=True)\n",
    "print(mi_ss)\n",
    "print(less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:202: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:53.808358\n",
      "0:00:36.315813\n",
      "20180820 unzip finished\n",
      "0:00:45.122711\n",
      "0:01:23.632507\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:25.765286\n",
      "0:00:31.488704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03.219981\n",
      "no massive missing\n",
      "0:01:43.242089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180820"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.307009\n",
      "0:00:38.174381\n",
      "20180821 unzip finished\n",
      "0:00:43.864244\n",
      "0:01:11.557983\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:42.727469\n",
      "0:00:32.937741\n",
      "0:00:03.271564\n",
      "no massive missing\n",
      "0:01:43.677207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180821"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.295266\n",
      "0:00:29.778000\n",
      "20180822 unzip finished\n",
      "0:00:38.878591\n",
      "0:01:15.192552\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:04.030516\n",
      "0:00:29.626171\n",
      "0:00:03.033302\n",
      "no massive missing\n",
      "0:01:43.698186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.006364\n",
      "0:00:30.675361\n",
      "20180823 unzip finished\n",
      "0:00:46.718068\n",
      "0:01:10.910430\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:52.315313\n",
      "0:00:31.321917\n",
      "0:00:03.169354\n",
      "no massive missing\n",
      "0:01:44.519318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180823"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.695834\n",
      "0:00:30.809333\n",
      "20180824 unzip finished\n",
      "0:00:41.443223\n",
      "0:01:11.725398\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:43.366105\n",
      "0:00:29.618048\n",
      "0:00:03.122295\n",
      "no massive missing\n",
      "0:01:40.720007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180824"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.700441\n",
      "0:00:31.554900\n",
      "20180827 unzip finished\n",
      "0:00:46.967264\n",
      "0:01:17.471813\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:48.898586\n",
      "0:00:32.808576\n",
      "0:00:03.337783\n",
      "no massive missing\n",
      "0:01:51.549761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180827"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.877391\n",
      "0:00:32.773952\n",
      "20180828 unzip finished\n",
      "0:00:48.050972\n",
      "0:01:14.615253\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:22.444387\n",
      "0:00:31.641403\n",
      "0:00:03.123380\n",
      "no massive missing\n",
      "0:01:46.156358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:02.611815\n",
      "0:00:33.472968\n",
      "20180829 unzip finished\n",
      "0:00:42.442704\n",
      "0:01:11.471688\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:09.968922\n",
      "0:00:31.553709\n",
      "0:00:03.192703\n",
      "no massive missing\n",
      "0:01:45.919377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180829"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.676985\n",
      "0:00:35.701233\n",
      "20180830 unzip finished\n",
      "0:00:45.878187\n",
      "0:01:17.293170\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:54.673477\n",
      "0:00:46.979296\n",
      "0:00:03.589661\n",
      "no massive missing\n",
      "0:01:54.924983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180830"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:01.945109\n",
      "0:00:30.560978\n",
      "20180831 unzip finished\n",
      "0:00:43.884106\n",
      "0:01:13.433015\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:42.580859\n",
      "0:00:30.913667\n",
      "0:00:03.032233\n",
      "no massive missing\n",
      "0:01:41.539916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180831"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.231084\n",
      "0:00:32.861891\n",
      "20180903 unzip finished\n",
      "0:00:44.120037\n",
      "0:01:12.410876\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:52.317267\n",
      "0:00:31.635690\n",
      "0:00:03.200811\n",
      "no massive missing\n",
      "0:01:45.509723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180903"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.730647\n",
      "0:00:29.451250\n",
      "20180904 unzip finished\n",
      "0:00:42.784141\n",
      "0:01:12.384316\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:03.252441\n",
      "0:00:31.719833\n",
      "0:00:03.192819\n",
      "no massive missing\n",
      "0:01:46.412018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.776357\n",
      "0:00:28.103794\n",
      "20180905 unzip finished\n",
      "0:00:42.794700\n",
      "0:01:12.844672\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:43.566221\n",
      "0:00:31.265239\n",
      "0:00:03.127458\n",
      "no massive missing\n",
      "0:01:42.686354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:02.591467\n",
      "0:00:26.684850\n",
      "20180906 unzip finished\n",
      "0:00:42.660469\n",
      "0:01:10.849431\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:31.310693\n",
      "0:00:30.887142\n",
      "0:00:03.127222\n",
      "no massive missing\n",
      "0:01:41.864162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180906"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:50.716826\n",
      "0:00:30.100580\n",
      "20180907 unzip finished\n",
      "0:00:41.420821\n",
      "0:01:12.656796\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:47.468947\n",
      "0:00:33.816071\n",
      "0:00:03.994568\n",
      "no massive missing\n",
      "0:01:46.588393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.635869\n",
      "0:00:29.018816\n",
      "20180910 unzip finished\n",
      "0:00:44.320243\n",
      "0:01:10.907744\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:31.293505\n",
      "0:00:29.944157\n",
      "0:00:03.018531\n",
      "no massive missing\n",
      "0:01:38.633792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180910"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.346513\n",
      "0:00:27.550678\n",
      "20180911 unzip finished\n",
      "0:00:39.802598\n",
      "0:01:08.679831\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:25.684281\n",
      "0:00:29.225053\n",
      "0:00:02.971381\n",
      "no massive missing\n",
      "0:01:40.194374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180911"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.086256\n",
      "0:00:27.703158\n",
      "20180912 unzip finished\n",
      "0:00:40.429491\n",
      "0:01:08.320621\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:16.794549\n",
      "0:00:30.660796\n",
      "0:00:03.035472\n",
      "no massive missing\n",
      "0:01:39.313422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180912"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:42.292466\n",
      "0:00:27.531764\n",
      "20180913 unzip finished\n",
      "0:00:41.881957\n",
      "0:01:10.014946\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:32.500948\n",
      "0:00:30.017107\n",
      "0:00:03.063940\n",
      "no massive missing\n",
      "0:01:41.050373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180913"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.945259\n",
      "0:00:34.958777\n",
      "20180914 unzip finished\n",
      "0:00:40.085942\n",
      "0:01:11.341266\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:28.476124\n",
      "0:00:30.327109\n",
      "0:00:03.096715\n",
      "no massive missing\n",
      "0:01:41.727440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180914"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.794655\n",
      "0:00:27.577392\n",
      "20180917 unzip finished\n",
      "0:00:40.823635\n",
      "0:01:09.785950\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:23.999461\n",
      "0:00:29.520222\n",
      "0:00:03.000521\n",
      "no massive missing\n",
      "0:01:40.875701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180917"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:42.424395\n",
      "0:00:29.691145\n",
      "20180918 unzip finished\n",
      "0:00:40.829637\n",
      "0:01:12.898047\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:53.783575\n",
      "0:00:32.249492\n",
      "0:00:03.243050\n",
      "no massive missing\n",
      "0:01:43.220638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180918"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:47.259936\n",
      "0:00:30.804453\n",
      "20180919 unzip finished\n",
      "0:00:46.005398\n",
      "0:01:21.057285\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:32.734349\n",
      "0:00:33.276833\n",
      "0:00:03.359071\n",
      "no massive missing\n",
      "0:01:51.065088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180919"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:04.666225\n",
      "0:00:28.309868\n",
      "20180920 unzip finished\n",
      "0:00:42.566730\n",
      "0:01:11.416004\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:49.227785\n",
      "0:00:30.393870\n",
      "0:00:03.139959\n",
      "no massive missing\n",
      "0:01:43.762071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180920"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:47.794353\n",
      "0:00:30.808217\n",
      "20180921 unzip finished\n",
      "0:00:46.236823\n",
      "0:01:18.468256\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:28.147912\n",
      "0:00:35.387241\n",
      "0:00:03.576696\n",
      "no massive missing\n",
      "0:01:54.506871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180921"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.648807\n",
      "0:00:30.323815\n",
      "20180925 unzip finished\n",
      "0:00:44.632332\n",
      "0:01:10.721904\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:46.332742\n",
      "0:00:30.439417\n",
      "0:00:03.143132\n",
      "no massive missing\n",
      "0:01:44.240206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180925"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.196575\n",
      "0:00:30.473110\n",
      "20180926 unzip finished\n",
      "0:00:44.898767\n",
      "0:01:16.662950\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:29.320964\n",
      "0:00:32.991813\n",
      "0:00:03.240929\n",
      "no massive missing\n",
      "0:01:50.932885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180926"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.759144\n",
      "0:00:30.123322\n",
      "20180927 unzip finished\n",
      "0:00:44.149269\n",
      "0:01:16.666927\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:23.116612\n",
      "0:00:34.202398\n",
      "0:00:03.309637\n",
      "no massive missing\n",
      "0:01:49.689639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.465410\n",
      "0:00:28.591246\n",
      "20180928 unzip finished\n",
      "0:00:44.937520\n",
      "0:01:13.436224\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:58.730571\n",
      "0:00:32.292249\n",
      "0:00:03.248362\n",
      "no massive missing\n",
      "0:01:45.586969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20180928"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.703455\n",
      "0:00:30.809479\n",
      "20181008 unzip finished\n",
      "0:00:42.639666\n",
      "0:01:12.474839\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:49.373000\n",
      "0:00:33.357746\n",
      "0:00:03.147863\n",
      "no massive missing\n",
      "0:01:43.046672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:05.162136\n",
      "0:00:29.159728\n",
      "20181009 unzip finished\n",
      "0:00:44.391839\n",
      "0:01:12.578062\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:44.354783\n",
      "0:00:31.114688\n",
      "0:00:03.143890\n",
      "no massive missing\n",
      "0:01:45.855928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181009"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.916609\n",
      "0:00:28.137060\n",
      "20181010 unzip finished\n",
      "0:00:42.062911\n",
      "0:01:10.814633\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:35.005450\n",
      "0:00:30.765731\n",
      "0:00:03.148164\n",
      "no massive missing\n",
      "0:01:48.873668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:44.049076\n",
      "0:00:34.089102\n",
      "20181011 unzip finished\n",
      "0:00:46.026766\n",
      "0:01:20.080991\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:48.234130\n",
      "0:00:37.447707\n",
      "0:00:03.616461\n",
      "no massive missing\n",
      "0:01:59.236293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:00.279102\n",
      "0:00:33.939387\n",
      "20181012 unzip finished\n",
      "0:00:48.093823\n",
      "0:01:21.709734\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:50.161868\n",
      "0:00:35.348763\n",
      "0:00:03.445186\n",
      "no massive missing\n",
      "0:01:55.918499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.044505\n",
      "0:00:28.377754\n",
      "20181015 unzip finished\n",
      "0:00:41.227661\n",
      "0:01:13.931929\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:43.469931\n",
      "0:00:33.206588\n",
      "0:00:03.213849\n",
      "no massive missing\n",
      "0:01:46.254146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181015"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:46.676892\n",
      "0:00:31.446726\n",
      "20181016 unzip finished\n",
      "0:00:42.048023\n",
      "0:01:14.857108\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:52.188643\n",
      "0:00:32.182116\n",
      "0:00:03.204742\n",
      "no massive missing\n",
      "0:01:49.680217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:46.734508\n",
      "0:00:30.731498\n",
      "20181017 unzip finished\n",
      "0:00:43.281501\n",
      "0:01:15.719527\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:51.453378\n",
      "0:00:31.832964\n",
      "0:00:03.261389\n",
      "no massive missing\n",
      "0:01:48.638255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.717263\n",
      "0:00:29.533798\n",
      "20181018 unzip finished\n",
      "0:00:43.183159\n",
      "0:01:16.563302\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:36.814952\n",
      "0:00:31.481066\n",
      "0:00:03.222147\n",
      "no massive missing\n",
      "0:01:49.766206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:47.203692\n",
      "0:00:33.565360\n",
      "20181019 unzip finished\n",
      "0:00:45.246201\n",
      "0:01:17.829804\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:20.272506\n",
      "0:00:33.241156\n",
      "0:00:03.312506\n",
      "no massive missing\n",
      "0:01:53.420893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:50.043126\n",
      "0:00:34.374828\n",
      "20181022 unzip finished\n",
      "0:00:47.992345\n",
      "0:01:25.288259\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:17.774043\n",
      "0:00:35.634879\n",
      "0:00:03.574030\n",
      "no massive missing\n",
      "0:01:58.976509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181022"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.655435\n",
      "0:00:32.735008\n",
      "20181023 unzip finished\n",
      "0:00:45.352986\n",
      "0:01:16.720881\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:24.276761\n",
      "0:00:33.851537\n",
      "0:00:03.323862\n",
      "no massive missing\n",
      "0:01:53.422004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181023"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.676070\n",
      "0:00:32.114105\n",
      "20181024 unzip finished\n",
      "0:00:43.774201\n",
      "0:01:14.565383\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:59.110790\n",
      "0:00:32.775952\n",
      "0:00:03.304365\n",
      "no massive missing\n",
      "0:01:51.769554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:47.269593\n",
      "0:00:31.464987\n",
      "20181025 unzip finished\n",
      "0:00:45.914245\n",
      "0:01:14.944800\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:07.049784\n",
      "0:00:31.889931\n",
      "0:00:03.249701\n",
      "no massive missing\n",
      "0:01:48.963360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:47.871839\n",
      "0:00:30.558011\n",
      "20181026 unzip finished\n",
      "0:00:43.145909\n",
      "0:01:15.452862\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:13.519842\n",
      "0:00:31.279141\n",
      "0:00:03.291690\n",
      "no massive missing\n",
      "0:01:49.213432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.170492\n",
      "0:00:30.616163\n",
      "20181029 unzip finished\n",
      "0:00:42.729686\n",
      "0:01:13.871695\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:08:49.982491\n",
      "0:00:32.121237\n",
      "0:00:03.261225\n",
      "no massive missing\n",
      "0:01:48.626136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181029"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:02.337519\n",
      "0:00:37.110753\n",
      "20181030 unzip finished\n",
      "0:00:47.038782\n",
      "0:01:20.924688\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:36.065877\n",
      "0:00:35.752725\n",
      "0:00:03.512739\n",
      "no massive missing\n",
      "0:01:56.612882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.106697\n",
      "0:00:34.683870\n",
      "20181031 unzip finished\n",
      "0:00:48.569233\n",
      "0:01:22.384380\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:53.577785\n",
      "0:00:33.916006\n",
      "0:00:03.470116\n",
      "no massive missing\n",
      "0:01:54.057316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181031"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:52.621002\n",
      "0:00:35.300602\n",
      "20181101 unzip finished\n",
      "0:00:50.194133\n",
      "0:01:25.034769\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:12.302563\n",
      "0:00:36.254315\n",
      "0:00:03.524315\n",
      "no massive missing\n",
      "0:01:57.334183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181101"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:02.622020\n",
      "0:00:35.402312\n",
      "20181102 unzip finished\n",
      "0:00:50.306583\n",
      "0:01:25.067784\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:32.455173\n",
      "0:00:37.184797\n",
      "0:00:03.707808\n",
      "no massive missing\n",
      "0:02:03.885405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.467320\n",
      "0:00:33.966489\n",
      "20181105 unzip finished\n",
      "0:00:49.588971\n",
      "0:01:28.164614\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:28.654322\n",
      "0:00:37.598954\n",
      "0:00:03.788642\n",
      "no massive missing\n",
      "0:02:04.900372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.110402\n",
      "0:00:35.740909\n",
      "20181106 unzip finished\n",
      "0:00:47.002793\n",
      "0:01:18.942738\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:54.883042\n",
      "0:00:34.501774\n",
      "0:00:03.475349\n",
      "no massive missing\n",
      "0:01:58.990199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:04.342068\n",
      "0:00:35.056736\n",
      "20181107 unzip finished\n",
      "0:00:47.813458\n",
      "0:01:22.042949\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:05.142374\n",
      "0:00:35.204458\n",
      "0:00:03.511217\n",
      "no massive missing\n",
      "0:02:12.965241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.029370\n",
      "0:00:33.217840\n",
      "20181108 unzip finished\n",
      "0:00:47.943421\n",
      "0:01:22.068136\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:57.766081\n",
      "0:00:35.487205\n",
      "0:00:03.561867\n",
      "no massive missing\n",
      "0:01:56.426239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181108"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.144317\n",
      "0:00:29.644414\n",
      "20181109 unzip finished\n",
      "0:00:46.591094\n",
      "0:01:18.443788\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:30.164193\n",
      "0:00:33.895780\n",
      "0:00:03.369856\n",
      "no massive missing\n",
      "0:01:50.668597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.332060\n",
      "0:00:33.307096\n",
      "20181112 unzip finished\n",
      "0:00:51.165781\n",
      "0:01:26.206211\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:37.386891\n",
      "0:00:37.531870\n",
      "0:00:03.709174\n",
      "no massive missing\n",
      "0:02:01.510060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.851771\n",
      "0:00:37.151045\n",
      "20181113 unzip finished\n",
      "0:00:53.863695\n",
      "0:01:31.741765\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:11:21.183523\n",
      "0:00:39.850456\n",
      "0:00:03.898711\n",
      "no massive missing\n",
      "0:02:10.288204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.953943\n",
      "0:00:36.357184\n",
      "20181114 unzip finished\n",
      "0:00:55.526092\n",
      "0:01:37.272309\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:29.238185\n",
      "0:00:39.438720\n",
      "0:00:04.154507\n",
      "no massive missing\n",
      "0:02:13.574883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:11.117244\n",
      "0:00:37.958183\n",
      "20181115 unzip finished\n",
      "0:00:50.178139\n",
      "0:01:23.488719\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:24.864052\n",
      "0:00:39.163472\n",
      "0:00:04.063920\n",
      "no massive missing\n",
      "0:02:05.299069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:00.514316\n",
      "0:00:36.320110\n",
      "20181116 unzip finished\n",
      "0:00:50.555673\n",
      "0:01:35.493140\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:52.052123\n",
      "0:00:40.048340\n",
      "0:00:04.108541\n",
      "no massive missing\n",
      "0:02:10.263695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:06.681590\n",
      "0:00:36.097254\n",
      "20181119 unzip finished\n",
      "0:00:49.637168\n",
      "0:01:26.162243\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:35.234527\n",
      "0:00:38.276829\n",
      "0:00:03.791304\n",
      "no massive missing\n",
      "0:02:07.604934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:07.363620\n",
      "0:00:38.145717\n",
      "20181120 unzip finished\n",
      "0:00:52.377965\n",
      "0:01:24.476287\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:32.573426\n",
      "0:00:39.698517\n",
      "0:00:04.024642\n",
      "no massive missing\n",
      "0:02:05.157503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.489868\n",
      "0:00:32.111647\n",
      "20181121 unzip finished\n",
      "0:00:47.523389\n",
      "0:01:21.587489\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:25.658931\n",
      "0:00:39.932874\n",
      "0:00:03.790944\n",
      "no massive missing\n",
      "0:02:07.668858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181121"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:52.042109\n",
      "0:00:32.940537\n",
      "20181122 unzip finished\n",
      "0:00:48.276047\n",
      "0:01:19.078712\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:59.834150\n",
      "0:00:35.429981\n",
      "0:00:03.643531\n",
      "no massive missing\n",
      "0:01:56.965990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181122"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.905516\n",
      "0:00:36.373054\n",
      "20181123 unzip finished\n",
      "0:00:47.941132\n",
      "0:01:25.231888\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:16.563145\n",
      "0:00:38.182448\n",
      "0:00:03.872765\n",
      "no massive missing\n",
      "0:02:13.108016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.415403\n",
      "0:00:31.132219\n",
      "20181126 unzip finished\n",
      "0:00:45.830947\n",
      "0:01:15.558282\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:12.176235\n",
      "0:00:34.894863\n",
      "0:00:03.642190\n",
      "no massive missing\n",
      "0:01:57.901558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181126"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.987705\n",
      "0:00:32.746034\n",
      "20181127 unzip finished\n",
      "0:00:46.192753\n",
      "0:01:14.441873\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:05.771689\n",
      "0:00:34.218458\n",
      "0:00:03.474083\n",
      "no massive missing\n",
      "0:01:53.203592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181127"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:48.034500\n",
      "0:00:32.336990\n",
      "20181128 unzip finished\n",
      "0:00:45.900875\n",
      "0:01:26.790966\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:38.241498\n",
      "0:00:36.798176\n",
      "0:00:03.721506\n",
      "no massive missing\n",
      "0:02:06.108102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:54.867786\n",
      "0:00:32.632931\n",
      "20181129 unzip finished\n",
      "0:00:45.059816\n",
      "0:01:15.555692\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:36.961299\n",
      "0:00:35.533293\n",
      "0:00:03.541718\n",
      "no massive missing\n",
      "0:01:54.857823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181129"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.723977\n",
      "0:00:31.074655\n",
      "20181130 unzip finished\n",
      "0:00:45.564994\n",
      "0:01:27.903052\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:23.921181\n",
      "0:00:35.932464\n",
      "0:00:03.615100\n",
      "no massive missing\n",
      "0:01:56.126555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.093914\n",
      "0:00:35.578498\n",
      "20181203 unzip finished\n",
      "0:00:53.579463\n",
      "0:01:26.462867\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:46.085933\n",
      "0:00:37.760959\n",
      "0:00:03.805572\n",
      "no massive missing\n",
      "0:02:05.134424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181203"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.028503\n",
      "0:00:33.348362\n",
      "20181204 unzip finished\n",
      "0:00:49.091728\n",
      "0:01:25.676136\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:24.486008\n",
      "0:00:42.547056\n",
      "0:00:03.902995\n",
      "no massive missing\n",
      "0:02:07.819414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181204"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.624648\n",
      "0:00:32.973576\n",
      "20181205 unzip finished\n",
      "0:00:47.569518\n",
      "0:01:23.425665\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:20.690981\n",
      "0:00:37.277900\n",
      "0:00:03.665616\n",
      "no massive missing\n",
      "0:02:00.744120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181205"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:54.961897\n",
      "0:00:36.093199\n",
      "20181206 unzip finished\n",
      "0:00:50.213890\n",
      "0:01:22.587935\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:17.672847\n",
      "0:00:34.501765\n",
      "0:00:03.500128\n",
      "no massive missing\n",
      "0:01:55.887870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.033858\n",
      "0:00:33.529500\n",
      "20181207 unzip finished\n",
      "0:00:43.662014\n",
      "0:01:15.567187\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:58.662217\n",
      "0:00:35.959825\n",
      "0:00:03.415027\n",
      "no massive missing\n",
      "0:01:53.990459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:51.811012\n",
      "0:00:34.550873\n",
      "20181210 unzip finished\n",
      "0:00:48.658166\n",
      "0:01:27.021407\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:48.612401\n",
      "0:00:34.278405\n",
      "0:00:03.456093\n",
      "no massive missing\n",
      "0:01:53.649113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181210"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.030273\n",
      "0:00:37.535228\n",
      "20181211 unzip finished\n",
      "0:00:43.989326\n",
      "0:01:13.172522\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:30.636215\n",
      "0:00:38.348432\n",
      "0:00:03.581026\n",
      "no massive missing\n",
      "0:02:00.316637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181211"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:49.007469\n",
      "0:00:36.836065\n",
      "20181212 unzip finished\n",
      "0:00:45.715960\n",
      "0:01:22.869037\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:31.530331\n",
      "0:00:34.540799\n",
      "0:00:03.629144\n",
      "no massive missing\n",
      "0:01:57.107153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181212"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.159456\n",
      "0:00:35.238498\n",
      "20181213 unzip finished\n",
      "0:00:48.374488\n",
      "0:01:21.084561\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:26.689405\n",
      "0:00:36.648471\n",
      "0:00:03.761351\n",
      "no massive missing\n",
      "0:02:00.582461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181213"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:53.371271\n",
      "0:00:38.334413\n",
      "20181214 unzip finished\n",
      "0:00:47.969918\n",
      "0:01:21.993020\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:31.310934\n",
      "0:00:40.403836\n",
      "0:00:03.742269\n",
      "no massive missing\n",
      "0:02:04.535022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181214"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:55.747585\n",
      "0:00:37.826016\n",
      "20181217 unzip finished\n",
      "0:00:50.614344\n",
      "0:01:23.383197\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:14.261910\n",
      "0:00:37.619135\n",
      "0:00:03.783630\n",
      "no massive missing\n",
      "0:01:59.896710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181217"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:07.763658\n",
      "0:00:38.656218\n",
      "20181218 unzip finished\n",
      "0:00:52.848065\n",
      "0:01:37.269136\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:46.414137\n",
      "0:00:38.974163\n",
      "0:00:03.923019\n",
      "no massive missing\n",
      "0:02:09.856134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181218"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:01.150490\n",
      "0:00:35.773868\n",
      "20181219 unzip finished\n",
      "0:00:56.274994\n",
      "0:01:26.708586\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:33.245205\n",
      "0:00:36.210535\n",
      "0:00:03.665972\n",
      "no massive missing\n",
      "0:02:07.364569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:06.384511\n",
      "0:00:35.208562\n",
      "20181220 unzip finished\n",
      "0:00:52.771116\n",
      "0:01:26.954929\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:18.404029\n",
      "0:00:39.080121\n",
      "0:00:03.681239\n",
      "no massive missing\n",
      "0:02:11.799150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181220"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:02.495495\n",
      "0:00:34.042493\n",
      "20181221 unzip finished\n",
      "0:00:50.406581\n",
      "0:01:25.039888\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:20.469004\n",
      "0:00:35.200473\n",
      "0:00:03.501082\n",
      "no massive missing\n",
      "0:01:57.274940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181221"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.041508\n",
      "0:01:03.187930\n",
      "20181224 unzip finished\n",
      "0:00:49.729374\n",
      "0:01:21.304082\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:43.271073\n",
      "0:00:36.853585\n",
      "0:00:03.304997\n",
      "no massive missing\n",
      "0:01:49.184346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:59.951892\n",
      "0:00:38.053639\n",
      "20181225 unzip finished\n",
      "0:00:57.447775\n",
      "0:01:30.117753\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:45.645312\n",
      "0:00:36.336889\n",
      "0:00:03.450669\n",
      "no massive missing\n",
      "0:02:00.988365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181225"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:01:08.022684\n",
      "0:00:39.055778\n",
      "20181226 unzip finished\n",
      "0:00:49.579550\n",
      "0:01:24.042697\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:02.931298\n",
      "0:00:35.161319\n",
      "0:00:03.345207\n",
      "no massive missing\n",
      "0:01:54.357948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181226"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:56.385410\n",
      "0:00:57.057589\n",
      "20181227 unzip finished\n",
      "0:00:52.378724\n",
      "0:01:26.311491\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:10:35.383479\n",
      "0:00:33.508318\n",
      "0:00:03.268387\n",
      "no massive missing\n",
      "0:01:56.471413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:58.647366\n",
      "0:00:36.520464\n",
      "20181228 unzip finished\n",
      "0:00:52.066517\n",
      "0:01:21.587968\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "0:09:53.081544\n",
      "0:00:34.369662\n",
      "0:00:03.338789\n",
      "no massive missing\n",
      "0:01:59.921643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20181228"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH finished\n",
      "0:00:57.879093\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54dbf332ce4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartTm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m \u001b[0mwr_ong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwr_ong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwr_ong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0mmi_ss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi_ss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "readPath = '/home/work516/day_stock/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SH' for i in dataPathLs])]]\n",
    "db = pd.DataFrame()\n",
    "for p in dataPathLs:\n",
    "    dayData = pd.read_csv(p, compression='gzip')\n",
    "    db = pd.concat([db, dayData])\n",
    "print(datetime.datetime.now() - startTm)\n",
    "\n",
    "year = \"2018\"\n",
    "startDate = '20180820'\n",
    "endDate = '20181231'\n",
    "readPath = '/mnt/usb/data/' + year + '/***/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i).split('_')[0] for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "date_list = pd.read_csv(\"/home/work516/KR_upload_code/trading_days.csv\")\n",
    "wr_ong = []\n",
    "mi_ss = []\n",
    "less = []\n",
    "\n",
    "for data in dataPathLs:\n",
    "    if len(np.array(glob.glob(data + '/SH/***'))) == 0:\n",
    "        if int(os.path.basename(data)) not in date_list[\"Date\"].values:\n",
    "            continue\n",
    "        else:\n",
    "            print(os.path.basename(data) + \" less data!!!!!!!!!!!!!!!!!\")\n",
    "            less.append(data)\n",
    "            continue\n",
    "    startTm = datetime.datetime.now()\n",
    "    date = os.path.basename(data)\n",
    "    rar_path = data + '/SH/snapshot.7z'\n",
    "    path = '/mnt/e/unzip_data/2018/SH'\n",
    "    path1 = path + '/' + date\n",
    "    un_path = path1\n",
    "    cmd = '7za x {} -o{}'.format(rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    print(date + ' unzip finished')\n",
    "\n",
    "    readPath = path1 + '/snapshot/***2/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[((dateLs >= 600000) & (dateLs <= 700000))]\n",
    "    SH = []\n",
    "    ll = []\n",
    "    startTm = datetime.datetime.now()\n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i, usecols = [0,1,3,5,7,9,10,11,15,17,18,19,20,21,22,23,25,26,28,29,30,31,32,33,37,39,40,41,\n",
    "                                          42,46,47,49,50])\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"StockID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        SH += [df]\n",
    "    del df\n",
    "    SH = pd.concat(SH).reset_index(drop=True)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"skey\"] = SH[\"StockID\"] + 1000000\n",
    "    SH.drop([\"StockID\"],axis=1,inplace=True)\n",
    "    SH[\"date\"] = int(SH[\"QuotTime\"].iloc[0]//1000000000)\n",
    "    SH[\"time\"] = (SH['QuotTime'] - int(SH['QuotTime'].iloc[0]//1000000000*1000000000)).astype(np.int64) * 1000\n",
    "    SH[\"clockAtArrival\"] = SH[\"QuotTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    SH.drop([\"QuotTime\"],axis=1,inplace=True)\n",
    "    SH['datetime'] = SH[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"BidPrice\"] = SH[\"BidPrice\"].apply(lambda x: [float(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferPrice\"] = SH[\"OfferPrice\"].apply(lambda x: [float(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"BidOrderQty\"] = SH[\"BidOrderQty\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferOrderQty\"] = SH[\"OfferOrderQty\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"BidNumOrders\"] = SH[\"BidNumOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferNumOrders\"] = SH[\"OfferNumOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        SH[\"bid\" + str(i) + 'p'] = SH[\"BidPrice\"].apply(lambda x: x[i-1],2)\n",
    "    SH.drop([\"BidPrice\"],axis=1,inplace=True)\n",
    "    print(\"1\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"ask\" + str(i) + 'p'] = SH[\"OfferPrice\"].apply(lambda x: x[i-1],2)\n",
    "    SH.drop([\"OfferPrice\"],axis=1,inplace=True)\n",
    "    print(\"2\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"bid\" + str(i) + 'q'] = SH[\"BidOrderQty\"].apply(lambda x: x[i-1])\n",
    "    SH.drop([\"BidOrderQty\"],axis=1,inplace=True)\n",
    "    print(\"3\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"ask\" + str(i) + 'q'] = SH[\"OfferOrderQty\"].apply(lambda x: x[i-1])\n",
    "    SH.drop([\"OfferOrderQty\"],axis=1,inplace=True)\n",
    "    print(\"4\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"bid\" + str(i) + 'n'] = SH[\"BidNumOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"bid\" + str(i) + 'n'] = SH[\"bid\" + str(i) + 'n'].astype('int32')\n",
    "    SH.drop([\"BidNumOrders\"],axis=1,inplace=True)\n",
    "    print(\"5\")\n",
    "    for i in range(1, 11):\n",
    "        SH[\"ask\" + str(i) + 'n'] = SH[\"OfferNumOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"ask\" + str(i) + 'n'] = SH[\"ask\" + str(i) + 'n'].astype('int32') \n",
    "    SH.drop([\"OfferNumOrders\"],axis=1,inplace=True)\n",
    "    print(\"6\")\n",
    "    \n",
    "    SH[\"BidOrders\"] = SH[\"BidOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "    SH[\"OfferOrders\"] = SH[\"OfferOrders\"].apply(lambda x: [int(i) for i in x[1:-1].split(',')])\n",
    "\n",
    "    for i in range(1, 51):\n",
    "        SH[\"bid1Top\" + str(i) + 'q'] = SH[\"BidOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"bid1Top\" + str(i) + 'q'] = SH[\"bid1Top\" + str(i) + 'q'].astype('int32') \n",
    "    SH.drop([\"BidOrders\"],axis=1,inplace=True)\n",
    "    print(\"7\")\n",
    "    \n",
    "    for i in range(1, 51):\n",
    "        SH[\"ask1Top\" + str(i) + 'q'] = SH[\"OfferOrders\"].apply(lambda x: x[i-1])\n",
    "        SH[\"ask1Top\" + str(i) + 'q'] = SH[\"ask1Top\" + str(i) + 'q'].astype('int32') \n",
    "    SH.drop([\"OfferOrders\"],axis=1,inplace=True)\n",
    "    print(\"8\")\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH.columns = ['cum_trades_cnt', 'ask_trade_max_duration', 'total_bid_orders',\n",
    "       'cum_canceled_sell_amount', 'total_ask_quantity', 'cum_canceled_buy_orders',\n",
    "       'total_ask_vwap', 'cum_canceled_sell_volume', 'cum_volume', 'open',\n",
    "       'high', 'prev_close', 'low', 'total_bid_vwap',\n",
    "       'cum_canceled_sell_orders', 'total_ask_orders', 'total_ask_levels',\n",
    "       'total_bid_quantity', 'cum_canceled_buy_volume', 'bid_trade_max_duration',\n",
    "       'total_bid_levels', 'close', 'cum_amount', 'cum_canceled_buy_amount', 'skey', 'date', 'time', 'clockAtArrival',\n",
    "       'datetime', 'bid1p', 'bid2p', 'bid3p', 'bid4p', 'bid5p', 'bid6p',\n",
    "       'bid7p', 'bid8p', 'bid9p', 'bid10p', 'ask1p', 'ask2p', 'ask3p',\n",
    "       'ask4p', 'ask5p', 'ask6p', 'ask7p', 'ask8p', 'ask9p', 'ask10p',\n",
    "       'bid1q', 'bid2q', 'bid3q', 'bid4q', 'bid5q', 'bid6q', 'bid7q',\n",
    "       'bid8q', 'bid9q', 'bid10q', 'ask1q', 'ask2q', 'ask3q', 'ask4q',\n",
    "       'ask5q', 'ask6q', 'ask7q', 'ask8q', 'ask9q', 'ask10q', 'bid1n',\n",
    "       'bid2n', 'bid3n', 'bid4n', 'bid5n', 'bid6n', 'bid7n', 'bid8n',\n",
    "       'bid9n', 'bid10n', 'ask1n', 'ask2n', 'ask3n', 'ask4n', 'ask5n',\n",
    "       'ask6n', 'ask7n', 'ask8n', 'ask9n', 'ask10n', 'bid1Top1q',\n",
    "       'bid1Top2q', 'bid1Top3q', 'bid1Top4q', 'bid1Top5q', 'bid1Top6q',\n",
    "       'bid1Top7q', 'bid1Top8q', 'bid1Top9q', 'bid1Top10q', 'bid1Top11q',\n",
    "       'bid1Top12q', 'bid1Top13q', 'bid1Top14q', 'bid1Top15q',\n",
    "       'bid1Top16q', 'bid1Top17q', 'bid1Top18q', 'bid1Top19q',\n",
    "       'bid1Top20q', 'bid1Top21q', 'bid1Top22q', 'bid1Top23q',\n",
    "       'bid1Top24q', 'bid1Top25q', 'bid1Top26q', 'bid1Top27q',\n",
    "       'bid1Top28q', 'bid1Top29q', 'bid1Top30q', 'bid1Top31q',\n",
    "       'bid1Top32q', 'bid1Top33q', 'bid1Top34q', 'bid1Top35q',\n",
    "       'bid1Top36q', 'bid1Top37q', 'bid1Top38q', 'bid1Top39q',\n",
    "       'bid1Top40q', 'bid1Top41q', 'bid1Top42q', 'bid1Top43q',\n",
    "       'bid1Top44q', 'bid1Top45q', 'bid1Top46q', 'bid1Top47q',\n",
    "       'bid1Top48q', 'bid1Top49q', 'bid1Top50q', 'ask1Top1q', 'ask1Top2q',\n",
    "       'ask1Top3q', 'ask1Top4q', 'ask1Top5q', 'ask1Top6q', 'ask1Top7q',\n",
    "       'ask1Top8q', 'ask1Top9q', 'ask1Top10q', 'ask1Top11q', 'ask1Top12q',\n",
    "       'ask1Top13q', 'ask1Top14q', 'ask1Top15q', 'ask1Top16q',\n",
    "       'ask1Top17q', 'ask1Top18q', 'ask1Top19q', 'ask1Top20q',\n",
    "       'ask1Top21q', 'ask1Top22q', 'ask1Top23q', 'ask1Top24q',\n",
    "       'ask1Top25q', 'ask1Top26q', 'ask1Top27q', 'ask1Top28q',\n",
    "       'ask1Top29q', 'ask1Top30q', 'ask1Top31q', 'ask1Top32q',\n",
    "       'ask1Top33q', 'ask1Top34q', 'ask1Top35q', 'ask1Top36q',\n",
    "       'ask1Top37q', 'ask1Top38q', 'ask1Top39q', 'ask1Top40q',\n",
    "       'ask1Top41q', 'ask1Top42q', 'ask1Top43q', 'ask1Top44q',\n",
    "       'ask1Top45q', 'ask1Top46q', 'ask1Top47q', 'ask1Top48q',\n",
    "       'ask1Top49q', 'ask1Top50q']\n",
    "    SH = SH.fillna(0)\n",
    "#     SH[\"p1\"] = SH[\"bid1p\"] + SH[\"ask1p\"]\n",
    "#     tt = SH[(SH[\"cum_volume\"] > 0) & (SH[\"time\"] < 145700000000)].groupby(\"skey\")['p1'].min()\n",
    "#     SH.drop(\"p1\", axis=1, inplace=True)\n",
    "#     try:\n",
    "#         assert(tt[tt == 0].shape[0] == 0)\n",
    "#     except:\n",
    "#         display(tt[tt == 0])\n",
    "#     SH = SH[~((SH[\"bid1p\"] == 0) & (SH[\"ask1p\"] == 0))]\n",
    "    SH[\"ordering\"] = SH.groupby(\"skey\").cumcount()\n",
    "    SH[\"ordering\"] = SH[\"ordering\"] + 1\n",
    "    \n",
    "    SH[\"has_missing\"] = 0\n",
    "    \n",
    "    for col in [\"skey\", \"date\", \"cum_trades_cnt\", \"total_bid_orders\",\n",
    "        'total_ask_orders', 'total_bid_levels', 'total_ask_levels', 'cum_canceled_buy_orders','cum_canceled_sell_orders',\n",
    "            \"ordering\", 'bid_trade_max_duration', 'ask_trade_max_duration','has_missing']:\n",
    "        SH[col] = SH[col].astype('int32')\n",
    "    \n",
    "#     for cols in [\"prev_close\", 'open', \"high\", \"low\", \"close\", 'bid10p','bid9p','bid8p','bid7p','bid6p','bid5p','bid4p','bid3p',\n",
    "#              'bid2p','bid1p','ask1p','ask2p','ask3p','ask4p','ask5p','ask6p','ask7p','ask8p','ask9p','ask10p']:\n",
    "# #         SH[cols] = SH[cols].apply(lambda x: round(x, 2)).astype('float64')\n",
    "#         print(cols)\n",
    "#         print(SH[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "    \n",
    "#     for cols in ['cum_amount', \"cum_canceled_sell_amount\", \"cum_canceled_buy_amount\"]:\n",
    "# #         SH[cols] = SH[cols].apply(lambda x: round(x, 2)).astype('float64')\n",
    "#         print(cols)\n",
    "#         print(SH[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "        \n",
    "    for cols in ['total_bid_vwap', \"total_ask_vwap\"]:\n",
    "#         print(cols)\n",
    "#         print(SH[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "        SH[cols] = SH[cols].apply(lambda x: round(x, 3))\n",
    "        \n",
    "   \n",
    "    assert(sum(SH[SH[\"open\"] != 0].groupby(\"skey\")[\"open\"].nunique() != 1) == 0)\n",
    "    assert(sum(SH[SH[\"prev_close\"] != 0].groupby(\"skey\")[\"prev_close\"].nunique() != 1) == 0)\n",
    "    SH[\"prev_close\"] = np.where(SH[\"time\"] >= 91500000000, SH.groupby(\"skey\")[\"prev_close\"].transform(\"max\"), SH[\"prev_close\"]) \n",
    "    SH[\"open\"] = np.where(SH[\"cum_volume\"] > 0, SH.groupby(\"skey\")[\"open\"].transform(\"max\"), SH[\"open\"])\n",
    "    assert(sum(SH[SH[\"open\"] != 0].groupby(\"skey\")[\"open\"].nunique() != 1) == 0)\n",
    "    assert(sum(SH[SH[\"prev_close\"] != 0].groupby(\"skey\")[\"prev_close\"].nunique() != 1) == 0)\n",
    "    assert(SH[SH[\"cum_volume\"] > 0][\"open\"].min() > 0)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    # check 1\n",
    "    startTm = datetime.datetime.now()\n",
    "    da_te = str(SH[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    db1[\"ID\"] = db1[\"ID\"].str[2:].astype(int) + 1000000\n",
    "    db1[\"date\"] = (db1[\"date\"].str[:4] + db1[\"date\"].str[5:7] + db1[\"date\"].str[8:]).astype(int)\n",
    "    SH[\"cum_max\"] = SH.groupby(\"skey\")[\"cum_volume\"].transform(max)\n",
    "    s2 = SH[SH[\"cum_volume\"] == SH[\"cum_max\"]].groupby(\"skey\").first().reset_index()\n",
    "    dd = SH[SH[\"cum_volume\"] == SH[\"cum_max\"]].groupby(\"skey\")[\"time\"].first().reset_index()\n",
    "    SH.drop(\"cum_max\", axis=1, inplace=True)\n",
    "    s2 = s2.rename(columns={\"skey\": \"ID\", 'open':\"d_open\", \"prev_close\":\"d_yclose\",\"high\":\"d_high\", \"low\":\"d_low\", \"close\":\"d_close\", \"cum_volume\":\"d_volume\", \"cum_amount\":\"d_amount\"})\n",
    "    if SH[\"date\"].iloc[0] < 20180820:\n",
    "        s2[\"auction\"] = 0\n",
    "    else:\n",
    "        dd[\"auction\"] = np.where(dd[\"time\"]<=145700000000, 0, 1)\n",
    "        dd = dd.rename(columns={\"skey\": \"ID\"})\n",
    "        s2 = pd.merge(s2, dd[[\"ID\", \"auction\"]], on=\"ID\")\n",
    "    s2 = s2[[\"ID\", \"date\", \"d_open\", \"d_yclose\", \"d_high\", \"d_low\", \"d_close\", \"d_volume\", \"d_amount\", \"auction\"]]\n",
    "    re = pd.merge(db1, s2, on=[\"ID\", \"date\", \"d_open\", \"d_yclose\",\"d_high\", \"d_low\", \"d_volume\"], how=\"outer\")\n",
    "    try:\n",
    "        assert(sum(re[\"d_amount_y\"].isnull()) == 0)\n",
    "    except:\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(re[re[\"d_amount_y\"].isnull()])\n",
    "        wr_ong += [re[re[\"d_amount_y\"].isnull()]]\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    # check 2\n",
    "    # first part\n",
    "    startTm = datetime.datetime.now()\n",
    "    date = pd.DataFrame(pd.date_range(start='2019-06-10 08:30:00', end='2019-06-10 18:00:00', freq='s'), columns=[\"Orig\"])\n",
    "    date[\"time\"] = date[\"Orig\"].apply(lambda x: int(x.strftime(\"%H%M%S\"))*1000)\n",
    "    date[\"group\"] = date[\"time\"]//10000\n",
    "    SH[\"group\"] = SH[\"time\"]//10000000\n",
    "    gl = date[((date[\"time\"] >= 93000000) & (date[\"time\"] < 113000000))|((date[\"time\"] >= 130000000) & (date[\"time\"] <= 150000000))][\"group\"].unique()\n",
    "    l = set(gl) - set(SH[\"group\"].unique())\n",
    "    SH[\"has_missing1\"] = 0 \n",
    "    if len(l) != 0:\n",
    "        print(\"massive missing\")\n",
    "        print(l)\n",
    "        SH[\"order\"] = SH.groupby([\"skey\", \"time\"]).cumcount()\n",
    "        for i in l:\n",
    "            SH[\"t\"] = SH[SH[\"group\"] > i].groupby(\"skey\")[\"time\"].transform(\"min\")\n",
    "            SH[\"has_missing1\"] = np.where((SH[\"time\"] == SH[\"t\"]) & (SH[\"order\"] == 0), 1, 0)\n",
    "        SH.drop([\"order\", \"t\", \"group\"], axis=1, inplace=True)   \n",
    "    else:\n",
    "        print(\"no massive missing\")\n",
    "        SH.drop([\"group\"], axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # second part\n",
    "\n",
    "    SH[\"time_interval\"] = SH.groupby(\"skey\")[\"datetime\"].apply(lambda x: x - x.shift(1))\n",
    "    SH[\"time_interval\"] = SH[\"time_interval\"].apply(lambda x: x.seconds)\n",
    "    SH[\"tn_update\"] = SH.groupby(\"skey\")[\"cum_trades_cnt\"].apply(lambda x: x-x.shift(1))\n",
    "\n",
    "    f1 = SH[(SH[\"time\"] >= 93000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "    f1 = f1.rename(columns={\"time\": \"time1\"})\n",
    "    f2 = SH[(SH[\"time\"] >= 130000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "    f2 = f2.rename(columns={\"time\": \"time2\"})\n",
    "    f3 = SH[(SH[\"time\"] >= 150000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "    f3 = f3.rename(columns={\"time\": \"time3\"})\n",
    "    SH = pd.merge(SH, f1, on=\"skey\", how=\"left\")\n",
    "    del f1\n",
    "    SH = pd.merge(SH, f2, on=\"skey\", how=\"left\")\n",
    "    del f2\n",
    "    SH = pd.merge(SH, f3, on=\"skey\", how=\"left\")\n",
    "    del f3\n",
    "    p99 = SH[(SH[\"time\"] > 93000000000) & (SH[\"time\"] < 145700000000) & (SH[\"time\"] != SH[\"time2\"]) & (SH[\"tn_update\"] != 0)]\\\n",
    "    .groupby(\"skey\")[\"tn_update\"].apply(lambda x: x.describe([0.99])[\"99%\"]).reset_index()\n",
    "    p99 = p99.rename(columns={\"tn_update\":\"99%\"})\n",
    "    SH = pd.merge(SH, p99, on=\"skey\", how=\"left\")\n",
    "\n",
    "    SH[\"has_missing2\"] = 0\n",
    "    SH[\"has_missing2\"] = np.where((SH[\"time_interval\"] > 60) & (SH[\"tn_update\"] > SH[\"99%\"]) & \n",
    "         (SH[\"time\"] > SH[\"time1\"]) & (SH[\"time\"] != SH[\"time2\"]) & (SH[\"time\"] != SH[\"time3\"]) & (SH[\"time\"] != 100000000000), 1, 0)\n",
    "    SH.drop([\"time_interval\", \"tn_update\", \"time1\", \"time2\", \"time3\", \"99%\"], axis=1, inplace=True) \n",
    "\n",
    "    SH[\"has_missing\"] = np.where((SH[\"has_missing1\"] == 1) | (SH[\"has_missing2\"] == 1), 1, 0)\n",
    "    SH.drop([\"has_missing1\", \"has_missing2\"], axis=1, inplace=True) \n",
    "    if SH[SH[\"has_missing\"] == 1].shape[0] != 0:\n",
    "        print(\"has missing!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(SH[SH[\"has_missing\"] == 1].shape[0])\n",
    "        mi_ss += [SH[SH[\"has_missing\"] == 1]]\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"has_missing\"] = SH[\"has_missing\"].astype('int32')\n",
    "    SH = SH[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ordering\", \"has_missing\", \"cum_trades_cnt\", \"cum_volume\", \"cum_amount\", \"prev_close\",\n",
    "                            \"open\", \"high\", \"low\", \"close\", 'bid10p','bid9p','bid8p','bid7p','bid6p','bid5p','bid4p','bid3p','bid2p','bid1p',\n",
    "                            'ask1p','ask2p','ask3p','ask4p','ask5p','ask6p','ask7p','ask8p','ask9p','ask10p', 'bid10q','bid9q','bid8q',\n",
    "                             'bid7q','bid6q','bid5q','bid4q','bid3q','bid2q','bid1q', 'ask1q','ask2q','ask3q','ask4q','ask5q','ask6q',\n",
    "                             'ask7q','ask8q','ask9q','ask10q', 'bid10n', 'bid9n', 'bid8n', 'bid7n', 'bid6n', 'bid5n', 'bid4n', 'bid3n', 'bid2n', 'bid1n', \n",
    "                             'ask1n', 'ask2n', 'ask3n', 'ask4n', 'ask5n', 'ask6n','ask7n', 'ask8n', 'ask9n', 'ask10n','bid1Top1q','bid1Top2q','bid1Top3q','bid1Top4q','bid1Top5q','bid1Top6q',\n",
    "        'bid1Top7q','bid1Top8q','bid1Top9q','bid1Top10q','bid1Top11q','bid1Top12q','bid1Top13q','bid1Top14q','bid1Top15q','bid1Top16q','bid1Top17q','bid1Top18q',\n",
    "        'bid1Top19q','bid1Top20q','bid1Top21q','bid1Top22q','bid1Top23q','bid1Top24q','bid1Top25q','bid1Top26q','bid1Top27q','bid1Top28q','bid1Top29q',\n",
    "        'bid1Top30q','bid1Top31q','bid1Top32q','bid1Top33q','bid1Top34q','bid1Top35q','bid1Top36q','bid1Top37q','bid1Top38q','bid1Top39q','bid1Top40q',\n",
    "        'bid1Top41q','bid1Top42q','bid1Top43q','bid1Top44q','bid1Top45q','bid1Top46q','bid1Top47q','bid1Top48q','bid1Top49q','bid1Top50q', 'ask1Top1q',\n",
    "        'ask1Top2q','ask1Top3q','ask1Top4q','ask1Top5q','ask1Top6q','ask1Top7q','ask1Top8q','ask1Top9q','ask1Top10q','ask1Top11q','ask1Top12q','ask1Top13q',\n",
    "        'ask1Top14q','ask1Top15q','ask1Top16q','ask1Top17q','ask1Top18q','ask1Top19q','ask1Top20q','ask1Top21q','ask1Top22q','ask1Top23q',\n",
    "        'ask1Top24q','ask1Top25q','ask1Top26q','ask1Top27q','ask1Top28q','ask1Top29q','ask1Top30q','ask1Top31q','ask1Top32q','ask1Top33q',\n",
    "        'ask1Top34q','ask1Top35q','ask1Top36q','ask1Top37q','ask1Top38q','ask1Top39q','ask1Top40q','ask1Top41q','ask1Top42q','ask1Top43q',\n",
    "        'ask1Top44q','ask1Top45q','ask1Top46q','ask1Top47q','ask1Top48q','ask1Top49q','ask1Top50q',\"total_bid_quantity\", \"total_ask_quantity\",\"total_bid_vwap\", \"total_ask_vwap\",\n",
    "        \"total_bid_orders\",'total_ask_orders','total_bid_levels', 'total_ask_levels', 'bid_trade_max_duration', 'ask_trade_max_duration', 'cum_canceled_buy_orders', 'cum_canceled_buy_volume',\n",
    "        \"cum_canceled_buy_amount\", \"cum_canceled_sell_orders\", 'cum_canceled_sell_volume',\"cum_canceled_sell_amount\"]]\n",
    "    \n",
    "    display(SH[\"date\"].iloc[0])\n",
    "    print(\"SH finished\")\n",
    "    \n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    db1 = DB(\"192.168.10.223\", database_name, user, password)\n",
    "    db1.write('md_snapshot_l2', SH)\n",
    "    \n",
    "    del SH\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "wr_ong = pd.concat(wr_ong).reset_index(drop=True)\n",
    "print(wr_ong)\n",
    "mi_ss = pd.concat(mi_ss).reset_index(drop=True)\n",
    "print(mi_ss)\n",
    "print(less)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

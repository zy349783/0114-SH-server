{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:195: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:05:53.910072\n",
      "0:00:20.833907\n",
      "20170901 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170901\n",
      "order finished\n",
      "0:07:51.565118\n",
      "0:00:22.086957\n",
      "20170904 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170904\n",
      "order finished\n",
      "0:08:12.524122\n",
      "0:00:19.427176\n",
      "20170905 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170905\n",
      "order finished\n",
      "0:07:30.170558\n",
      "0:00:26.989535\n",
      "20170906 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170906\n",
      "order finished\n",
      "0:07:56.591715\n",
      "0:00:20.998357\n",
      "20170907 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (1,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170907\n",
      "order finished\n",
      "0:08:22.849819\n",
      "0:00:21.049312\n",
      "20170908 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170908\n",
      "order finished\n",
      "0:07:28.216675\n",
      "0:00:23.710070\n",
      "20170911 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170911\n",
      "order finished\n",
      "0:07:34.187523\n",
      "0:00:23.721532\n",
      "20170912 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170912\n",
      "order finished\n",
      "0:09:28.063395\n",
      "0:00:18.604889\n",
      "20170913 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170913\n",
      "order finished\n",
      "0:07:15.304521\n",
      "0:00:20.941566\n",
      "20170914 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170914\n",
      "order finished\n",
      "0:08:00.919550\n",
      "0:00:21.197931\n",
      "20170915 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170915\n",
      "order finished\n",
      "0:07:54.420771\n",
      "0:00:18.767983\n",
      "20170918 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170918\n",
      "order finished\n",
      "0:07:29.646360\n",
      "0:00:23.006759\n",
      "20170919 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170919\n",
      "order finished\n",
      "0:07:43.727748\n",
      "0:00:21.299894\n",
      "20170920 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170920\n",
      "order finished\n",
      "0:08:02.956854\n",
      "0:00:21.525432\n",
      "20170921 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170921\n",
      "order finished\n",
      "0:08:15.625868\n",
      "0:00:20.269686\n",
      "20170922 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170922\n",
      "order finished\n",
      "0:07:37.612626\n",
      "0:00:19.273197\n",
      "20170925 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170925\n",
      "order finished\n",
      "0:06:57.024632\n",
      "0:00:23.681472\n",
      "20170926 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170926\n",
      "order finished\n",
      "0:06:41.239092\n",
      "0:00:18.631381\n",
      "20170927 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170927\n",
      "order finished\n",
      "0:06:51.292952\n",
      "0:00:19.400692\n",
      "20170928 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170928\n",
      "order finished\n",
      "0:07:07.017135\n",
      "0:00:19.557239\n",
      "20170929 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170929\n",
      "order finished\n",
      "0:06:52.378877\n",
      "0:00:25.546880\n",
      "20171009 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171009\n",
      "order finished\n",
      "0:07:18.623551\n",
      "0:00:19.855161\n",
      "20171010 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171010\n",
      "order finished\n",
      "0:07:42.000977\n",
      "0:00:23.048472\n",
      "20171011 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171011\n",
      "order finished\n",
      "0:08:31.564779\n",
      "0:01:15.681454\n",
      "20171012 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171012\n",
      "order finished\n",
      "0:07:29.961601\n",
      "0:00:28.903904\n",
      "20171013 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171013\n",
      "order finished\n",
      "0:07:07.461257\n",
      "0:00:21.697468\n",
      "20171016 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171016\n",
      "order finished\n",
      "0:07:59.961901\n",
      "0:00:20.460452\n",
      "20171017 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171017\n",
      "order finished\n",
      "0:06:24.354545\n",
      "0:00:18.442983\n",
      "20171018 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171018\n",
      "order finished\n",
      "0:06:33.765806\n",
      "0:00:18.592418\n",
      "20171019 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171019\n",
      "order finished\n",
      "0:06:49.486709\n",
      "0:00:21.094902\n",
      "20171020 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171020\n",
      "order finished\n",
      "0:05:52.281180\n",
      "0:00:19.020431\n",
      "20171023 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171023\n",
      "order finished\n",
      "0:06:10.175763\n",
      "0:00:17.167505\n",
      "20171024 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171024\n",
      "order finished\n",
      "0:06:14.177331\n",
      "0:00:17.791934\n",
      "20171025 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171025\n",
      "order finished\n",
      "0:06:09.242513\n",
      "0:00:21.365720\n",
      "20171026 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171026\n",
      "order finished\n",
      "0:07:01.620479\n",
      "0:00:19.830178\n",
      "20171027 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171027\n",
      "order finished\n",
      "0:06:36.909655\n",
      "0:00:29.826126\n",
      "20171030 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171030\n",
      "order finished\n",
      "0:07:34.322956\n",
      "0:00:18.345820\n",
      "20171031 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171031\n",
      "order finished\n",
      "0:06:14.734698\n",
      "0:00:17.546455\n",
      "20171101 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171101\n",
      "order finished\n",
      "0:06:44.310083\n",
      "0:00:42.997191\n",
      "20171102 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171102\n",
      "order finished\n",
      "0:06:36.998889\n",
      "0:00:22.524164\n",
      "20171103 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171103\n",
      "order finished\n",
      "0:06:43.889356\n",
      "0:00:24.168287\n",
      "20171106 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171106\n",
      "order finished\n",
      "0:06:51.058662\n",
      "0:00:31.714699\n",
      "20171107 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171107\n",
      "order finished\n",
      "0:07:00.244546\n",
      "0:00:29.526175\n",
      "20171108 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171108\n",
      "order finished\n",
      "0:08:17.874677\n",
      "0:00:19.725843\n",
      "20171109 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171109\n",
      "order finished\n",
      "0:07:22.810944\n",
      "0:00:37.289769\n",
      "20171110 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171110\n",
      "order finished\n",
      "0:07:50.039367\n",
      "0:00:22.803041\n",
      "20171113 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171113\n",
      "order finished\n",
      "0:08:05.752387\n",
      "0:01:54.770460\n",
      "20171114 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171114\n",
      "order finished\n",
      "0:08:03.827949\n",
      "0:01:36.129371\n",
      "20171115 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171115\n",
      "order finished\n",
      "0:07:35.959858\n",
      "0:01:40.705551\n",
      "20171116 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171116\n",
      "order finished\n",
      "0:07:31.786451\n",
      "0:00:19.630365\n",
      "20171117 unzip finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-20cbd166b943>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SecurityID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mOrderLog\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mOrderLog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOrderLog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0mOrderLog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderLog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOrderLog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ChannelNo\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "readPath = '/home/work516/day_stock/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "db = pd.DataFrame()\n",
    "for p in dataPathLs:\n",
    "    dayData = pd.read_csv(p, compression='gzip')\n",
    "    db = pd.concat([db, dayData])\n",
    "print(datetime.datetime.now() - startTm)\n",
    "\n",
    "year = \"2017\"\n",
    "startDate = '20170901'\n",
    "endDate = '20171231'\n",
    "readPath = '/mnt/usb/data/' + year + '/***/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "less = []\n",
    "\n",
    "for data in dataPathLs:\n",
    "    \n",
    "    \n",
    "    if len(np.array(glob.glob(data + '/SZ/***'))) == 0:\n",
    "        if int(os.path.basename(data)) not in date_list[\"Date\"].values:\n",
    "            continue\n",
    "        else:\n",
    "            print(os.path.basename(data) + \" less data!!!!!!!!!!!!!!!!!\")\n",
    "            less.append(data)\n",
    "            continue\n",
    "    startTm = datetime.datetime.now()\n",
    "    date = os.path.basename(data)\n",
    "    rar_path = data + '/SZ/order.7z'\n",
    "    path = '/mnt/e/unzip_data/2017/SZ'\n",
    "    path1 = path + '/' + date\n",
    "    un_path = path1\n",
    "    cmd = '7za x {} -o{}'.format(rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    print(date + ' unzip finished')\n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    \n",
    "    readPath = path1 + '/order/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs < 4000) | ((dateLs > 300000) & (dateLs < 310000))]\n",
    "    OrderLog = []\n",
    "    ll = []\n",
    "    \n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i, encoding='GBK')\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"SecurityID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        OrderLog += [df]\n",
    "    OrderLog = pd.concat(OrderLog).reset_index(drop=True)\n",
    "    OrderLog = OrderLog[OrderLog[\"ChannelNo\"] != 4001]\n",
    "    \n",
    "    OrderLog = OrderLog.rename(columns={\"OrdType\": \"OrderType\"})\n",
    "    OrderLog[\"date\"] = OrderLog[\"TransactTime\"].iloc[0]//1000000000\n",
    "    OrderLog[\"OrderType\"] = np.where(OrderLog[\"OrderType\"] == 'U', 3, OrderLog[\"OrderType\"])\n",
    "    OrderLog[\"skey\"] = OrderLog[\"SecurityID\"] + 2000000\n",
    "    OrderLog[\"clockAtArrival\"] = OrderLog[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    OrderLog['datetime'] = OrderLog[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    OrderLog[\"time\"] = (OrderLog['TransactTime'] - int(OrderLog['TransactTime'].iloc[0]//1000000000*1000000000)).astype(np.int64)*1000\n",
    "    \n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"OrderQty\", \"Side\", \"OrderType\"]:\n",
    "        OrderLog[col] = OrderLog[col].astype('int32')\n",
    "#     for cols in [\"Price\"]:\n",
    "#         print(cols)\n",
    "#         print(OrderLog[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "    \n",
    "    assert(OrderLog[((OrderLog[\"Side\"] != 1) & (OrderLog[\"Side\"] != 2)) | (OrderLog[\"OrderType\"].isnull())].shape[0] == 0)\n",
    "    da_te = str(OrderLog[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    sl = (db1[\"ID\"].str[2:].astype(int) + 2000000).unique()\n",
    "    del db1\n",
    "    try:\n",
    "        assert(len(set(sl) - set(OrderLog[\"skey\"].unique())) == 0)\n",
    "    except:\n",
    "        print(\"less stocks\")\n",
    "        display(set(sl) - set(OrderLog[\"skey\"].unique()))\n",
    "    if len(set(OrderLog[\"skey\"].unique()) - set(sl)) != 0:\n",
    "        print(\"more stocks\")\n",
    "        print(set(OrderLog[\"skey\"].unique()) - set(sl))\n",
    "    \n",
    "    OrderLog = OrderLog.rename(columns={\"Side\":\"order_side\", \"OrderType\":\"order_type\", \"Price\":\"order_price\", \"OrderQty\":\"order_qty\"})\n",
    "    OrderLog = OrderLog[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"order_side\", \"order_type\", \"order_price\",\n",
    "                                                 \"order_qty\"]]\n",
    "    \n",
    "    print(OrderLog[\"date\"].iloc[0])\n",
    "    print(\"order finished\")\n",
    "\n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    db1 = DB(\"192.168.10.223\", database_name, user, password)\n",
    "    db1.write('md_order', OrderLog)\n",
    "    \n",
    "    del OrderLog\n",
    "    \n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "#     pd.set_option(\"max_rows\", 200)\n",
    "#     display(OrderLog.dtypes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:195: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:04:44.635741\n",
      "0:00:19.382055\n",
      "20171117 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171117\n",
      "order finished\n",
      "0:08:17.026919\n",
      "0:00:16.400086\n",
      "20171120 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171120\n",
      "order finished\n",
      "0:06:46.243236\n",
      "0:00:19.146173\n",
      "20171121 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171121\n",
      "order finished\n",
      "0:07:41.460746\n",
      "0:00:18.682503\n",
      "20171122 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171122\n",
      "order finished\n",
      "0:07:55.932529\n",
      "0:00:19.052622\n",
      "20171123 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171123\n",
      "order finished\n",
      "0:07:40.804100\n",
      "0:00:17.234268\n",
      "20171124 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171124\n",
      "order finished\n",
      "0:06:25.847623\n",
      "0:00:19.348507\n",
      "20171127 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171127\n",
      "order finished\n",
      "0:06:00.215878\n",
      "0:00:15.424651\n",
      "20171128 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171128\n",
      "order finished\n",
      "0:06:40.725272\n",
      "0:00:16.346202\n",
      "20171129 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171129\n",
      "order finished\n",
      "0:06:29.476386\n",
      "0:00:17.020726\n",
      "20171130 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171130\n",
      "order finished\n",
      "0:06:16.511944\n",
      "0:00:15.940252\n",
      "20171201 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171201\n",
      "order finished\n",
      "0:06:12.626145\n",
      "0:00:16.630455\n",
      "20171204 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171204\n",
      "order finished\n",
      "0:07:28.472688\n",
      "0:00:19.339368\n",
      "20171205 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171205\n",
      "order finished\n",
      "0:07:05.536547\n",
      "0:00:20.841208\n",
      "20171206 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171206\n",
      "order finished\n",
      "0:06:27.043340\n",
      "0:00:20.667314\n",
      "20171207 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171207\n",
      "order finished\n",
      "0:06:00.631903\n",
      "0:00:18.339043\n",
      "20171208 unzip finished\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "readPath = '/home/work516/day_stock/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "db = pd.DataFrame()\n",
    "for p in dataPathLs:\n",
    "    dayData = pd.read_csv(p, compression='gzip')\n",
    "    db = pd.concat([db, dayData])\n",
    "print(datetime.datetime.now() - startTm)\n",
    "\n",
    "year = \"2017\"\n",
    "startDate = '20171117'\n",
    "endDate = '20171231'\n",
    "readPath = '/mnt/usb/data/' + year + '/***/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "less = []\n",
    "\n",
    "for data in dataPathLs:\n",
    "    \n",
    "    \n",
    "    if len(np.array(glob.glob(data + '/SZ/***'))) == 0:\n",
    "        if int(os.path.basename(data)) not in date_list[\"Date\"].values:\n",
    "            continue\n",
    "        else:\n",
    "            print(os.path.basename(data) + \" less data!!!!!!!!!!!!!!!!!\")\n",
    "            less.append(data)\n",
    "            continue\n",
    "    startTm = datetime.datetime.now()\n",
    "    date = os.path.basename(data)\n",
    "    rar_path = data + '/SZ/order.7z'\n",
    "    path = '/mnt/e/unzip_data/2017/SZ'\n",
    "    path1 = path + '/' + date\n",
    "    un_path = path1\n",
    "    cmd = '7za x {} -o{}'.format(rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    print(date + ' unzip finished')\n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    \n",
    "    readPath = path1 + '/order/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs < 4000) | ((dateLs > 300000) & (dateLs < 310000))]\n",
    "    OrderLog = []\n",
    "    ll = []\n",
    "    \n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i, encoding='GBK')\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"SecurityID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        OrderLog += [df]\n",
    "    OrderLog = pd.concat(OrderLog).reset_index(drop=True)\n",
    "    OrderLog = OrderLog[OrderLog[\"ChannelNo\"] != 4001]\n",
    "    \n",
    "    OrderLog = OrderLog.rename(columns={\"OrdType\": \"OrderType\"})\n",
    "    OrderLog[\"date\"] = OrderLog[\"TransactTime\"].iloc[0]//1000000000\n",
    "    OrderLog[\"OrderType\"] = np.where(OrderLog[\"OrderType\"] == 'U', 3, OrderLog[\"OrderType\"])\n",
    "    OrderLog[\"skey\"] = OrderLog[\"SecurityID\"] + 2000000\n",
    "    OrderLog[\"clockAtArrival\"] = OrderLog[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    OrderLog['datetime'] = OrderLog[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    OrderLog[\"time\"] = (OrderLog['TransactTime'] - int(OrderLog['TransactTime'].iloc[0]//1000000000*1000000000)).astype(np.int64)*1000\n",
    "    \n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"OrderQty\", \"Side\", \"OrderType\"]:\n",
    "        OrderLog[col] = OrderLog[col].astype('int32')\n",
    "#     for cols in [\"Price\"]:\n",
    "#         print(cols)\n",
    "#         print(OrderLog[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "    \n",
    "    assert(OrderLog[((OrderLog[\"Side\"] != 1) & (OrderLog[\"Side\"] != 2)) | (OrderLog[\"OrderType\"].isnull())].shape[0] == 0)\n",
    "    da_te = str(OrderLog[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    sl = (db1[\"ID\"].str[2:].astype(int) + 2000000).unique()\n",
    "    del db1\n",
    "    try:\n",
    "        assert(len(set(sl) - set(OrderLog[\"skey\"].unique())) == 0)\n",
    "    except:\n",
    "        print(\"less stocks\")\n",
    "        display(set(sl) - set(OrderLog[\"skey\"].unique()))\n",
    "    if len(set(OrderLog[\"skey\"].unique()) - set(sl)) != 0:\n",
    "        print(\"more stocks\")\n",
    "        print(set(OrderLog[\"skey\"].unique()) - set(sl))\n",
    "    \n",
    "    OrderLog = OrderLog.rename(columns={\"Side\":\"order_side\", \"OrderType\":\"order_type\", \"Price\":\"order_price\", \"OrderQty\":\"order_qty\"})\n",
    "    OrderLog = OrderLog[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"order_side\", \"order_type\", \"order_price\",\n",
    "                                                 \"order_qty\"]]\n",
    "    \n",
    "    print(OrderLog[\"date\"].iloc[0])\n",
    "    print(\"order finished\")\n",
    "\n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    db1 = DB(\"192.168.10.223\", database_name, user, password)\n",
    "    db1.write('md_order', OrderLog)\n",
    "    \n",
    "    del OrderLog\n",
    "    \n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "#     pd.set_option(\"max_rows\", 200)\n",
    "#     display(OrderLog.dtypes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:195: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:06:21.279861\n",
      "0:00:00.449144\n",
      "20171207 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171207\n",
      "order finished\n",
      "0:06:23.511890\n",
      "0:00:00.843641\n",
      "20171208 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171208\n",
      "order finished\n",
      "0:07:01.909869\n",
      "0:00:00.432961\n",
      "20171211 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (1,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171211\n",
      "order finished\n",
      "0:06:37.205144\n",
      "0:00:00.438255\n",
      "20171212 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171212\n",
      "order finished\n",
      "0:06:48.356236\n",
      "0:00:00.379938\n",
      "20171213 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171213\n",
      "order finished\n",
      "0:05:35.669396\n",
      "0:00:15.445587\n",
      "20171214 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171214\n",
      "order finished\n",
      "0:05:53.395458\n",
      "0:00:18.267237\n",
      "20171215 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171215\n",
      "order finished\n",
      "0:06:12.183349\n",
      "0:00:16.789061\n",
      "20171218 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171218\n",
      "order finished\n",
      "0:05:41.642334\n",
      "0:00:14.336990\n",
      "20171219 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171219\n",
      "order finished\n",
      "0:05:23.808078\n",
      "0:00:15.481196\n",
      "20171220 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171220\n",
      "order finished\n",
      "0:05:37.826269\n",
      "0:00:15.700688\n",
      "20171221 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171221\n",
      "order finished\n",
      "0:05:53.249613\n",
      "0:00:18.953655\n",
      "20171222 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171222\n",
      "order finished\n",
      "0:05:22.868228\n",
      "0:00:15.742478\n",
      "20171225 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171225\n",
      "order finished\n",
      "0:05:48.593555\n",
      "0:00:15.526567\n",
      "20171226 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171226\n",
      "order finished\n",
      "0:05:42.580268\n",
      "0:00:16.428841\n",
      "20171227 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171227\n",
      "order finished\n",
      "0:06:11.443631\n",
      "0:00:16.376430\n",
      "20171228 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171228\n",
      "order finished\n",
      "0:06:28.620900\n",
      "0:00:15.981398\n",
      "20171229 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171229\n",
      "order finished\n",
      "0:05:46.854041\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "readPath = '/home/work516/day_stock/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "db = pd.DataFrame()\n",
    "for p in dataPathLs:\n",
    "    dayData = pd.read_csv(p, compression='gzip')\n",
    "    db = pd.concat([db, dayData])\n",
    "print(datetime.datetime.now() - startTm)\n",
    "\n",
    "year = \"2017\"\n",
    "startDate = '20171207'\n",
    "endDate = '20171231'\n",
    "readPath = '/mnt/usb/data/' + year + '/***/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "less = []\n",
    "\n",
    "for data in dataPathLs:\n",
    "    \n",
    "    \n",
    "    if len(np.array(glob.glob(data + '/SZ/***'))) == 0:\n",
    "        if int(os.path.basename(data)) not in date_list[\"Date\"].values:\n",
    "            continue\n",
    "        else:\n",
    "            print(os.path.basename(data) + \" less data!!!!!!!!!!!!!!!!!\")\n",
    "            less.append(data)\n",
    "            continue\n",
    "    startTm = datetime.datetime.now()\n",
    "    date = os.path.basename(data)\n",
    "    rar_path = data + '/SZ/order.7z'\n",
    "    path = '/mnt/e/unzip_data/2017/SZ'\n",
    "    path1 = path + '/' + date\n",
    "    un_path = path1\n",
    "    cmd = '7za x {} -o{}'.format(rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    print(date + ' unzip finished')\n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    \n",
    "    readPath = path1 + '/order/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs < 4000) | ((dateLs > 300000) & (dateLs < 310000))]\n",
    "    OrderLog = []\n",
    "    ll = []\n",
    "    \n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i, encoding='GBK')\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"SecurityID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        OrderLog += [df]\n",
    "    OrderLog = pd.concat(OrderLog).reset_index(drop=True)\n",
    "    OrderLog = OrderLog[OrderLog[\"ChannelNo\"] != 4001]\n",
    "    \n",
    "    OrderLog = OrderLog.rename(columns={\"OrdType\": \"OrderType\"})\n",
    "    OrderLog[\"date\"] = OrderLog[\"TransactTime\"].iloc[0]//1000000000\n",
    "    OrderLog[\"OrderType\"] = np.where(OrderLog[\"OrderType\"] == 'U', 3, OrderLog[\"OrderType\"])\n",
    "    OrderLog[\"skey\"] = OrderLog[\"SecurityID\"] + 2000000\n",
    "    OrderLog[\"clockAtArrival\"] = OrderLog[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    OrderLog['datetime'] = OrderLog[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    OrderLog[\"time\"] = (OrderLog['TransactTime'] - int(OrderLog['TransactTime'].iloc[0]//1000000000*1000000000)).astype(np.int64)*1000\n",
    "    \n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"OrderQty\", \"Side\", \"OrderType\"]:\n",
    "        OrderLog[col] = OrderLog[col].astype('int32')\n",
    "#     for cols in [\"Price\"]:\n",
    "#         print(cols)\n",
    "#         print(OrderLog[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "    \n",
    "    assert(OrderLog[((OrderLog[\"Side\"] != 1) & (OrderLog[\"Side\"] != 2)) | (OrderLog[\"OrderType\"].isnull())].shape[0] == 0)\n",
    "    da_te = str(OrderLog[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    sl = (db1[\"ID\"].str[2:].astype(int) + 2000000).unique()\n",
    "    del db1\n",
    "    try:\n",
    "        assert(len(set(sl) - set(OrderLog[\"skey\"].unique())) == 0)\n",
    "    except:\n",
    "        print(\"less stocks\")\n",
    "        display(set(sl) - set(OrderLog[\"skey\"].unique()))\n",
    "    if len(set(OrderLog[\"skey\"].unique()) - set(sl)) != 0:\n",
    "        print(\"more stocks\")\n",
    "        print(set(OrderLog[\"skey\"].unique()) - set(sl))\n",
    "    \n",
    "    OrderLog = OrderLog.rename(columns={\"Side\":\"order_side\", \"OrderType\":\"order_type\", \"Price\":\"order_price\", \"OrderQty\":\"order_qty\"})\n",
    "    OrderLog = OrderLog[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"order_side\", \"order_type\", \"order_price\",\n",
    "                                                 \"order_qty\"]]\n",
    "    \n",
    "    print(OrderLog[\"date\"].iloc[0])\n",
    "    print(\"order finished\")\n",
    "\n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    db1 = DB(\"192.168.10.223\", database_name, user, password)\n",
    "    db1.write('md_order', OrderLog)\n",
    "    \n",
    "    del OrderLog\n",
    "    \n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "#     pd.set_option(\"max_rows\", 200)\n",
    "#     display(OrderLog.dtypes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:177: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:05:27.019539\n",
      "0:00:15.261566\n",
      "20180102 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180102\n",
      "order finished\n",
      "0:05:20.148924\n",
      "0:00:18.443840\n",
      "20180103 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180103\n",
      "order finished\n",
      "0:06:46.281167\n",
      "0:00:16.408613\n",
      "20180104 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180104\n",
      "order finished\n",
      "0:06:13.494110\n",
      "0:00:16.065804\n",
      "20180105 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180105\n",
      "order finished\n",
      "0:06:08.911434\n",
      "0:00:16.527113\n",
      "20180108 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180108\n",
      "order finished\n",
      "0:06:25.142429\n",
      "0:00:15.676600\n",
      "20180109 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180109\n",
      "order finished\n",
      "0:06:21.597419\n",
      "0:00:19.048002\n",
      "20180110 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180110\n",
      "order finished\n",
      "0:06:38.901671\n",
      "0:00:17.238399\n",
      "20180111 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180111\n",
      "order finished\n",
      "0:06:40.423588\n",
      "0:00:22.325239\n",
      "20180112 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180112\n",
      "order finished\n",
      "0:06:15.221123\n",
      "0:00:18.444350\n",
      "20180115 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180115\n",
      "order finished\n",
      "0:07:05.444892\n",
      "0:00:16.510426\n",
      "20180116 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180116\n",
      "order finished\n",
      "0:06:26.723757\n",
      "0:00:19.135810\n",
      "20180117 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (1,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180117\n",
      "order finished\n",
      "0:07:30.839039\n",
      "0:00:15.958015\n",
      "20180118 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180118\n",
      "order finished\n",
      "0:05:49.210835\n",
      "0:00:16.633041\n",
      "20180119 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180119\n",
      "order finished\n",
      "0:06:03.494841\n",
      "0:00:17.245802\n",
      "20180122 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180122\n",
      "order finished\n",
      "0:06:14.780511\n",
      "0:00:16.119549\n",
      "20180123 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180123\n",
      "order finished\n",
      "0:06:06.367385\n",
      "0:00:19.997868\n",
      "20180124 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180124\n",
      "order finished\n",
      "0:07:01.167360\n",
      "0:00:19.813490\n",
      "20180125 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (6,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180125\n",
      "order finished\n",
      "0:07:22.952835\n",
      "0:00:16.548694\n",
      "20180126 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180126\n",
      "order finished\n",
      "0:06:10.249547\n",
      "0:00:17.690573\n",
      "20180129 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180129\n",
      "order finished\n",
      "0:06:31.385331\n",
      "0:00:16.091478\n",
      "20180130 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180130\n",
      "order finished\n",
      "0:05:34.177123\n",
      "0:00:15.955127\n",
      "20180131 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180131\n",
      "order finished\n",
      "0:06:20.480684\n",
      "0:00:17.565088\n",
      "20180201 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180201\n",
      "order finished\n",
      "0:06:43.062987\n",
      "0:00:15.877069\n",
      "20180202 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180202\n",
      "order finished\n",
      "0:05:39.833827\n",
      "0:00:15.050018\n",
      "20180205 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180205\n",
      "order finished\n",
      "0:05:04.167137\n",
      "0:00:17.003395\n",
      "20180206 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180206\n",
      "order finished\n",
      "0:05:59.321689\n",
      "0:00:15.786458\n",
      "20180207 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180207\n",
      "order finished\n",
      "0:05:53.222993\n",
      "0:00:14.151549\n",
      "20180208 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180208\n",
      "order finished\n",
      "0:05:16.285365\n",
      "0:00:15.736174\n",
      "20180209 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180209\n",
      "order finished\n",
      "0:05:58.165742\n",
      "0:00:13.103288\n",
      "20180212 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180212\n",
      "order finished\n",
      "0:04:40.026146\n",
      "0:00:13.055207\n",
      "20180213 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180213\n",
      "order finished\n",
      "0:04:37.459528\n",
      "0:00:10.937269\n",
      "20180214 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180214\n",
      "order finished\n",
      "0:03:37.664909\n",
      "0:00:12.534550\n",
      "20180222 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180222\n",
      "order finished\n",
      "0:04:24.582347\n",
      "0:00:12.750247\n",
      "20180223 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180223\n",
      "order finished\n",
      "0:04:51.587619\n",
      "0:00:15.779228\n",
      "20180226 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180226\n",
      "order finished\n",
      "0:06:06.479273\n",
      "0:00:17.757917\n",
      "20180227 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180227\n",
      "order finished\n",
      "0:06:33.179746\n",
      "0:00:17.345650\n",
      "20180228 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180228\n",
      "order finished\n",
      "0:06:22.642316\n",
      "0:00:17.676001\n",
      "20180301 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180301\n",
      "order finished\n",
      "0:06:33.434194\n",
      "0:00:16.198069\n",
      "20180302 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180302\n",
      "order finished\n",
      "0:06:28.432628\n",
      "0:00:15.926401\n",
      "20180305 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180305\n",
      "order finished\n",
      "0:05:46.409953\n",
      "0:00:19.398650\n",
      "20180306 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180306\n",
      "order finished\n",
      "0:06:57.411389\n",
      "0:00:16.809244\n",
      "20180307 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180307\n",
      "order finished\n",
      "0:06:28.516157\n",
      "0:00:16.024746\n",
      "20180308 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180308\n",
      "order finished\n",
      "0:06:15.604881\n",
      "0:00:19.204001\n",
      "20180309 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180309\n",
      "order finished\n",
      "0:07:28.994862\n",
      "0:00:21.068572\n",
      "20180312 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180312\n",
      "order finished\n",
      "0:08:05.748117\n",
      "0:00:19.816021\n",
      "20180313 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180313\n",
      "order finished\n",
      "0:07:59.237378\n",
      "0:00:18.312332\n",
      "20180314 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180314\n",
      "order finished\n",
      "0:07:01.847033\n",
      "0:00:18.328504\n",
      "20180315 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180315\n",
      "order finished\n",
      "0:07:11.379725\n",
      "0:00:16.395514\n",
      "20180316 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180316\n",
      "order finished\n",
      "0:06:17.441992\n",
      "0:00:15.928405\n",
      "20180319 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180319\n",
      "order finished\n",
      "0:06:02.673082\n",
      "0:00:16.532107\n",
      "20180320 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180320\n",
      "order finished\n",
      "0:06:26.531484\n",
      "0:00:18.493716\n",
      "20180321 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180321\n",
      "order finished\n",
      "0:07:18.875221\n",
      "0:00:17.054693\n",
      "20180322 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180322\n",
      "order finished\n",
      "0:06:25.286991\n",
      "0:00:20.989584\n",
      "20180323 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180323\n",
      "order finished\n",
      "0:08:22.147048\n",
      "0:00:17.639570\n",
      "20180326 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180326\n",
      "order finished\n",
      "0:06:33.937945\n",
      "0:00:19.286927\n",
      "20180327 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180327\n",
      "order finished\n",
      "0:07:39.787753\n",
      "0:00:18.999646\n",
      "20180328 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180328\n",
      "order finished\n",
      "0:07:38.498647\n",
      "0:00:18.442396\n",
      "20180329 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180329\n",
      "order finished\n",
      "0:07:15.415938\n",
      "0:00:19.842264\n",
      "20180330 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180330\n",
      "order finished\n",
      "0:07:17.809251\n",
      "0:00:21.407315\n",
      "20180402 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180402\n",
      "order finished\n",
      "0:08:23.933893\n",
      "0:00:19.415656\n",
      "20180403 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180403\n",
      "order finished\n",
      "0:07:50.418525\n",
      "0:00:19.140316\n",
      "20180404 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180404\n",
      "order finished\n",
      "0:07:23.704858\n",
      "0:00:17.608209\n",
      "20180409 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180409\n",
      "order finished\n",
      "0:06:48.984520\n",
      "0:00:18.803542\n",
      "20180410 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180410\n",
      "order finished\n",
      "0:07:19.915465\n",
      "0:00:18.863933\n",
      "20180411 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180411\n",
      "order finished\n",
      "0:07:04.017052\n",
      "0:00:18.268056\n",
      "20180412 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180412\n",
      "order finished\n",
      "0:07:05.007878\n",
      "0:00:17.311854\n",
      "20180413 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180413\n",
      "order finished\n",
      "0:06:29.447978\n",
      "0:00:17.619171\n",
      "20180416 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180416\n",
      "order finished\n",
      "0:06:57.831247\n",
      "0:00:18.530960\n",
      "20180417 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180417\n",
      "order finished\n",
      "0:07:17.534560\n",
      "0:00:19.380596\n",
      "20180418 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180418\n",
      "order finished\n",
      "0:07:33.473407\n",
      "0:00:19.495587\n",
      "20180419 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180419\n",
      "order finished\n",
      "0:07:11.932020\n",
      "0:00:18.312387\n",
      "20180420 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180420\n",
      "order finished\n",
      "0:07:03.050035\n",
      "0:00:17.843980\n",
      "20180423 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180423\n",
      "order finished\n",
      "0:06:34.339163\n",
      "0:00:19.094354\n",
      "20180424 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180424\n",
      "order finished\n",
      "0:06:59.174439\n",
      "0:00:18.349650\n",
      "20180425 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180425\n",
      "order finished\n",
      "0:07:03.201285\n",
      "0:00:20.187256\n",
      "20180426 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180426\n",
      "order finished\n",
      "0:06:52.571916\n",
      "0:00:16.542483\n",
      "20180427 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180427\n",
      "order finished\n",
      "0:06:19.740968\n",
      "0:00:15.664752\n",
      "20180502 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180502\n",
      "order finished\n",
      "0:06:04.928007\n",
      "0:00:17.472913\n",
      "20180503 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180503\n",
      "order finished\n",
      "0:06:37.835006\n",
      "0:00:16.077413\n",
      "20180504 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180504\n",
      "order finished\n",
      "0:06:21.866788\n",
      "0:00:16.453385\n",
      "20180507 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180507\n",
      "order finished\n",
      "0:06:30.859304\n",
      "0:00:18.084797\n",
      "20180508 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180508\n",
      "order finished\n",
      "0:07:14.780327\n",
      "0:00:16.922069\n",
      "20180509 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180509\n",
      "order finished\n",
      "0:06:38.625565\n",
      "0:00:18.190436\n",
      "20180510 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180510\n",
      "order finished\n",
      "0:06:51.992188\n",
      "0:00:17.960428\n",
      "20180511 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180511\n",
      "order finished\n",
      "0:06:54.328733\n",
      "0:00:15.996475\n",
      "20180514 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180514\n",
      "order finished\n",
      "0:06:25.874431\n",
      "0:00:15.932719\n",
      "20180515 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180515\n",
      "order finished\n",
      "0:06:07.679163\n",
      "0:00:18.276837\n",
      "20180516 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180516\n",
      "order finished\n",
      "0:06:19.942097\n",
      "0:00:15.753956\n",
      "20180517 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180517\n",
      "order finished\n",
      "0:06:05.344541\n",
      "0:00:16.815732\n",
      "20180518 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180518\n",
      "order finished\n",
      "0:06:07.974394\n",
      "0:00:17.661990\n",
      "20180521 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180521\n",
      "order finished\n",
      "0:06:57.528936\n",
      "0:00:18.040902\n",
      "20180522 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180522\n",
      "order finished\n",
      "0:06:58.899012\n",
      "0:00:18.784033\n",
      "20180523 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180523\n",
      "order finished\n",
      "0:07:28.093350\n",
      "0:00:16.704679\n",
      "20180524 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180524\n",
      "order finished\n",
      "0:06:25.777311\n",
      "0:00:17.355552\n",
      "20180525 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180525\n",
      "order finished\n",
      "0:06:44.429939\n",
      "0:00:16.928164\n",
      "20180528 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180528\n",
      "order finished\n",
      "0:06:52.453413\n",
      "0:00:18.310608\n",
      "20180529 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180529\n",
      "order finished\n",
      "0:06:41.237046\n",
      "0:00:17.193978\n",
      "20180530 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180530\n",
      "order finished\n",
      "0:07:06.415700\n",
      "0:00:16.239665\n",
      "20180531 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180531\n",
      "order finished\n",
      "0:06:24.432930\n",
      "0:00:16.870324\n",
      "20180601 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180601\n",
      "order finished\n",
      "0:06:20.536785\n",
      "0:00:14.875665\n",
      "20180604 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180604\n",
      "order finished\n",
      "0:05:43.265163\n",
      "0:00:15.541596\n",
      "20180605 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180605\n",
      "order finished\n",
      "0:06:08.006074\n",
      "0:00:15.547180\n",
      "20180606 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180606\n",
      "order finished\n",
      "0:06:06.398417\n",
      "0:00:15.358212\n",
      "20180607 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180607\n",
      "order finished\n",
      "0:06:02.611598\n",
      "0:00:15.749122\n",
      "20180608 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180608\n",
      "order finished\n",
      "0:06:12.867474\n",
      "0:00:13.404895\n",
      "20180611 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180611\n",
      "order finished\n",
      "0:05:41.136380\n",
      "0:00:14.842294\n",
      "20180612 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180612\n",
      "order finished\n",
      "0:06:13.220974\n",
      "0:00:14.957685\n",
      "20180613 unzip finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (6,11,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180613\n",
      "order finished\n",
      "0:05:55.368262\n",
      "0:00:14.424780\n",
      "20180614 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180614\n",
      "order finished\n",
      "0:05:25.343731\n",
      "0:00:15.604853\n",
      "20180615 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180615\n",
      "order finished\n",
      "0:06:04.562583\n",
      "0:00:16.960267\n",
      "20180619 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180619\n",
      "order finished\n",
      "0:06:36.961886\n",
      "0:00:16.458245\n",
      "20180620 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180620\n",
      "order finished\n",
      "0:06:05.777486\n",
      "0:00:15.744724\n",
      "20180621 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180621\n",
      "order finished\n",
      "0:06:17.036410\n",
      "0:00:14.522742\n",
      "20180622 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180622\n",
      "order finished\n",
      "0:05:47.975341\n",
      "0:00:13.908047\n",
      "20180625 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180625\n",
      "order finished\n",
      "0:05:38.426917\n",
      "0:00:16.076314\n",
      "20180626 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180626\n",
      "order finished\n",
      "0:06:07.860806\n",
      "0:00:15.193149\n",
      "20180627 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180627\n",
      "order finished\n",
      "0:06:06.798470\n",
      "0:00:14.993349\n",
      "20180628 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180628\n",
      "order finished\n",
      "0:05:51.721587\n",
      "0:00:16.372911\n",
      "20180629 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180629\n",
      "order finished\n",
      "0:06:26.937653\n",
      "0:00:15.654776\n",
      "20180702 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180702\n",
      "order finished\n",
      "0:06:25.834728\n",
      "0:00:17.615437\n",
      "20180703 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180703\n",
      "order finished\n",
      "0:06:58.338099\n",
      "0:00:15.569742\n",
      "20180704 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180704\n",
      "order finished\n",
      "0:06:07.356209\n",
      "0:00:14.743653\n",
      "20180705 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180705\n",
      "order finished\n",
      "0:06:10.911651\n",
      "0:00:16.123562\n",
      "20180706 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180706\n",
      "order finished\n",
      "0:06:17.787481\n",
      "0:00:14.904952\n",
      "20180709 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180709\n",
      "order finished\n",
      "0:05:37.836228\n",
      "0:00:15.350420\n",
      "20180710 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180710\n",
      "order finished\n",
      "0:05:50.363044\n",
      "0:00:16.892843\n",
      "20180711 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180711\n",
      "order finished\n",
      "0:06:01.914301\n",
      "0:00:17.562680\n",
      "20180712 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180712\n",
      "order finished\n",
      "0:06:48.496495\n",
      "0:00:15.724632\n",
      "20180713 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180713\n",
      "order finished\n",
      "0:06:16.809287\n",
      "0:00:14.537138\n",
      "20180716 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180716\n",
      "order finished\n",
      "0:05:47.812167\n",
      "0:00:14.616277\n",
      "20180717 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180717\n",
      "order finished\n",
      "0:05:44.168600\n",
      "0:00:15.129265\n",
      "20180718 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180718\n",
      "order finished\n",
      "0:05:59.104202\n",
      "0:00:14.984794\n",
      "20180719 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180719\n",
      "order finished\n",
      "0:05:33.157577\n",
      "0:00:15.954371\n",
      "20180720 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180720\n",
      "order finished\n",
      "0:05:46.957150\n",
      "0:00:15.797503\n",
      "20180723 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180723\n",
      "order finished\n",
      "0:06:22.224145\n",
      "0:00:17.735208\n",
      "20180724 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180724\n",
      "order finished\n",
      "0:07:09.315471\n",
      "0:00:16.386070\n",
      "20180725 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180725\n",
      "order finished\n",
      "0:06:40.481096\n",
      "0:00:18.766378\n",
      "20180726 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180726\n",
      "order finished\n",
      "0:06:44.215940\n",
      "0:00:14.407674\n",
      "20180727 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180727\n",
      "order finished\n",
      "0:05:40.812098\n",
      "0:00:14.548657\n",
      "20180730 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180730\n",
      "order finished\n",
      "0:05:46.041285\n",
      "0:00:12.925391\n",
      "20180731 unzip finished\n",
      "less stocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2001872, 2001914}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180731\n",
      "order finished\n",
      "0:05:05.725817\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "class DB(object):\n",
    "    def __init__(self, uri, symbol_column='skey'):\n",
    "        self.db_name = 'white_db'\n",
    "        user, passwd, host = self.parse_uri(uri)\n",
    "        auth_db = 'admin' if user in ('admin', 'root') else self.db_name\n",
    "        self.uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "readPath = '/home/work516/day_stock/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dataPathLs = dataPathLs[[np.array([os.path.basename(i).split('.')[0][:2] == 'SZ' for i in dataPathLs])]]\n",
    "db = pd.DataFrame()\n",
    "for p in dataPathLs:\n",
    "    dayData = pd.read_csv(p, compression='gzip')\n",
    "    db = pd.concat([db, dayData])\n",
    "print(datetime.datetime.now() - startTm)\n",
    "\n",
    "year = \"2018\"\n",
    "startDate = '20180102'\n",
    "endDate = '20180731'\n",
    "readPath = '/mnt/usb/' + year + '/***/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "less = []\n",
    "\n",
    "for data in dataPathLs:\n",
    "    \n",
    "    \n",
    "    if len(np.array(glob.glob(data + '/SZ/***'))) == 0:\n",
    "        if int(os.path.basename(data)) not in date_list[\"Date\"].values:\n",
    "            continue\n",
    "        else:\n",
    "            print(os.path.basename(data) + \" less data!!!!!!!!!!!!!!!!!\")\n",
    "            less.append(data)\n",
    "            continue\n",
    "    startTm = datetime.datetime.now()\n",
    "    date = os.path.basename(data)\n",
    "    rar_path = data + '/SZ/order.7z'\n",
    "    path = '/mnt/e/unzip_data/2018/SZ'\n",
    "    path1 = path + '/' + date\n",
    "    un_path = path1\n",
    "    cmd = '7za x {} -o{}'.format(rar_path, un_path)\n",
    "    os.system(cmd)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    print(date + ' unzip finished')\n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    \n",
    "    readPath = path1 + '/order/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs < 4000) | ((dateLs > 300000) & (dateLs < 310000))]\n",
    "    OrderLog = []\n",
    "    ll = []\n",
    "    \n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i, encoding='GBK')\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        df[\"SecurityID\"] = int(os.path.basename(i).split('.')[0])\n",
    "        OrderLog += [df]\n",
    "    OrderLog = pd.concat(OrderLog).reset_index(drop=True)\n",
    "    OrderLog = OrderLog[OrderLog[\"ChannelNo\"] != 4001]\n",
    "    \n",
    "    OrderLog = OrderLog.rename(columns={\"OrdType\": \"OrderType\"})\n",
    "    OrderLog[\"date\"] = OrderLog[\"TransactTime\"].iloc[0]//1000000000\n",
    "    OrderLog[\"OrderType\"] = np.where(OrderLog[\"OrderType\"] == 'U', 3, OrderLog[\"OrderType\"])\n",
    "    OrderLog[\"skey\"] = OrderLog[\"SecurityID\"] + 2000000\n",
    "    OrderLog[\"clockAtArrival\"] = OrderLog[\"TransactTime\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    OrderLog['datetime'] = OrderLog[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    OrderLog[\"time\"] = (OrderLog['TransactTime'] - int(OrderLog['TransactTime'].iloc[0]//1000000000*1000000000)).astype(np.int64)*1000\n",
    "    \n",
    "    for col in [\"skey\", \"date\", \"ApplSeqNum\", \"OrderQty\", \"Side\", \"OrderType\"]:\n",
    "        OrderLog[col] = OrderLog[col].astype('int32')\n",
    "#     for cols in [\"Price\"]:\n",
    "#         print(cols)\n",
    "#         print(OrderLog[cols].astype(str).apply(lambda x: len(str(x.split('.')[1]))).unique())\n",
    "    \n",
    "    assert(OrderLog[((OrderLog[\"Side\"] != 1) & (OrderLog[\"Side\"] != 2)) | (OrderLog[\"OrderType\"].isnull())].shape[0] == 0)\n",
    "    da_te = str(OrderLog[\"date\"].iloc[0]) \n",
    "    da_te = da_te[:4] + '-' + da_te[4:6] + '-' + da_te[6:8]\n",
    "    db1 = db[db[\"date\"] == da_te]\n",
    "    sl = (db1[\"ID\"].str[2:].astype(int) + 2000000).unique()\n",
    "    del db1\n",
    "    try:\n",
    "        assert(len(set(sl) - set(OrderLog[\"skey\"].unique())) == 0)\n",
    "    except:\n",
    "        print(\"less stocks\")\n",
    "        display(set(sl) - set(OrderLog[\"skey\"].unique()))\n",
    "    if len(set(OrderLog[\"skey\"].unique()) - set(sl)) != 0:\n",
    "        print(\"more stocks\")\n",
    "        print(set(OrderLog[\"skey\"].unique()) - set(sl))\n",
    "    \n",
    "    OrderLog = OrderLog.rename(columns={\"Side\":\"order_side\", \"OrderType\":\"order_type\", \"Price\":\"order_price\", \"OrderQty\":\"order_qty\"})\n",
    "    OrderLog = OrderLog[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ApplSeqNum\", \"order_side\", \"order_type\", \"order_price\",\n",
    "                                                 \"order_qty\"]]\n",
    "    \n",
    "    print(OrderLog[\"date\"].iloc[0])\n",
    "    print(\"order finished\")\n",
    "\n",
    "    \n",
    "    db1 = DB(\"mongodb://user_rw:faa96dfc@192.168.10.223\")\n",
    "    db1.write('order', OrderLog)\n",
    "    \n",
    "    del OrderLog\n",
    "    \n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "#     pd.set_option(\"max_rows\", 200)\n",
    "#     display(OrderLog.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderQty</th>\n",
       "      <th>OrdType</th>\n",
       "      <th>TransactTime</th>\n",
       "      <th>ExpirationDays</th>\n",
       "      <th>Side</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>Contactor</th>\n",
       "      <th>SendingTime</th>\n",
       "      <th>Price</th>\n",
       "      <th>ChannelNo</th>\n",
       "      <th>ExpirationType</th>\n",
       "      <th>ContactInfo</th>\n",
       "      <th>ConfirmID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>20170901091500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170901091500000</td>\n",
       "      <td>11.21</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>20170901091500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170901091500000</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>20170901091500020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170901091500000</td>\n",
       "      <td>11.02</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>20170901091500030</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170901091500000</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>20170901091500030</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170901091500000</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42402</th>\n",
       "      <td>1300</td>\n",
       "      <td>2</td>\n",
       "      <td>20170901145956230</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11563946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170901145956000</td>\n",
       "      <td>11.21</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42403</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>20170901145956290</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11563965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170901145956000</td>\n",
       "      <td>11.18</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42404</th>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>20170901145959030</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11564604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170901145958000</td>\n",
       "      <td>11.21</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42405</th>\n",
       "      <td>13700</td>\n",
       "      <td>2</td>\n",
       "      <td>20170901145959140</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11564627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170901145959000</td>\n",
       "      <td>11.33</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42406</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>20170901145959930</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11564788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170901145959000</td>\n",
       "      <td>11.21</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42407 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       OrderQty OrdType       TransactTime  ExpirationDays  Side  ApplSeqNum  \\\n",
       "0          1000       2  20170901091500000               0     1         223   \n",
       "1           200       2  20170901091500000               0     2         324   \n",
       "2          1000       2  20170901091500020               0     1         616   \n",
       "3          1000       2  20170901091500030               0     2         667   \n",
       "4          1000       2  20170901091500030               0     2         669   \n",
       "...         ...     ...                ...             ...   ...         ...   \n",
       "42402      1300       2  20170901145956230               0     2    11563946   \n",
       "42403       100       2  20170901145956290               0     2    11563965   \n",
       "42404       500       2  20170901145959030               0     1    11564604   \n",
       "42405     13700       2  20170901145959140               0     1    11564627   \n",
       "42406      1000       2  20170901145959930               0     1    11564788   \n",
       "\n",
       "       Contactor        SendingTime  Price  ChannelNo  ExpirationType  \\\n",
       "0            NaN  20170901091500000  11.21       2011               0   \n",
       "1            NaN  20170901091500000  11.80       2011               0   \n",
       "2            NaN  20170901091500000  11.02       2011               0   \n",
       "3            NaN  20170901091500000  11.80       2011               0   \n",
       "4            NaN  20170901091500000  12.00       2011               0   \n",
       "...          ...                ...    ...        ...             ...   \n",
       "42402        NaN  20170901145956000  11.21       2011               0   \n",
       "42403        NaN  20170901145956000  11.18       2011               0   \n",
       "42404        NaN  20170901145958000  11.21       2011               0   \n",
       "42405        NaN  20170901145959000  11.33       2011               0   \n",
       "42406        NaN  20170901145959000  11.21       2011               0   \n",
       "\n",
       "       ContactInfo  ConfirmID  \n",
       "0              NaN        NaN  \n",
       "1              NaN        NaN  \n",
       "2              NaN        NaN  \n",
       "3              NaN        NaN  \n",
       "4              NaN        NaN  \n",
       "...            ...        ...  \n",
       "42402          NaN        NaN  \n",
       "42403          NaN        NaN  \n",
       "42404          NaN        NaN  \n",
       "42405          NaN        NaN  \n",
       "42406          NaN        NaN  \n",
       "\n",
       "[42407 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"max_columns\", 200)\n",
    "d = pd.read_csv('/mnt/e/unzip_data/2017/SZ/20170901/order/000001.csv')\n",
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

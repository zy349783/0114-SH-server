{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-13 22:02:00.670250\n",
      "\n",
      "still wait for data coming\n",
      "2021-01-13 22:07:00.777293\n",
      "We start to generate report now\n",
      "start\n",
      "-----------------------------------------------------------------------------------------------\n",
      "load data\n",
      "/mnt/orderLog/data/20201231.pkl\n",
      "/mnt/orderLog/data/20201229.pkl\n",
      "/mnt/orderLog/data/20201230.pkl\n",
      "/mnt/orderLog/data/20210104.pkl\n",
      "/mnt/orderLog/data/20210105.pkl\n",
      "/mnt/orderLog/data/20210106.pkl\n",
      "/mnt/orderLog/data/20210107.pkl\n",
      "/mnt/orderLog/data/20210108.pkl\n",
      "/mnt/orderLog/data/20210111.pkl\n",
      "/mnt/orderLog/data/20210112.pkl\n",
      "/mnt/orderLog/data/20210113.pkl\n",
      "There are ticks with orderDirection 0\n",
      "             date      colo  accCode    secid  vai  updateType      sdd  \\\n",
      "48658    20201229  zt_96_01   966301  1600376   -1           1     -1.0   \n",
      "48659    20201229  zt_96_01   966301  1600376   -1           1     -1.0   \n",
      "48660    20201229  zt_96_01   966301  1600376   -1           1     -1.0   \n",
      "247510   20201229  zt_52_04   537301  1603786   -1           1     -1.0   \n",
      "271265   20201229  zt_52_04   528401  1603979   -1           1  52020.0   \n",
      "...           ...       ...      ...      ...  ...         ...      ...   \n",
      "9372816  20210113  zs_94_05     9471  2002706   -1           7  40409.0   \n",
      "9419258  20210113  zs_54_01     5474  2002882   -1           1  37983.0   \n",
      "9452349  20210113  zs_94_05     9454  2002988   -1           1  47829.0   \n",
      "9657899  20210113  zs_66_01     6634  2300681   -1           7  34440.0   \n",
      "9683521  20210113  zs_94_05     9454  2300750   -1           7  48848.0   \n",
      "\n",
      "         orderDirection  absOrderSize  internalId      orderId  \n",
      "48658                 0             0        -1.0         15.0  \n",
      "48659                 0             0        -1.0         16.0  \n",
      "48660                 0             0        -1.0         17.0  \n",
      "247510                0             0        -1.0         14.0  \n",
      "271265                0             0        -1.0     479470.0  \n",
      "...                 ...           ...         ...          ...  \n",
      "9372816               0             0        -1.0         -1.0  \n",
      "9419258               0             0        -1.0  868907304.0  \n",
      "9452349               0             0        -1.0    2300356.0  \n",
      "9657899               0             0        -1.0         -1.0  \n",
      "9683521               0             0        -1.0         -1.0  \n",
      "\n",
      "[198 rows x 11 columns]\n",
      "There are orders with all things same except sdd\n",
      "        Unnamed: 0  ApplSeqNum       aaa  absFilledThisUpdate  absOrderSize  \\\n",
      "466842    466842.0   1444460.0  0.000687                    0           100   \n",
      "466902    466902.0   9795909.0  0.000694                    0           100   \n",
      "\n",
      "        absOrderSizeCumFilled  accCode  ars             caamd  \\\n",
      "466842                      0   966301  1.0  1609205575014635   \n",
      "466902                      0   966301  1.0  1609208372125359   \n",
      "\n",
      "        cancellationPending        cfe         clock    clockAtArrival  \\\n",
      "466842                  0.0  128034.25  1.609206e+15  1609205575014666   \n",
      "466902                  0.0   52600.79  1.609208e+15  1609208372125429   \n",
      "\n",
      "        cumSharesBought  cumSharesBuyInserted  cumSharesSellInserted  \\\n",
      "466842              0.0                   0.0                  300.0   \n",
      "466902              0.0                   0.0                  600.0   \n",
      "\n",
      "        cumSharesSold      date  finalState        gfe       hee  \\\n",
      "466842          200.0  20201229         0.0  128033.25  0.000504   \n",
      "466902          400.0  20201229         0.0   52599.79 -0.000102   \n",
      "\n",
      "        insertedShortOrder  insertionPending  internalId  inv_L  inv_L0  \\\n",
      "466842                 0.0               1.0         9.0  700.0     0.0   \n",
      "466902                 0.0               1.0         9.0  100.0     0.0   \n",
      "\n",
      "        inv_S  inv_S0            l4algoDebug  l4tr  locateShares  \\\n",
      "466842    0.0     0.0                    NaN   0.0           0.0   \n",
      "466902    0.0     0.0  1015.000000|2.000000|   0.0           0.0   \n",
      "\n",
      "        locateSharesTotal  mfe  mra100  mrb100       mrm     mrm25  mrmum  \\\n",
      "466842                0.0 -1.0  2765.0  2764.0 -0.000118  -0.00139   -1.0   \n",
      "466902                0.0 -1.0  2774.0  2771.0  0.000174 -0.002573   -1.0   \n",
      "\n",
      "        mrrlma mrsb300    mrsb90  mrss300    mrss90  mrstaat  mrstauc  \\\n",
      "466842    -1.0      -1 -0.001033     -1.0  0.000687   1000.0      0.0   \n",
      "466902    -1.0      -1 -0.001770     -1.0  0.000694   1000.0      0.0   \n",
      "\n",
      "        mrstaum        mrv               ms  mse   mt  mta   mv  \\\n",
      "466842     -1.0   140020.0  09:32:55.014196  100  0.0 -999  0.0   \n",
      "466902     -1.0  1976879.0  10:19:32.125029  100  0.0 -999  0.0   \n",
      "\n",
      "        orderDirection  orderId  orderOutstanding  orderPrice orderSysId  \\\n",
      "466842              -1      9.0               0.0       27.64        NaN   \n",
      "466902              -1     -1.0               0.0       27.71        NaN   \n",
      "\n",
      "        resa          sdd    secid  sequenceNo  session  threadId  \\\n",
      "466842   2.0   93255060.0  2002595   8271885.0        5   29229.0   \n",
      "466902   2.0  101932190.0  2002595  56341419.0        1   29306.0   \n",
      "\n",
      "        totalActions  totalCanceled tradeId  tradePrice  underlyingIndex  \\\n",
      "466842           7.0            0.0     NaN        -1.0              905   \n",
      "466902          10.0            1.0     NaN        -1.0              905   \n",
      "\n",
      "        updateType      vai                            zipFile      colo  \\\n",
      "466842           0   140020  logs_20201229_zt_96_01_day_966301  zt_96_01   \n",
      "466902           0  1976879  logs_20201229_zt_96_01_day_966301  zt_96_01   \n",
      "\n",
      "        caa_orderLog    start_time     Price  OrderQty  Side statusLs  \\\n",
      "466842  1.609206e+15  1.609206e+15  276400.0     100.0   2.0   (0, 4)   \n",
      "466902           NaN           NaN       NaN       NaN   NaN      NaN   \n",
      "\n",
      "       TradePriceLs TradeQtyLs   beta_60  adjMid_F30s  adjMid_F90s  \\\n",
      "466842  (0, 276400)   (0, 100)  0.581536    27.643913    27.627500   \n",
      "466902          NaN        NaN  0.581536    27.649275    27.629737   \n",
      "\n",
      "        adjMid_F300s  indexClose  indexClose_F30s  indexClose_F90s  \\\n",
      "466842     27.473333   6239.2341        6241.7701        6238.8906   \n",
      "466902     27.631667   6235.4744        6234.7954        6229.9708   \n",
      "\n",
      "        indexClose_F300s  \n",
      "466842         6226.1042  \n",
      "466902         6237.2874  \n",
      "There are orders with same internalId but different orderId other than accCode 8856 case\n",
      "date      colo      accCode  secid    orderDirection  absOrderSize  internalId\n",
      "20201229  zt_96_01  966301   1600376   0              0             -1.0          3\n",
      "                             2002595  -1              100            9.0          2\n",
      "Name: orderId, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are orders in 8856 with same internalId and various orderId!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "     secid  accCode      colo      vai  updateType         sdd  internalId  \\\n",
      "0  2300271     8856  zs_88_04  22400.0           0  93007340.0        30.0   \n",
      "1  2300271     8856  zs_88_04  22400.0           2        -1.0        30.0   \n",
      "2  2300271     8856  zs_88_04  22400.0           1     34209.0        30.0   \n",
      "3  2300271     8856  zs_88_04  22400.0           3        -1.0        30.0   \n",
      "4  2300271     8856  zs_88_04  22400.0           0  93009860.0        34.0   \n",
      "5  2300271     8856  zs_88_04  22400.0           2        -1.0        34.0   \n",
      "6  2300271     8856  zs_88_04  22400.0           2        -1.0        34.0   \n",
      "\n",
      "   orderId  absOrderSize  absFilledThisUpdate  absOrderSizeCumFilled  \\\n",
      "0     30.0           100                    0                      0   \n",
      "1     30.0           100                    0                      0   \n",
      "2     30.0           100                    0                      0   \n",
      "3     30.0           100                    0                      0   \n",
      "4     34.0           100                    0                      0   \n",
      "5     34.0           100                    0                      0   \n",
      "6     34.0           100                  100                    100   \n",
      "\n",
      "   orderPrice  tradePrice  \n",
      "0       24.73        -1.0  \n",
      "1       24.73        -1.0  \n",
      "2       24.73        -1.0  \n",
      "3       24.73        -1.0  \n",
      "4       24.70        -1.0  \n",
      "5       24.70        -1.0  \n",
      "6       24.70        24.7  \n",
      "=======================================================================================\n",
      "1. same date, secid, vai: same direction\n",
      "orders with abnormal ars values\n",
      "ars\n",
      "0.0    1\n",
      "Name: date, dtype: int64\n",
      "accCode\n",
      "8854    1\n",
      "Name: date, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opposite direction for same date, same secid, same vai\n",
      "accCode\n",
      "5222      1\n",
      "5225      1\n",
      "5230      2\n",
      "5232      1\n",
      "5289      1\n",
      "5290      3\n",
      "5291      2\n",
      "5326      2\n",
      "5329      3\n",
      "5377      1\n",
      "5384      2\n",
      "5386      1\n",
      "5470      2\n",
      "5474      2\n",
      "6480      3\n",
      "6623      2\n",
      "6627      4\n",
      "6631      1\n",
      "6634      2\n",
      "6878      1\n",
      "8924      1\n",
      "8943      2\n",
      "8970      1\n",
      "9208      1\n",
      "9243      1\n",
      "9248      1\n",
      "9448      5\n",
      "9454      1\n",
      "9461      1\n",
      "9471      1\n",
      "9551      1\n",
      "9655      2\n",
      "9741      1\n",
      "9754      2\n",
      "9756      1\n",
      "9765      2\n",
      "523101    1\n",
      "527101    3\n",
      "528701    2\n",
      "529001    1\n",
      "529101    1\n",
      "897102    2\n",
      "974102    1\n",
      "Name: orderDirection, dtype: int64\n",
      "=======================================================================================\n",
      "2. same date, secid, vai, accCode: one insertion\n",
      "more than one insertion at same time\n",
      "             date      colo  accCode    secid        vai          sdd  \\\n",
      "1574263  20210108  zs_96_08     6237  1603317  1375708.0  103134000.0   \n",
      "\n",
      "         clockAtArrival  \n",
      "1574263               2  \n",
      "date\n",
      "20210108    1\n",
      "Name: accCode, dtype: int64\n",
      "date      accCode\n",
      "20210108  6237       1\n",
      "Name: sdd, dtype: int64\n",
      "=======================================================================================\n",
      "3. IPO stocks selling (ars = 301, 302)\n",
      "=======================================================================================\n",
      "4. updateType 7 orders\n",
      "=======================================================================================\n",
      "5. updateType 6 orders\n",
      "=======================================================================================\n",
      "6. CYB stocks order size < 30w\n",
      "=======================================================================================\n",
      "7. unexpected updateType\n",
      "updateType\n",
      "(0, 2, 1, 3, 4)                     34\n",
      "(0, 2, 1, 4, 3, 4)                   5\n",
      "(0, 2, 2, 2)                        78\n",
      "(0, 2, 2, 2, 1, 3)                   2\n",
      "(0, 2, 2, 2, 2)                     10\n",
      "(0, 2, 2, 2, 2, 2)                   3\n",
      "(0, 2, 2, 2, 2, 2, 2)                1\n",
      "(0, 2, 2, 2, 2, 2, 2, 2, 1, 3)       1\n",
      "(0, 2, 4, 1)                        13\n",
      "(0, 2, 4, 1, 3, 4)                  26\n",
      "(0, 2, 4, 1, 4, 3, 4)                6\n",
      "(0, 2, 4, 3)                         5\n",
      "(0, 2, 6)                          112\n",
      "(0, 6)                            1041\n",
      "(0, 8)                              21\n",
      "Name: order, dtype: int64\n",
      "=======================================================================================\n",
      "8. status == 0: all traded\n",
      "in total trade, any fill != total cases\n",
      "Series([], Name: order, dtype: int64)\n",
      "=======================================================================================\n",
      "9. status == 1: partial traded\n",
      "in partial trade, any fill >= total or fill is 0 cases for updateType 4\n",
      "Series([], Name: order, dtype: int64)\n",
      "=======================================================================================\n",
      "10. no cancellation within 1 sec\n",
      "any cancellation within 1 sec\n",
      "date      accCode\n",
      "20201230  8854        5\n",
      "20201231  8854       37\n",
      "          966301      5\n",
      "20210104  8854       63\n",
      "          966301      9\n",
      "Name: order, dtype: int64\n",
      "=======================================================================================\n",
      "11. Orders with size > 80w or notional > 800w\n",
      "date      accCode\n",
      "20201229  9448       1\n",
      "20201230  5289       1\n",
      "          9551       1\n",
      "          527101     1\n",
      "          968501     1\n",
      "20201231  5225       1\n",
      "          5273       1\n",
      "          6237       1\n",
      "          6634       2\n",
      "          8865       1\n",
      "          9435       1\n",
      "          9655       1\n",
      "          522501     1\n",
      "20210104  5470       1\n",
      "          522601     1\n",
      "          529001     1\n",
      "          966701     1\n",
      "20210105  5474       1\n",
      "          6627       1\n",
      "          8886       1\n",
      "          9448       1\n",
      "          522901     1\n",
      "20210106  5230       1\n",
      "          5275       1\n",
      "          5292       1\n",
      "          5386       1\n",
      "20210107  8943       1\n",
      "          9448       1\n",
      "20210108  9758       1\n",
      "          522501     1\n",
      "          527101     1\n",
      "          537403     1\n",
      "          968501     1\n",
      "          975601     1\n",
      "20210111  5292       1\n",
      "          523001     1\n",
      "20210112  5264       1\n",
      "          5332       1\n",
      "          8833       1\n",
      "          8865       1\n",
      "          8970       1\n",
      "          9471       1\n",
      "20210113  5474       1\n",
      "          6623       1\n",
      "          8865       1\n",
      "          9435       1\n",
      "          9685       1\n",
      "          528101     1\n",
      "          528401     1\n",
      "          528703     1\n",
      "          897002     1\n",
      "Name: secid, dtype: int64\n",
      "mrstaat  mrstauc\n",
      "1000.0   0.0         2333\n",
      "3000.0   1000.0     10302\n",
      "         2000.0      1107\n",
      "         3000.0       690\n",
      "Name: date, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>order_x</th>\n",
       "      <th>order_y</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>accCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20210113</th>\n",
       "      <th>8854</th>\n",
       "      <td>1576</td>\n",
       "      <td>1575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.12% SZE orders triggered by msg data\n",
      "100.00% SZE orders triggered by msg data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cur_perc</th>\n",
       "      <th>prev_perc</th>\n",
       "      <th>prev_mean</th>\n",
       "      <th>prev_min</th>\n",
       "      <th>prev_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <th>accCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSE</th>\n",
       "      <th>8854</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>82</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SZE</th>\n",
       "      <th>8854</th>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:574: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:575: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:577: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:578: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:579: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:580: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:581: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:582: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:583: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:584: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:587: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:588: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:589: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:590: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:591: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:593: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:594: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:598: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:600: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:601: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:602: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:603: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:608: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:610: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cur_ret</th>\n",
       "      <th>prev_mean</th>\n",
       "      <th>prev_min</th>\n",
       "      <th>prev_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accCode</th>\n",
       "      <th>exchange</th>\n",
       "      <th>Side</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">8854</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">SSE</th>\n",
       "      <th>Buy</th>\n",
       "      <td>14.46</td>\n",
       "      <td>14.457000</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>32.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sell</th>\n",
       "      <td>-4.40</td>\n",
       "      <td>5.610909</td>\n",
       "      <td>-40.43</td>\n",
       "      <td>20.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SZE</th>\n",
       "      <th>Buy</th>\n",
       "      <td>7.29</td>\n",
       "      <td>10.311000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>22.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sell</th>\n",
       "      <td>5.93</td>\n",
       "      <td>7.715455</td>\n",
       "      <td>-3.13</td>\n",
       "      <td>15.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">966301</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">SSE</th>\n",
       "      <th>Buy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.513333</td>\n",
       "      <td>-8.43</td>\n",
       "      <td>16.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sell</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.907778</td>\n",
       "      <td>-20.62</td>\n",
       "      <td>47.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SZE</th>\n",
       "      <th>Buy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.642500</td>\n",
       "      <td>-16.23</td>\n",
       "      <td>10.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sell</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12.843333</td>\n",
       "      <td>-10.38</td>\n",
       "      <td>31.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smtp server connected\n",
      "login\n",
      "send mail\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "pd.set_option('max_rows', 100)\n",
    "pd.set_option('max_columns', 100)\n",
    "\n",
    "perc = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "\n",
    "def generate_report(dd):\n",
    "\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import glob\n",
    "    import datetime\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    import pickle\n",
    "\n",
    "    print('start')\n",
    "    readPath = '/mnt/orderLog/data/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    path = dataPathLs[dateLs >= 20201229]\n",
    "    cur = np.max([int(os.path.basename(i).split('.')[0]) for i in path])\n",
    "    assert(cur == int(dd))\n",
    "\n",
    "\n",
    "    body = \"<html><body><div>\" + 'Hi all,<p>The following is daily report based on ' + str(cur) + ' data.</p>'\n",
    "    body += '<p><b>I. Assertions</p></b>'\n",
    "    count = 0\n",
    "\n",
    "    # load data\n",
    "    print('-----------------------------------------------------------------------------------------------')\n",
    "    print('load data')\n",
    "    rawOrderLog = []\n",
    "    for thisPath in path:\n",
    "        print(thisPath)\n",
    "        data = pickle.load(open(thisPath, 'rb'))\n",
    "        data = data.rename(columns={'mdClockAtArrival': 'caamd'})\n",
    "        rawOrderLog += [data]\n",
    "    rawOrderLog = pd.concat(rawOrderLog, sort=False)\n",
    "\n",
    "    for col in ['clockAtArrival', 'caamd', 'secid', 'updateType', 'vai', 'absFilledThisUpdate', 'orderDirection', 'absOrderSize',\n",
    "                'absOrderSizeCumFilled', 'date', 'accCode', 'mse']:\n",
    "        rawOrderLog[col] = rawOrderLog[col].fillna(0).astype('int64')   \n",
    "    rawOrderLog = rawOrderLog.sort_values(by=['date', 'secid', 'vai', 'accCode', 'clockAtArrival']).reset_index(drop=True)\n",
    "\n",
    "    rawOrderLog = rawOrderLog[rawOrderLog[\"secid\"] >= 1000000]\n",
    "\n",
    "    if rawOrderLog[rawOrderLog.duplicated(['date', 'secid', 'vai', 'accCode', 'clockAtArrival', 'updateType', \\\n",
    "                                        'orderDirection', 'absOrderSize'], keep=False)].shape[0] != 0:\n",
    "        print('There are accounts with duplicated ticks:')\n",
    "        print(rawOrderLog[rawOrderLog.duplicated(['date', 'secid', 'vai', 'accCode', 'clockAtArrival', 'updateType', \\\n",
    "                                        'orderDirection', 'absOrderSize'], keep=False)]\\\n",
    "    .groupby(['date', 'colo', 'accCode'])['ars'].size())\n",
    "        rawOrderLog = rawOrderLog.drop_duplicates(['date', 'secid', 'vai', 'accCode', 'clockAtArrival', 'updateType', \\\n",
    "                                        'orderDirection', 'absOrderSize'], keep='first')\n",
    "\n",
    "\n",
    "    print('There are ticks with orderDirection 0')\n",
    "    print(rawOrderLog[rawOrderLog['orderDirection'] == 0][['date', 'colo', 'accCode', \\\n",
    "                'secid', 'vai', 'updateType', 'sdd', 'orderDirection', 'absOrderSize', 'internalId', 'orderId']])\n",
    "\n",
    "\n",
    "    try:\n",
    "        num1 = rawOrderLog[(rawOrderLog['orderDirection'] == 0) & (rawOrderLog['date'] == cur) & (rawOrderLog['accCode'].isin([8854, 966301]))].shape[0]\n",
    "        assert(num1 < 5)\n",
    "    except:\n",
    "        count += 1\n",
    "        body += str(count) + '. There are in total ' + str(num1) + ' orders with orderDirection 0.<div>'\n",
    "\n",
    "\n",
    "    assert(rawOrderLog[rawOrderLog['updateType'] == 0][rawOrderLog[rawOrderLog['updateType'] == 0]\\\n",
    "                                                       .duplicated(['date', 'colo', 'accCode', 'secid', 'orderDirection',\n",
    "                                                                    'vai', 'absOrderSize', 'internalId'], keep=False)].shape[0] == 0)\n",
    "    try:\n",
    "        assert(rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)][rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)]\\\n",
    "                                                           .duplicated(['date', 'colo', 'accCode', 'secid', 'orderDirection',\n",
    "                                                                        'absOrderSize', 'internalId'], keep=False)].shape[0] == 0)\n",
    "    except:\n",
    "        print('There are orders with all things same except sdd')\n",
    "        print(rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)][rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)]\\\n",
    "                                                           .duplicated(['date', 'colo', 'accCode', 'secid', 'orderDirection',\n",
    "                                                                        'absOrderSize', 'internalId'], keep=False)])\n",
    "        assert(rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)][rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)]\\\n",
    "                                                           .duplicated(['date', 'colo', 'accCode', 'secid', 'orderDirection',\n",
    "                                                                        'absOrderSize', 'internalId', 'sdd'], keep=False)].shape[0] == 0)\n",
    "    try:\n",
    "        assert(sum(rawOrderLog[(rawOrderLog['updateType'] != 0) & (rawOrderLog['accCode'] != 8856)].groupby(['date', 'colo', 'accCode', 'secid', \n",
    "                    'orderDirection', 'absOrderSize', 'internalId'])['orderId'].nunique() != 1) == 0) \n",
    "    except:\n",
    "        print('There are orders with same internalId but different orderId other than accCode 8856 case')\n",
    "        print(rawOrderLog[(rawOrderLog['updateType'] != 0) & (rawOrderLog['accCode'] != 8856)].groupby(['date', 'colo', 'accCode', 'secid', \n",
    "                    'orderDirection', 'absOrderSize', 'internalId'])['orderId'].nunique()[rawOrderLog[(rawOrderLog['updateType'] != 0) & (rawOrderLog['accCode'] != 8856)].groupby(['date', 'colo', 'accCode', 'secid', \n",
    "                    'orderDirection', 'absOrderSize', 'internalId'])['orderId'].nunique() > 1])\n",
    "\n",
    "    r2 = rawOrderLog[(rawOrderLog['accCode'] != 8856) & (rawOrderLog['orderDirection'] != 0)]\n",
    "    r1 = rawOrderLog[(rawOrderLog['accCode'] == 8856) & (rawOrderLog['orderDirection'] != 0)]\n",
    "    r1['test'] = r1.groupby(['date', 'colo', 'accCode', 'secid', \n",
    "                'orderDirection', 'absOrderSize']).grouper.group_info[0]\n",
    "    r1 = r1.sort_values(by=['test', 'clockAtArrival'])\n",
    "    r1.loc[r1['updateType'] != 0, 'vai'] = np.nan\n",
    "    r1['vai'] = r1.groupby('test')['vai'].ffill()\n",
    "    r2['test'] = r2.groupby(['date', 'colo', 'accCode', 'secid', \n",
    "                'orderDirection', 'absOrderSize', 'internalId']).grouper.group_info[0]\n",
    "    r2 = r2.sort_values(by=['test', 'clockAtArrival'])\n",
    "    r2.loc[r2['updateType'] != 0, 'vai'] = np.nan\n",
    "    r2['vai'] = r2.groupby('test')['vai'].ffill()\n",
    "    try:\n",
    "        assert(sum(r1[r1['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique() != 1) == 0)\n",
    "    except:\n",
    "        a = r1[r1['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique()[r1[r1['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique() != 1].reset_index()\n",
    "        print('There are orders in 8856 with same internalId and various orderId!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        print(pd.merge(r1, a[['test', 'vai']], on=['test', 'vai'], how='inner')[['secid', 'accCode', 'colo', 'vai', 'updateType', 'sdd', 'internalId', 'orderId', 'absOrderSize', 'absFilledThisUpdate', 'absOrderSizeCumFilled', 'orderPrice', 'tradePrice']])\n",
    "    \n",
    "    try:\n",
    "        assert(sum(r2[r2['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique() != 1) == 0)\n",
    "    except:\n",
    "        a = r2[r2['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique()[r2[r2['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique() != 1].reset_index()\n",
    "        print('There are orders out of 8856 with same internalId and various orderId!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        print(pd.merge(r2, a[['test', 'vai']], on=['test', 'vai'], how='inner')[['secid', 'accCode', 'colo', 'vai', 'updateType', 'sdd', 'internalId', 'orderId', 'absOrderSize', 'absFilledThisUpdate', 'absOrderSizeCumFilled', 'orderPrice', 'tradePrice']])\n",
    "    orderLog = pd.concat([r1, r2])\n",
    "    del r1\n",
    "    del r2    \n",
    "\n",
    "    orderLog = orderLog.sort_values(by=['date', 'colo', 'accCode', 'secid', 'vai', 'clockAtArrival']).reset_index(drop=True)\n",
    "    orderLog['clock'] = orderLog['clockAtArrival'].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    orderLog[\"broker\"] = np.where(orderLog[\"accCode\"].astype(str).apply(lambda x: len(x) == 6), orderLog['accCode'] // 10000, orderLog['accCode'] // 100)\n",
    "    orderLog['colo_broker'] = orderLog['colo'].str[:2] + '_' + orderLog['broker'].astype('str')\n",
    "    orderLog['order'] = orderLog.groupby(['date', 'colo', 'accCode', 'secid', 'vai', 'orderDirection', 'absOrderSize', 'internalId']).grouper.group_info[0]\n",
    "    orderLog['group'] = orderLog.groupby(['date', 'secid', 'vai']).grouper.group_info[0]\n",
    "    orderLog['startClock'] = orderLog.groupby(['order'])['clockAtArrival'].transform('first')\n",
    "    orderLog['duration'] = orderLog['clockAtArrival'] - orderLog['startClock']\n",
    "    orderLog['orderPrice'] = orderLog['orderPrice'].apply(lambda x: round(x, 2))\n",
    "    orderLog['tradePrice'] = orderLog['tradePrice'].apply(lambda x: round(x, 2))\n",
    "    orderLog['orderDirection1'] = np.where(orderLog[\"orderDirection\"] == -2, -1, np.where(\n",
    "        orderLog[\"orderDirection\"] == 2, 1, orderLog[\"orderDirection\"]))\n",
    "    orderLog[\"ars\"] = orderLog.groupby(['order'])['ars'].transform('first')\n",
    "    orderLog['sdd'] = orderLog.groupby('order')['sdd'].transform('first')\n",
    "    orderLog['caamd'] = orderLog.groupby('order')['caamd'].transform('first')\n",
    "    copydf = orderLog.copy()\n",
    "\n",
    "\n",
    "    ### Assertion 1:  make sure same direction in same date, secid, vai\n",
    "    print('=======================================================================================')\n",
    "    print('1. same date, secid, vai: same direction')\n",
    "    taking = orderLog[orderLog['ars'].isin([1, 7])]\n",
    "    making = orderLog[orderLog['ars'].isin([2, 3])]\n",
    "    else_orders = orderLog[~(orderLog['ars'].isin([1, 2, 3, 7]))]\n",
    "    print('orders with abnormal ars values')\n",
    "    if else_orders[(else_orders['updateType'] == 0) & (else_orders['date'] == cur) & (else_orders['accCode'].isin([8854, 966301]))].shape[0] != 0:\n",
    "        print(else_orders[(else_orders['updateType'] == 0) & (else_orders['date'] == cur) & (else_orders['accCode'].isin([8854, 966301]))].groupby('ars')['date'].size().sort_values(ascending=False))\n",
    "        print(else_orders[(else_orders['updateType'] == 0) & (else_orders['date'] == cur) & (else_orders['accCode'].isin([8854, 966301]))].groupby('accCode')['date'].size().sort_values(ascending=False))\n",
    "        ars_list = else_orders[(else_orders['updateType'] == 0) & (else_orders['date'] == cur) & (else_orders['accCode'].isin([8854, 966301]))].groupby('ars')['date'].size().sort_values(ascending=False).reset_index()['ars'].values\n",
    "        ars_list = ', '.join([str(x) for x in ars_list])\n",
    "        count += 1\n",
    "        body += str(count) + '. There are abnormal ars values in data: ' + ars_list + '.<div>'\n",
    "        kk = else_orders[(else_orders['updateType'] == 0) & (else_orders['date'] == cur) & (else_orders['accCode'].isin([8854, 966301]))].groupby('accCode')['date'].size().sort_values(ascending=False)\n",
    "        if kk[kk > 10].shape[0] > 0:\n",
    "            count += 1\n",
    "            stock_list = ', '.join([str(x) for x in kk[kk > 10].index.values])\n",
    "            body += str(count) + '. These accounts have more than 10 abnormal ars orders: ' + stock_list + '.<div>'\n",
    "    taking['directNum'] = taking.groupby(['date', 'secid', 'vai', 'sdd'])['orderDirection1'].transform('nunique')\n",
    "    if taking[(taking['directNum'] != 1)].shape[0] > 0:\n",
    "        print('opposite direction for same date, same secid, same vai')\n",
    "        print(taking[(taking['directNum'] != 1) & (taking['updateType'] == 0)].groupby(['accCode'])['orderDirection'].size())\n",
    "        try:\n",
    "            num1 = taking[(taking['directNum'] != 1) & (taking['updateType'] == 0) & (taking['date'] == cur) & (taking['accCode'].isin([8854, 966301]))].shape[0]\n",
    "            assert(num1 < 10)\n",
    "        except:\n",
    "            count += 1\n",
    "            body += str(count) + '. There are in total ' + str(num1) + ' orders with opposite directions under same date, secid, vai.<div>'\n",
    "        try:\n",
    "            num2 = list(taking[(taking['directNum'] != 1) & (taking['updateType'] == 0) & (taking['date'] == \\\n",
    "                cur) & (taking['accCode'].isin([8854, 966301]))].groupby('accCode')['date'].size()[taking[(taking['directNum'] != 1) & \\\n",
    "               (taking['updateType'] == 0) & (taking['date'] == cur) & (taking['accCode'].isin([8854, 966301]))].\\\n",
    "                                                                           groupby('accCode')['date'].size() > 10].index)\n",
    "            assert(len(num2) == 0)\n",
    "        except:\n",
    "            count += 1\n",
    "            num2 = ', '.join([str(x) for x in num2])\n",
    "            body += str(count) + '. ' + num2 + ' has more than 10 orders with opposite directions under same date, secid, vai.<div>'\n",
    "        taking = taking[taking['directNum'] == 1]\n",
    "\n",
    "    assert((taking.groupby(['date', 'secid', 'vai', 'sdd'])['orderDirection1'].nunique() == 1).all() == True)\n",
    "    orderLog = pd.concat([taking, making]).sort_values(by=['date', 'colo', 'accCode', 'secid', 'vai', 'clockAtArrival']).reset_index(drop=True)\n",
    "\n",
    "    ## Assertion 2:  make sure each account, secid, vai only has one insertion\n",
    "    print('=======================================================================================')\n",
    "    print('2. same date, secid, vai, accCode: one insertion')\n",
    "    a = orderLog[orderLog['updateType'] == 0].groupby(['date', 'colo', 'accCode', 'secid', 'vai', 'sdd'])['clockAtArrival'].count().reset_index()\n",
    "    if a[a['clockAtArrival'] > 1].shape[0] > 0:\n",
    "        print('more than one insertion at same time')\n",
    "        a = a[(a['clockAtArrival'] > 1)]\n",
    "        print(a)\n",
    "        print(a.groupby(['date'])['accCode'].size())\n",
    "        print(a.groupby(['date', 'accCode'])['sdd'].size())\n",
    "        try:\n",
    "            num1 = a[(a['date'] == cur) & (a['accCode'].isin([8854, 966301]))].shape[0]\n",
    "            assert(num1 < 10)\n",
    "        except:\n",
    "            count += 1\n",
    "            body += str(count) + '. There are in total ' + str(num1) + ' orders with more than one insertion in same order.<div>'\n",
    "        try:\n",
    "            num2 = list(a[(a['date'] == cur) & (a['accCode'].isin([8854, 966301]))].groupby(['accCode'])['date'].size()[a[(a['date'] == cur) & (a['accCode'].isin([8854, 966301]))].groupby(['accCode'])['date'].size() > 10].index)\n",
    "            assert(len(num2) == 0)\n",
    "        except:\n",
    "            count += 1\n",
    "            num2 = ', '.join([str(x) for x in num2])\n",
    "            body += str(count) + '. ' + num2 + ' has more than 10 orders with more than one insertion in same order.<div>'        \n",
    "        d_el = pd.merge(orderLog, a, on=['date', 'colo', 'accCode', 'secid', 'vai', 'sdd'])['order'].unique()\n",
    "        orderLog = orderLog[~(orderLog['order'].isin(d_el))]\n",
    "\n",
    "    orderLog['isMsg'] = np.where(orderLog['updateType'] == 0, \n",
    "                                 np.where(orderLog['mse'] == 100, 1, 0), np.nan)\n",
    "    orderLog['isMsg'] = orderLog.groupby(['order'])['isMsg'].ffill()\n",
    "\n",
    "\n",
    "    ### Assertion 3:  check IPO stocks selling status\n",
    "    print('=======================================================================================')\n",
    "    print('3. IPO stocks selling (ars = 301, 302)')\n",
    "    if orderLog[(orderLog['ars'].isin([301, 302])) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))].shape[0] != 0:\n",
    "        kk = orderLog[(orderLog['ars'].isin([301, 302])) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))]\n",
    "        print(kk)\n",
    "        try:\n",
    "            assert(kk[kk['orderDirection1'] == 1].shape[0] == 0)\n",
    "            print('we only sell, never buy')\n",
    "        except:\n",
    "            print('There are IPO buy side orders!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "            count += 1\n",
    "            num1 = kk[kk['orderDirection1'] == 1].shape[0]\n",
    "            body += str(count) + '. There are ' + str(num1) + ' IPO buy side orders.<div>'\n",
    "            print(kk[kk['orderDirection1'] == 1])\n",
    "        kk1 = kk[kk['updateType'] == 0]\n",
    "        kk1 = kk1.sort_values(by=['accCode', 'secid','clockAtArrival'])\n",
    "        kk1['diff'] = kk1.groupby(['accCode', 'secid'])['clockAtArrival'].apply(lambda x: x-x.shift(1))\n",
    "        kk1['diff'] = kk1['diff'].fillna(0)\n",
    "        try:\n",
    "            assert(kk1[kk1['diff'] < 10e6].shape[0] == 0)\n",
    "            print('for each stock in the same account, there is no insertion within 10 seconds of the previous insertion')\n",
    "        except:\n",
    "            count += 1\n",
    "            kk1 = kk1.reset_index()\n",
    "            num2 = kk1[kk1['diff'] < 10e6].shape[0]\n",
    "            body += str(count) + '. There are ' + str(num2) + ' over ' + str(kk1.shape[0]) + ' orders with insertion within 10 seconds for orders under same account same stock.<div>'\n",
    "            print('There are insertion within 10 seconds for orders under same account same stock!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')        \n",
    "            print(kk1[kk1['diff'] < 10e6])\n",
    "        kk2 = kk[(kk['updateType'] == 1)]\n",
    "\n",
    "        try:\n",
    "            assert(kk2[kk2['duration'] < 3e6].shape[0] == 0)\n",
    "            print('for each stock in the same account, the cancellation of an order happens more than 3 seconds after the insertion')\n",
    "        except:\n",
    "            count += 1\n",
    "            num2 = kk2[kk2['duration'] < 3e6].shape[0]\n",
    "            body += str(count) + '. There are ' + str(num2) + ' over ' + str(kk1.shape[0]) + ' orders with cancellation within 3 seconds after insertion.<div>'        \n",
    "            print('There are cancellation within 3 seconds for orders under same account same stock!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "            print(kk2[kk2['duration'] < 3e6])\n",
    "\n",
    "\n",
    "    ### Assertion 4: check updateType == 7 orders, make sure updateType == 7 orders < 20 per account, < 100 in total\n",
    "    print('=======================================================================================')\n",
    "    print('4. updateType 7 orders')\n",
    "    if orderLog[(orderLog['updateType'] == 7) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))].shape[0] != 0:\n",
    "        try:\n",
    "            assert(orderLog[(orderLog['updateType'] == 7) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))].groupby(['date', 'accCode'])['order'].nunique().max() < 10)\n",
    "        except:\n",
    "            print('There are more than 10 updateType 7 orders per account')\n",
    "            count += 1\n",
    "            a = list(orderLog[(orderLog['updateType'] == 7) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))].groupby(['accCode'])['order'].nunique()[\n",
    "                orderLog[(orderLog['updateType'] == 7) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))].groupby(['accCode'])['order'].nunique() >= 10\n",
    "            ].index)\n",
    "            a = ', '.join([str(x) for x in a])\n",
    "            body += str(count) + '. ' + a + ' has more than 10 updateType 7 orders.<div>'\n",
    "        try:      \n",
    "            assert(orderLog[(orderLog['updateType'] == 7) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))]['order'].nunique() < 20)\n",
    "        except:\n",
    "            print('Ther are more than 20 updateType 7 orders in total')\n",
    "            count += 1\n",
    "            body += str(count) + '. There are more than 20 updateType 7 orders in total.<div>'\n",
    "\n",
    "\n",
    "    ### Assertion 5: check updateType == 6 orders, make sure updateType == 6 orders < 5% per account\n",
    "    print('=======================================================================================')\n",
    "    print('5. updateType 6 orders')\n",
    "    k1 = orderLog[(orderLog['updateType'] == 6) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))].groupby(['accCode'])['order'].nunique().reset_index()\n",
    "    k2 = orderLog[(orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))].groupby(['accCode'])['order'].nunique().reset_index()\n",
    "    k = pd.merge(k1, k2, on=['accCode'], how='left')\n",
    "    k['prob'] = k['order_x']/k['order_y']\n",
    "    try:\n",
    "        assert(sum(k['prob'] >= 0.05) == 0)\n",
    "    except:\n",
    "        print('There are accounts with more than 5% updateType 6 orders!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        print(k[k['prob'] >= 0.05])\n",
    "        a = k[k['prob'] >= 0.05]['accCode'].unique()\n",
    "        a = ', '.join([str(x) for x in a])\n",
    "        count += 1\n",
    "        body += str(count) + '. ' + a + ' has more than 5% updateType 6 orders.<div>'\n",
    "\n",
    "    ### Assertion 6: check CYB orders, make sure all CYB stocks have absOrderSize < 30w\n",
    "    print('=======================================================================================')\n",
    "    print('6. CYB stocks order size < 30w')\n",
    "    try:\n",
    "        cyb = orderLog[(orderLog['secid'] >= 2300000) & (orderLog['updateType'] == 0) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))]\n",
    "        assert(cyb[cyb['absOrderSize'] > 300000].shape[0] == 0)\n",
    "    except:\n",
    "        print('CYB stocks total absOrderSize >= 30w!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        num1 = cyb[cyb['absOrderSize'] > 300000].shape[0]\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(num1) + ' orders with CYB absOrderSize > 30w.<div>'\n",
    "\n",
    "\n",
    "    ### Assertion 7:  make sure there is no unexpected updateType \n",
    "    print('=======================================================================================')\n",
    "    print('7. unexpected updateType')\n",
    "    def getTuple(x):\n",
    "        return tuple(i for i in x)\n",
    "\n",
    "    checkLog = orderLog[~((orderLog['updateType'] == 4) & (orderLog.groupby(['order'])['updateType'].shift(-1) == 4))]\n",
    "    checkLog = checkLog.groupby(['order'])['updateType'].apply(lambda x: getTuple(x)).reset_index()\n",
    "    checkLog['status'] = np.where(checkLog['updateType'].isin([(0, 2, 4), (0, 2, 1, 4), (0, 2, 1, 2, 4), (0, 2, 4, 1, 4), (0, 4), (0, 1, 4), (0, 4, 1, 4), (0, 2, 2, 4), (0, 4, 2, 4), (0, 2, 2, 1, 4), (0, 2, 2, 4, 1, 4)]),0,\n",
    "                         np.where(checkLog['updateType'].isin([(0, 2, 4, 1, 3), (0, 2, 4, 1, 4, 3), (0, 2, 1, 4, 3), (0, 4, 1, 3), (0, 1, 4, 3),\n",
    "                                                                   (0, 2, 2, 4, 1, 3), (0, 2, 2, 4, 1, 4, 3), (0, 2, 2, 1, 4, 3), (0, 4, 2, 4, 1, 3),\n",
    "                                                                   (0, 4, 2, 1, 3), (0, 4, 1, 4, 3), (0, 4, 1)]), 1,\n",
    "                         np.where(checkLog['updateType'].isin([(0, 2, 1, 3), (0, 2, 2, 1, 3), (0, 2, 3), (0, 3), (0, 1, 3), (0, ), (0, 2), (0, 2, 1), (0, 2, 2)]), 2, 3)))\n",
    "    print(checkLog[checkLog['status'] == 3].groupby('updateType')['order'].size())\n",
    "    orderLog = pd.merge(orderLog, checkLog[['order', 'status']], how='left', on=['order'], validate='many_to_one')\n",
    "    orderLog = orderLog[orderLog['status'].isin([0, 1, 2])].reset_index(drop=True)\n",
    "\n",
    "    ### Assertion 8:  make sure status==0 got all traded\n",
    "    print('=======================================================================================')\n",
    "    print('8. status == 0: all traded')\n",
    "    a = orderLog[(orderLog['status'] == 0)]\n",
    "    a = a.groupby(['date', 'order', 'accCode'])[['absOrderSizeCumFilled', 'absOrderSize']].max().reset_index()\n",
    "    a.columns = ['date', 'order', 'accCode', 'filled', 'total']\n",
    "    print('in total trade, any fill != total cases')\n",
    "    print(a[(a['filled'] != a['total']) & (a['accCode'].isin([8854, 966301]))].groupby(['date', 'accCode'])['order'].size())\n",
    "    if a[a['filled'] != a['total']].shape[0] > 0:\n",
    "        removeOrderLs = a[a['filled'] != a['total']]['order'].unique()\n",
    "        if a[(a['filled'] != a['total']) & (a['date'] == cur) & (a['accCode'].isin([8854, 966301]))].shape[0] > 0:\n",
    "            count += 1\n",
    "            body += str(count) + '. There are ' + str(a[(a['filled'] != a['total']) & (a['date'] == cur) & (a['accCode'].isin([8854, 966301]))]['order'].nunique()) + \\\n",
    "            ' over ' + str(a[(a['date'] == cur) & (a['accCode'].isin([8854, 966301]))]['order'].nunique()) + ' orders status == 0 but not all traded.<div>'\n",
    "        orderLog = orderLog[~(orderLog['order'].isin(removeOrderLs))]\n",
    "\n",
    "    ### Assertion 9:  make sure status==1 got partial traded\n",
    "    print('=======================================================================================')\n",
    "    print('9. status == 1: partial traded')\n",
    "    a = orderLog[orderLog['status'] == 1]\n",
    "    a = a.groupby(['date', 'order', 'accCode'])[['absOrderSizeCumFilled', 'absOrderSize']].max().reset_index()\n",
    "    a.columns = ['date', 'order', 'accCode', 'filled', 'total']\n",
    "    print('in partial trade, any fill >= total or fill is 0 cases for updateType 4')\n",
    "    print(a[((a['filled'] >= a['total']) | (a['filled'] == 0)) & (a['accCode'].isin([8854, 966301]))].groupby(['date', 'accCode'])['order'].size())\n",
    "    if a[(a['filled'] >= a['total']) | (a['filled'] == 0)].shape[0] > 0:\n",
    "        removeOrderLs = a[(a['filled'] >= a['total']) | (a['filled'] == 0)]['order'].unique()\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(a[((a['filled'] >= a['total']) | (a['filled'] == 0)) & (a['date'] == cur) & (a['accCode'].isin([8854, 966301]))]['order'].nunique()) + \\\n",
    "        ' over ' + str(a[(a['date'] == cur) & (a['accCode'].isin([8854, 966301]))]['order'].nunique()) + ' orders status == 1 but not partial traded.<div>'\n",
    "        orderLog = orderLog[~(orderLog['order'].isin(removeOrderLs))]\n",
    "\n",
    "    ### Assertion 10: make sure no cancellation within 1 sec\n",
    "    print('=======================================================================================')\n",
    "    print('10. no cancellation within 1 sec')\n",
    "    a = orderLog[(orderLog['updateType'] == 1) & (orderLog['duration'] < 1e6)]\n",
    "    print('any cancellation within 1 sec')\n",
    "    print(a[(a['accCode'].isin([8854, 966301]))].groupby(['date', 'accCode'])['order'].size())\n",
    "    if a[(a['date'] == cur) & (a['accCode'].isin([8854, 966301]))].shape[0] > 0:\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(a[(a['date'] == cur) & (a['accCode'].isin([8854, 966301]))]['order'].nunique()) + ' orders cancel within 1s on current day.<div>'    \n",
    "    if a.shape[0] > 0:\n",
    "        removeOrderLs = a['order'].unique()\n",
    "        orderLog = orderLog[~(orderLog['order'].isin(removeOrderLs))]\n",
    "\n",
    "\n",
    "    ### Assertion 11: make sure no order has shares > 80w or notional > 800w\n",
    "    print('=======================================================================================')\n",
    "    print('11. Orders with size > 80w or notional > 800w')\n",
    "    orderLog['orderNtl'] = orderLog['absOrderSize'] * orderLog['orderPrice']\n",
    "    if orderLog[(orderLog['absOrderSize'] > 800000) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))].shape[0] > 0:\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(orderLog[(orderLog['absOrderSize'] > 800000) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))]['order'].nunique()) + ' orders shares > 80w.<div>'    \n",
    "    if orderLog[orderLog['absOrderSize'] > 800000].shape[0] > 0:\n",
    "        print('some order quantity are > 80w')\n",
    "        print(orderLog[orderLog['absOrderSize'] > 800000].groupby(['colo', 'accCode'])['order'].nunique())\n",
    "        print(orderLog[orderLog['absOrderSize'] > 800000][['date', 'accCode', 'secid', 'vai', 'absOrderSize', 'orderPrice',\n",
    "                                                             'orderNtl', 'orderDirection', 'clock', 'order']])\n",
    "    if orderLog[(orderLog['orderNtl'] > 8000000) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))].shape[0] > 0:\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(orderLog[(orderLog['orderNtl'] > 8000000) & (orderLog['date'] == cur) & (orderLog['accCode'].isin([8854, 966301]))]['order'].nunique()) + ' orders notional > 800w.<div>'                \n",
    "    if orderLog[orderLog['orderNtl'] > 8000000].shape[0] > 0:\n",
    "        print('some order ntl are > 800w')\n",
    "        print(orderLog[orderLog['orderNtl'] > 8000000].groupby(['colo', 'accCode'])['order'].nunique())\n",
    "        print(orderLog[orderLog['orderNtl'] > 8000000][['date', 'accCode', 'secid', 'vai', 'absOrderSize', 'orderPrice',\n",
    "                                                          'orderNtl', 'orderDirection', 'clock', 'order', \"updateType\", \n",
    "                                                          \"tradePrice\", \"absOrderSizeCumFilled\", \"absFilledThisUpdate\"]])\n",
    "\n",
    "    removeOrderLs = list(set(orderLog[orderLog['absOrderSize'] > 800000]['order'].unique()) | set(orderLog[orderLog['orderNtl'] > 8000000]['order'].unique()))\n",
    "    orderLog = orderLog[~(orderLog['order'].isin(removeOrderLs))]\n",
    "\n",
    "\n",
    "    orderLog = orderLog.sort_values(by=['date', 'secid', 'vai', 'accCode', 'order', 'clockAtArrival']).reset_index(drop=True)\n",
    "\n",
    "    orderLog['exchange'] = np.where(orderLog['secid'] >= 2000000, 'SZE', 'SSE')\n",
    "    orderLog['orderNtl'] = orderLog['orderPrice'] * orderLog['absOrderSize']\n",
    "    orderLog['tradeNtl'] = np.where(orderLog['updateType'] == 4, orderLog['tradePrice']*orderLog['absFilledThisUpdate'], 0)\n",
    "    orderLog[\"mrstaat\"] = orderLog.groupby(['order'])['mrstaat'].transform('first')\n",
    "    orderLog[\"ars\"] = orderLog.groupby(['order'])['ars'].transform('first')\n",
    "    orderLog[\"mrstauc\"] = orderLog.groupby(['order'])['mrstauc'].transform('first')\n",
    "    orderLog[\"mrsb90\"] = orderLog.groupby(['order'])['mrsb90'].transform('first')\n",
    "    orderLog[\"mrss90\"] = orderLog.groupby(['order'])['mrss90'].transform('first')\n",
    "    orderLog[\"aaa\"] = orderLog.groupby(['order'])['aaa'].transform('first')\n",
    "    orderLog = orderLog[~orderLog['ars'].isnull()]\n",
    "    # orderLog = orderLog[orderLog['ars'] % 10 == 1]\n",
    "\n",
    "\n",
    "    orderLog['m1'] = orderLog['mrstaat'].apply(lambda x: x - (x // 10000) * 10000)\n",
    "    orderLog['m2'] = orderLog['mrstauc'].apply(lambda x: x - (x // 10000) * 10000)\n",
    "    try:\n",
    "        orderLog['mrsb90'] = orderLog['mrsb90'].astype(float)\n",
    "    except:\n",
    "        print(orderLog[orderLog['mrsb90'] == '-'])\n",
    "        orderLog = orderLog[orderLog['mrsb90'] != '-']\n",
    "        orderLog['mrsb90'] = orderLog['mrsb90'].astype(float)\n",
    "    try:\n",
    "        orderLog['mrss90'] = orderLog['mrss90'].astype(float)\n",
    "    except:\n",
    "        print(orderLog[orderLog['mrss90'] == '-'])\n",
    "        orderLog = orderLog[orderLog['mrss90'] != '-']\n",
    "        orderLog['mrss90'] = orderLog['mrss90'].astype(float)\n",
    "    try:\n",
    "        orderLog['aaa'] = orderLog['aaa'].astype(float)\n",
    "    except:\n",
    "        print(orderLog[orderLog['aaa'] == '-'])\n",
    "        orderLog = orderLog[orderLog['aaa'] != '-']\n",
    "        orderLog['aaa'] = orderLog['aaa'].astype(float)\n",
    "\n",
    "    orderLog.loc[(orderLog['orderDirection'] >= 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrsb90']) < 1e-12), 'mrstauc'] = \\\n",
    "    orderLog.loc[(orderLog['orderDirection'] >= 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrsb90']) < 1e-12), 'm2']\n",
    "\n",
    "    orderLog.loc[(orderLog['orderDirection'] >= 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrsb90']) < 1e-12), 'mrstaat'] = \\\n",
    "    orderLog.loc[(orderLog['orderDirection'] >= 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrsb90']) < 1e-12), 'm1']\n",
    "\n",
    "    orderLog.loc[(orderLog['orderDirection'] < 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrss90']) < 1e-12), 'mrstauc'] = \\\n",
    "    orderLog.loc[(orderLog['orderDirection'] < 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrss90']) < 1e-12), 'm2']\n",
    "\n",
    "    orderLog.loc[(orderLog['orderDirection'] < 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrss90']) < 1e-12), 'mrstaat'] = \\\n",
    "    orderLog.loc[(orderLog['orderDirection'] < 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrss90']) < 1e-12), 'm1']    \n",
    "\n",
    "\n",
    "    orderLog['sta'] = np.where(orderLog['mrstaat'] == 1000, '1. staone', np.where(\n",
    "    orderLog['mrstaat'] == 3000, '2. statwo', np.where(\n",
    "    orderLog['mrstaat'].isin([11000, 13000]), '3. sta300', 'else')))\n",
    "    print(orderLog[(orderLog['sta'] == 'else') & (orderLog['updateType'] == 0)].groupby(['date', 'accCode'])['secid'].size())\n",
    "\n",
    "    m1 = orderLog[(orderLog['sta'] == 'else') & (orderLog['date'] == cur) & (orderLog['updateType'] == 0) & (orderLog['accCode'].isin([8854, 966301]))].shape[0]\n",
    "    if m1 != 0:\n",
    "        print(orderLog[(orderLog['sta'] == 'else') & (orderLog['date'] == cur) & (orderLog['updateType'] == 0) & (orderLog['accCode'].isin([8854, 966301]))])\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(m1) + ' orders with invalid strategy.<div>'                    \n",
    "    orderLog = orderLog[orderLog['mrstaat'].isin([11000, 13000, 1000, 3000])]\n",
    "    orderLog = orderLog[orderLog['accCode'].isin([8854, 966301])]\n",
    "    print(orderLog[orderLog['updateType'] == 0].groupby(['mrstaat', 'mrstauc'])['date'].size())\n",
    "\n",
    "    re1 = copydf[copydf['accCode'].isin([8854, 966301])].groupby(['date', 'accCode'])['order'].nunique().reset_index()\n",
    "    re2 = orderLog.groupby(['date', 'accCode'])['order'].nunique().reset_index()\n",
    "    re = pd.merge(re1, re2, on=['date', 'accCode'])\n",
    "    re = re[re['date'] == re['date'].max()]\n",
    "    re['diff'] = re['order_x'] - re['order_y']\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(re.groupby(['date', 'accCode']).first().to_html()))\n",
    "    m1 = re[re['accCode'] == 8854]['order_x'].sum()\n",
    "    m2 = re[re['accCode'] == 8854]['diff'].sum()\n",
    "    if m2 != 0:\n",
    "        count += 1\n",
    "        body += str(count) + '. There are in total ' + str(m2) + ' over ' + str(m1) + ' orders dropped in the filtering period in accCode 8854.<div>'       \n",
    "    m1 = re[re['accCode'] == 966301]['order_x'].sum()\n",
    "    m2 = re[re['accCode'] == 966301]['diff'].sum()\n",
    "    if m2 != 0:\n",
    "        count += 1\n",
    "        body += str(count) + '. There are in total ' + str(m2) + ' over ' + str(m1) + ' orders dropped in the filtering period in accCode 966301.<div>'       \n",
    "    if count == 0:\n",
    "        print('No assertions')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    body += '<p><b>II. fill rate</b></p>'\n",
    "\n",
    "    import pandas as pd\n",
    "    def convertToHtml(result,title):\n",
    "        #htmltable\n",
    "        #resultlist[list1,list2]\n",
    "        #titlelistresulttitleList[0]resultList[0]html\n",
    "        d = {}\n",
    "        index = 0\n",
    "        for t in title:\n",
    "            d[t]=result[index]\n",
    "            index = index+1\n",
    "        df = pd.DataFrame(d)\n",
    "        df = df[title]\n",
    "        h = df.to_html(index=False)\n",
    "        return h\n",
    "\n",
    "    placeSZE = orderLog[(orderLog['secid'] >= 2000000) & (orderLog['updateType'] == 0) & (orderLog['accCode'] == 8854)]\n",
    "    print('%.2f%% SZE orders triggered by msg data'%(placeSZE[placeSZE['isMsg'] == 1].shape[0]/placeSZE.shape[0]*100))\n",
    "    body += 'In 8854, %.2f%% SZE orders triggered by msg data<div>'%(placeSZE[placeSZE['isMsg'] == 1].shape[0]/placeSZE.shape[0]*100)\n",
    "    placeSZE = orderLog[(orderLog['secid'] >= 2000000) & (orderLog['updateType'] == 0) & (orderLog['accCode'] != 8854)]\n",
    "    print('%.2f%% SZE orders triggered by msg data'%(placeSZE[placeSZE['isMsg'] == 1].shape[0]/placeSZE.shape[0]*100))\n",
    "    body += 'In 966301, %.2f%% SZE orders triggered by msg data<div>'%(placeSZE[placeSZE['isMsg'] == 1].shape[0]/placeSZE.shape[0]*100)\n",
    "\n",
    "    orderLog['tag'] = 'previous'\n",
    "    orderLog.loc[orderLog['date'] == cur, 'tag'] = 'current'\n",
    "    o1 = orderLog[orderLog['updateType'] == 0].groupby(['tag', 'exchange', 'accCode'])['orderNtl'].sum().reset_index()\n",
    "    o2 = orderLog[orderLog['updateType'] == 4].groupby(['tag', 'exchange', 'accCode'])['tradeNtl'].sum().reset_index()\n",
    "    o = pd.merge(o1, o2, on=['tag', 'exchange', 'accCode'])\n",
    "    o['perc'] = o['tradeNtl'] / o['orderNtl']\n",
    "    o['perc'] = o['perc'].apply(lambda x: '%.f'%(x*100))\n",
    "    o1 = o[o['tag'] == 'current']\n",
    "    o1 = o1.rename(columns={'perc':'cur_perc'})\n",
    "    o2 = o[o['tag'] == 'previous']\n",
    "    o2 = o2.rename(columns={'perc':'prev_perc'})\n",
    "    re = pd.merge(o1[['exchange', 'accCode', 'cur_perc']], o2[['exchange', 'accCode', 'prev_perc']], on=['exchange', 'accCode'])\n",
    "\n",
    "    prev = orderLog[orderLog['tag'] == 'previous']\n",
    "    o1 = prev[prev['updateType'] == 0].groupby(['exchange', 'accCode', 'date'])['orderNtl'].sum().reset_index()\n",
    "    o2 = prev[prev['updateType'] == 4].groupby(['exchange', 'accCode', 'date'])['tradeNtl'].sum().reset_index()  \n",
    "    o = pd.merge(o1, o2, on=['exchange', 'accCode', 'date'])\n",
    "    o['perc'] = o['tradeNtl'] / o['orderNtl']\n",
    "    ree = o.groupby(['exchange', 'accCode'])['perc'].describe()[['mean', 'min', 'max']].reset_index()\n",
    "    ree = ree.rename(columns={'mean':'prev_mean', 'min':'prev_min', 'max':'prev_max'})\n",
    "    for cols in ['prev_mean', 'prev_min', 'prev_max']:\n",
    "        ree[cols] = ree[cols].apply(lambda x: '%.f'%(x*100))\n",
    "    re = pd.merge(re, ree, on=['accCode', 'exchange'])\n",
    "    re = re.sort_values(by=['accCode', 'exchange'])\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(re.groupby(['exchange', 'accCode']).first().to_html()))\n",
    "    result = [re['accCode'].values, re['exchange'].values, re['cur_perc'].values, re['prev_min'].values, re['prev_mean'].values, re['prev_max'].values]\n",
    "    title=['accCode', 'exchange', 'cur_fillRate', 'prev_min', 'prev_mean', 'prev_max']\n",
    "    body += convertToHtml(result,title)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "    import datetime\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    body += '<p><b>III. order return</b></p>'\n",
    "    checkLog = orderLog[orderLog['updateType'] == 4]\n",
    "    if checkLog[checkLog['absFilledThisUpdate'] == 0].shape[0] != 0:\n",
    "        print('There are stocks with zero trade size')\n",
    "        print(checkLog[checkLog['absFilledThisUpdate'] == 0].groupby(['colo', 'accCode'])['secid'].size())\n",
    "        checkLog = checkLog[checkLog['absFilledThisUpdate'] != 0]\n",
    "    if checkLog[checkLog['beta_60'].isnull()].shape[0] != 0:\n",
    "        print('There are stocks with null beta')\n",
    "        print(checkLog[checkLog['beta_60'].isnull()])\n",
    "        checkLog = checkLog[~checkLog['beta_60'].isnull()]\n",
    "    checkLog['max_trade'] = checkLog.groupby('order')['absOrderSizeCumFilled'].transform('max')\n",
    "    checkLog['last'] = 0\n",
    "    checkLog.loc[checkLog['max_trade'] == checkLog['absOrderSizeCumFilled'], 'last'] = 1\n",
    "    checkLog[\"buyRet\"] = np.where(checkLog[\"orderDirection\"].isin([1, 2]), checkLog[\"adjMid_F90s\"] / checkLog[\"tradePrice\"] - 1, np.nan)\n",
    "    checkLog[\"buyRet1\"] = np.where(checkLog[\"orderDirection\"].isin([1, 2]), checkLog[\"adjMid_F300s\"] / checkLog[\"tradePrice\"] - 1, np.nan)\n",
    "    checkLog[\"sellRet\"] = np.where(checkLog[\"orderDirection\"].isin([-1, -2]), checkLog[\"tradePrice\"] / checkLog[\"adjMid_F90s\"] - 1, np.nan)\n",
    "    checkLog[\"sellRet1\"] = np.where(checkLog[\"orderDirection\"].isin([-1, -2]), checkLog[\"tradePrice\"] / checkLog[\"adjMid_F300s\"] - 1, np.nan)\n",
    "    checkLog[\"buyNum\"] = np.where((checkLog[\"orderDirection\"].isin([1, 2])) & (checkLog['last'] == 1), 1, 0)\n",
    "    checkLog[\"sellNum\"] = np.where((checkLog[\"orderDirection\"].isin([-1, -2])) & (checkLog['last'] == 1), 1, 0)\n",
    "    checkLog[\"server\"] = checkLog[\"colo\"].apply(lambda x: x.split(\"_\")[0] + x.split(\"_\")[1] + x.split(\"_\")[2])\n",
    "    checkLog[\"server_account\"] = checkLog[\"server\"] + '_' + checkLog['accCode'].astype('str')\n",
    "    df = checkLog[(checkLog['ars']%10 == 1)]\n",
    "\n",
    "    df['tradeNtl'] = df['tradePrice']*df['absFilledThisUpdate']\n",
    "    df[\"buyNtl\"] = np.where(~df[\"buyRet\"].isnull(), df[\"tradeNtl\"], np.nan)\n",
    "    df[\"sellNtl\"] = np.where(~df[\"sellRet\"].isnull(), df[\"tradeNtl\"], np.nan)\n",
    "    df[\"sumbuyNtl\"] = df.groupby([\"date\", \"exchange\", \"accCode\"])[\"buyNtl\"].transform(sum)\n",
    "    df[\"sumsellNtl\"] = df.groupby([\"date\", \"exchange\", \"accCode\"])[\"sellNtl\"].transform(sum)\n",
    "\n",
    "    df[\"sumsellRet\"] = df[\"tradeNtl\"] * df[\"sellRet\"]\n",
    "    df[\"sumsellRet\"] = df.groupby([\"date\", \"exchange\", \"accCode\"])[\"sumsellRet\"].transform(sum)\n",
    "\n",
    "\n",
    "    df[\"sumbuyRet\"] = df[\"tradeNtl\"] * df[\"buyRet\"]\n",
    "    df[\"sumbuyRet\"] = df.groupby([\"date\", \"exchange\", \"accCode\"])[\"sumbuyRet\"].transform(sum)\n",
    "\n",
    "    df[\"buyRet\"] = df[\"sumbuyRet\"] / df[\"sumbuyNtl\"]\n",
    "    df[\"sellRet\"] = df[\"sumsellRet\"] / df[\"sumsellNtl\"]\n",
    "    df[\"buyOrderNum\"] = df.groupby([\"date\", \"exchange\", \"accCode\"])[\"buyNum\"].transform(sum)\n",
    "    df[\"sellOrderNum\"] = df.groupby([\"date\", \"exchange\", \"accCode\"])[\"sellNum\"].transform(sum)\n",
    "\n",
    "\n",
    "    from IPython.display import display, HTML\n",
    "    for col in [\"buyRet\", \"sellRet\"]:\n",
    "        df[col] = (df[col] * 10000).round(2)\n",
    "\n",
    "    re = df.groupby([\"exchange\", \"date\", \"accCode\"])[\"buyOrderNum\", \"buyRet\", \"sellOrderNum\", \"sellRet\"].first().reset_index()\n",
    "\n",
    "    cur1 = re[(re['date'] == checkLog['date'].max()) & (re['buyOrderNum'] != 0)].groupby([\"exchange\", 'date', \"accCode\"])[\"buyRet\"].first().reset_index()\n",
    "    cur1['Side'] = 'Buy'\n",
    "    cur1 = cur1.rename(columns={'buyRet':'cur_ret'})\n",
    "    cur2 = re[(re['date'] == checkLog['date'].max()) & (re['sellOrderNum'] != 0)].groupby([\"exchange\", 'date', \"accCode\"])[\"sellRet\"].first().reset_index()\n",
    "    cur2['Side'] = 'Sell'\n",
    "    cur2 = cur2.rename(columns={'sellRet':'cur_ret'})   \n",
    "    cur = pd.concat([cur1[['exchange', 'accCode', 'Side', 'cur_ret']], cur2[['exchange', 'accCode', 'Side', 'cur_ret']]])\n",
    "\n",
    "    prev1 = re[(re['date'] != checkLog['date'].max()) & (re['buyOrderNum'] != 0)].groupby([\"exchange\", \"accCode\"])[\"buyRet\"].describe()[['mean', 'min', 'max']].reset_index()\n",
    "    prev1['Side'] = 'Buy'\n",
    "    prev1 = prev1.rename(columns={'mean':'prev_mean', 'min':'prev_min', 'max':'prev_max'})\n",
    "    prev2 = re[re['date'] != checkLog['date'].max() & (re['sellOrderNum'] != 0)].groupby([\"exchange\", \"accCode\"])[\"sellRet\"].describe()[['mean', 'min', 'max']].reset_index()\n",
    "    prev2['Side'] = 'Sell'\n",
    "    prev2 = prev2.rename(columns={'mean':'prev_mean', 'min':'prev_min', 'max':'prev_max'})     \n",
    "    prev = pd.concat([prev1[['exchange', 'accCode', 'Side', 'prev_mean', 'prev_min', 'prev_max']], prev2[['exchange', 'accCode', 'Side', 'prev_mean', 'prev_min', 'prev_max']]])    \n",
    "\n",
    "    ree = pd.merge(cur, prev, on=['exchange', 'Side', 'accCode'], how='outer')\n",
    "    ree = ree.sort_values(by=['accCode', 'exchange','Side'])\n",
    "    display(HTML(ree.groupby(['accCode', 'exchange','Side']).first().to_html()))\n",
    "\n",
    "    for i in ['prev_mean', 'prev_min', 'prev_max']:\n",
    "        ree[i] = ree[i].round(2)\n",
    "\n",
    "    body += '<div>The following shows SSE order return in this period:<div>'\n",
    "    ree1 = ree[ree['exchange'] == 'SSE']\n",
    "    result = [ree1['accCode'].values, ree1['exchange'].values, ree1['Side'].values,\n",
    "             ree1['cur_ret'].values, ree1['prev_min'].values, ree1['prev_mean'].values, ree1['prev_max'].values]\n",
    "    title = ['accCode', 'exchange','Side', 'cur_ret', 'prev_min', 'prev_mean', 'prev_max']\n",
    "    body += convertToHtml(result,title)\n",
    "\n",
    "    body += '<div>The following shows SZE order return in this period:<div>'\n",
    "    ree2 = ree[ree['exchange'] == 'SZE']\n",
    "    result = [ree2['accCode'].values, ree2['exchange'].values, ree2['Side'].values, \n",
    "             ree2['cur_ret'].values, ree2['prev_min'].values, ree2['prev_mean'].values, ree2['prev_max'].values]\n",
    "    title = ['accCode', 'exchange','Side', 'cur_ret', 'prev_min', 'prev_mean', 'prev_max']\n",
    "    body += convertToHtml(result,title)\n",
    "\n",
    "    import smtplib\n",
    "    from email.mime.text import MIMEText\n",
    "    from email.mime.multipart import MIMEMultipart    \n",
    "\n",
    "    title = str(orderLog['date'].max()) + ' 8854 & 966301 daily report'\n",
    "    body = body + \"</div></body></html>\"\n",
    "    smtp_server = '42.120.226.4' # 'smtp.mxhichina.com'\n",
    "    user = 'zhenyu.yin@general-int.com'\n",
    "    passwd = 'Yqzy0063!'\n",
    "    from_addr = 'zhenyu.yin@general-int.com'\n",
    "    to_addr = ['zhenyu.yin@general-int.com', 'kevin.zhang@general-int.com', 'felix.ma@general-int.com']\n",
    "#     to_addr = ['zhenyu.yin@general-int.com']\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = from_addr\n",
    "    msg['To'] = ', '.join(to_addr)\n",
    "    msg['Subject'] = title\n",
    "    txt = MIMEText(body, _subtype='html', _charset='UTF-8')\n",
    "    msg.attach(txt)\n",
    "\n",
    "    smtp = None\n",
    "    while True:\n",
    "        try:\n",
    "            smtp = smtplib.SMTP(smtp_server)\n",
    "            print('smtp server connected')\n",
    "            smtp.login(user, passwd)\n",
    "            print('login')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    print('send mail')\n",
    "    smtp.sendmail(from_addr, to_addr, msg.as_string())\n",
    "    smtp.quit()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "from twisted.internet import task, reactor\n",
    "import schedule\n",
    "\n",
    "\n",
    "def sleeptime(hour,min,sec):\n",
    "    return hour*3600 + min*60 + sec\n",
    "\n",
    "\n",
    "class Test(object):\n",
    "    def __init__(self):\n",
    "        self.status = True        \n",
    "    def test(self):\n",
    "        while self.status == True:\n",
    "            try:\n",
    "                print(datetime.datetime.now())\n",
    "#                 date = (datetime.datetime.today()).strftime('%Y%m%d')\n",
    "                date = '20210113'\n",
    "                readPath = '/mnt/orderLog/data/***'\n",
    "                dataPathLs = np.array(glob.glob(readPath))\n",
    "                dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "                assert(np.max(dateLs) == int(date))\n",
    "                print('We start to generate report now')\n",
    "                generate_report(date)\n",
    "                self.status = False\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('still wait for data coming')  \n",
    "                second = sleeptime(0,5,0)\n",
    "                time.sleep(second)\n",
    "\n",
    "test1 = Test()\n",
    "schedule.every().day.at(\"22:02\").do(test1.test)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

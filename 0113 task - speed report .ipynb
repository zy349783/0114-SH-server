{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-13 22:03:00.388050\n",
      "\n",
      "still wait for data coming\n",
      "2021-01-13 22:08:00.495325\n",
      "We start to generate report now\n",
      "start\n",
      "-----------------------------------------------------------------------------------------------\n",
      "load data\n",
      "/mnt/orderLog/data/20201229.pkl\n",
      "/mnt/orderLog/data/20201230.pkl\n",
      "/mnt/orderLog/data/20201231.pkl\n",
      "/mnt/orderLog/data/20210104.pkl\n",
      "/mnt/orderLog/data/20210105.pkl\n",
      "/mnt/orderLog/data/20210106.pkl\n",
      "/mnt/orderLog/data/20210107.pkl\n",
      "/mnt/orderLog/data/20210108.pkl\n",
      "/mnt/orderLog/data/20210111.pkl\n",
      "/mnt/orderLog/data/20210112.pkl\n",
      "/mnt/orderLog/data/20210113.pkl\n",
      "There are ticks with orderDirection 0\n",
      "             date      colo  accCode    secid  vai  updateType      sdd  \\\n",
      "48658    20201229  zt_96_01   966301  1600376   -1           1     -1.0   \n",
      "48659    20201229  zt_96_01   966301  1600376   -1           1     -1.0   \n",
      "48660    20201229  zt_96_01   966301  1600376   -1           1     -1.0   \n",
      "247510   20201229  zt_52_04   537301  1603786   -1           1     -1.0   \n",
      "271265   20201229  zt_52_04   528401  1603979   -1           1  52020.0   \n",
      "...           ...       ...      ...      ...  ...         ...      ...   \n",
      "9372816  20210113  zs_94_05     9471  2002706   -1           7  40409.0   \n",
      "9419258  20210113  zs_54_01     5474  2002882   -1           1  37983.0   \n",
      "9452349  20210113  zs_94_05     9454  2002988   -1           1  47829.0   \n",
      "9657899  20210113  zs_66_01     6634  2300681   -1           7  34440.0   \n",
      "9683521  20210113  zs_94_05     9454  2300750   -1           7  48848.0   \n",
      "\n",
      "         orderDirection  absOrderSize  internalId      orderId  \n",
      "48658                 0             0        -1.0         15.0  \n",
      "48659                 0             0        -1.0         16.0  \n",
      "48660                 0             0        -1.0         17.0  \n",
      "247510                0             0        -1.0         14.0  \n",
      "271265                0             0        -1.0     479470.0  \n",
      "...                 ...           ...         ...          ...  \n",
      "9372816               0             0        -1.0         -1.0  \n",
      "9419258               0             0        -1.0  868907304.0  \n",
      "9452349               0             0        -1.0    2300356.0  \n",
      "9657899               0             0        -1.0         -1.0  \n",
      "9683521               0             0        -1.0         -1.0  \n",
      "\n",
      "[198 rows x 11 columns]\n",
      "There are orders with all things same except sdd\n",
      "        Unnamed: 0  ApplSeqNum       aaa  absFilledThisUpdate  absOrderSize  \\\n",
      "466842    466842.0   1444460.0  0.000687                    0           100   \n",
      "466902    466902.0   9795909.0  0.000694                    0           100   \n",
      "\n",
      "        absOrderSizeCumFilled  accCode  ars             caamd  \\\n",
      "466842                      0   966301  1.0  1609205575014635   \n",
      "466902                      0   966301  1.0  1609208372125359   \n",
      "\n",
      "        cancellationPending        cfe         clock    clockAtArrival  \\\n",
      "466842                  0.0  128034.25  1.609206e+15  1609205575014666   \n",
      "466902                  0.0   52600.79  1.609208e+15  1609208372125429   \n",
      "\n",
      "        cumSharesBought  cumSharesBuyInserted  cumSharesSellInserted  \\\n",
      "466842              0.0                   0.0                  300.0   \n",
      "466902              0.0                   0.0                  600.0   \n",
      "\n",
      "        cumSharesSold      date  finalState        gfe       hee  \\\n",
      "466842          200.0  20201229         0.0  128033.25  0.000504   \n",
      "466902          400.0  20201229         0.0   52599.79 -0.000102   \n",
      "\n",
      "        insertedShortOrder  insertionPending  internalId  inv_L  inv_L0  \\\n",
      "466842                 0.0               1.0         9.0  700.0     0.0   \n",
      "466902                 0.0               1.0         9.0  100.0     0.0   \n",
      "\n",
      "        inv_S  inv_S0            l4algoDebug  l4tr  locateShares  \\\n",
      "466842    0.0     0.0                    NaN   0.0           0.0   \n",
      "466902    0.0     0.0  1015.000000|2.000000|   0.0           0.0   \n",
      "\n",
      "        locateSharesTotal  mfe  mra100  mrb100       mrm     mrm25  mrmum  \\\n",
      "466842                0.0 -1.0  2765.0  2764.0 -0.000118  -0.00139   -1.0   \n",
      "466902                0.0 -1.0  2774.0  2771.0  0.000174 -0.002573   -1.0   \n",
      "\n",
      "        mrrlma mrsb300    mrsb90  mrss300    mrss90  mrstaat  mrstauc  \\\n",
      "466842    -1.0      -1 -0.001033     -1.0  0.000687   1000.0      0.0   \n",
      "466902    -1.0      -1 -0.001770     -1.0  0.000694   1000.0      0.0   \n",
      "\n",
      "        mrstaum        mrv               ms  mse   mt  mta   mv  \\\n",
      "466842     -1.0   140020.0  09:32:55.014196  100  0.0 -999  0.0   \n",
      "466902     -1.0  1976879.0  10:19:32.125029  100  0.0 -999  0.0   \n",
      "\n",
      "        orderDirection  orderId  orderOutstanding  orderPrice orderSysId  \\\n",
      "466842              -1      9.0               0.0       27.64        NaN   \n",
      "466902              -1     -1.0               0.0       27.71        NaN   \n",
      "\n",
      "        resa          sdd    secid  sequenceNo  session  threadId  \\\n",
      "466842   2.0   93255060.0  2002595   8271885.0        5   29229.0   \n",
      "466902   2.0  101932190.0  2002595  56341419.0        1   29306.0   \n",
      "\n",
      "        totalActions  totalCanceled tradeId  tradePrice  underlyingIndex  \\\n",
      "466842           7.0            0.0     NaN        -1.0              905   \n",
      "466902          10.0            1.0     NaN        -1.0              905   \n",
      "\n",
      "        updateType      vai                            zipFile      colo  \\\n",
      "466842           0   140020  logs_20201229_zt_96_01_day_966301  zt_96_01   \n",
      "466902           0  1976879  logs_20201229_zt_96_01_day_966301  zt_96_01   \n",
      "\n",
      "        caa_orderLog    start_time     Price  OrderQty  Side statusLs  \\\n",
      "466842  1.609206e+15  1.609206e+15  276400.0     100.0   2.0   (0, 4)   \n",
      "466902           NaN           NaN       NaN       NaN   NaN      NaN   \n",
      "\n",
      "       TradePriceLs TradeQtyLs   beta_60  adjMid_F30s  adjMid_F90s  \\\n",
      "466842  (0, 276400)   (0, 100)  0.581536    27.643913    27.627500   \n",
      "466902          NaN        NaN  0.581536    27.649275    27.629737   \n",
      "\n",
      "        adjMid_F300s  indexClose  indexClose_F30s  indexClose_F90s  \\\n",
      "466842     27.473333   6239.2341        6241.7701        6238.8906   \n",
      "466902     27.631667   6235.4744        6234.7954        6229.9708   \n",
      "\n",
      "        indexClose_F300s  \n",
      "466842         6226.1042  \n",
      "466902         6237.2874  \n",
      "There are orders with same internalId but different orderId other than accCode 8856 case\n",
      "date      colo      accCode  secid    orderDirection  absOrderSize  internalId\n",
      "20201229  zt_96_01  966301   1600376   0              0             -1.0          3\n",
      "                             2002595  -1              100            9.0          2\n",
      "Name: orderId, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are orders in 8856 with same internalId and various orderId!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "     secid  accCode      colo      vai  updateType         sdd  internalId  \\\n",
      "0  2300271     8856  zs_88_04  22400.0           0  93007340.0        30.0   \n",
      "1  2300271     8856  zs_88_04  22400.0           2        -1.0        30.0   \n",
      "2  2300271     8856  zs_88_04  22400.0           1     34209.0        30.0   \n",
      "3  2300271     8856  zs_88_04  22400.0           3        -1.0        30.0   \n",
      "4  2300271     8856  zs_88_04  22400.0           0  93009860.0        34.0   \n",
      "5  2300271     8856  zs_88_04  22400.0           2        -1.0        34.0   \n",
      "6  2300271     8856  zs_88_04  22400.0           2        -1.0        34.0   \n",
      "\n",
      "   orderId  absOrderSize  absFilledThisUpdate  absOrderSizeCumFilled  \\\n",
      "0     30.0           100                    0                      0   \n",
      "1     30.0           100                    0                      0   \n",
      "2     30.0           100                    0                      0   \n",
      "3     30.0           100                    0                      0   \n",
      "4     34.0           100                    0                      0   \n",
      "5     34.0           100                    0                      0   \n",
      "6     34.0           100                  100                    100   \n",
      "\n",
      "   orderPrice  tradePrice  \n",
      "0       24.73        -1.0  \n",
      "1       24.73        -1.0  \n",
      "2       24.73        -1.0  \n",
      "3       24.73        -1.0  \n",
      "4       24.70        -1.0  \n",
      "5       24.70        -1.0  \n",
      "6       24.70        24.7  \n",
      "=======================================================================================\n",
      "1. same date, secid, vai: same direction\n",
      "orders with abnormal ars values\n",
      "ars\n",
      "0.0    23\n",
      "Name: date, dtype: int64\n",
      "accCode\n",
      "527603    2\n",
      "974101    1\n",
      "523101    1\n",
      "6683      1\n",
      "8854      1\n",
      "8886      1\n",
      "9451      1\n",
      "9461      1\n",
      "522201    1\n",
      "522401    1\n",
      "522501    1\n",
      "522601    1\n",
      "522901    1\n",
      "523001    1\n",
      "526901    1\n",
      "897102    1\n",
      "527601    1\n",
      "527701    1\n",
      "528101    1\n",
      "528401    1\n",
      "528701    1\n",
      "528703    1\n",
      "528901    1\n",
      "529001    1\n",
      "529101    1\n",
      "529103    1\n",
      "5287      1\n",
      "Name: date, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opposite direction for same date, same secid, same vai\n",
      "accCode\n",
      "5222      1\n",
      "5225      1\n",
      "5230      2\n",
      "5232      1\n",
      "5289      1\n",
      "5290      3\n",
      "5291      2\n",
      "5326      2\n",
      "5329      3\n",
      "5377      1\n",
      "5384      2\n",
      "5386      1\n",
      "5470      2\n",
      "5474      2\n",
      "6480      3\n",
      "6623      2\n",
      "6627      4\n",
      "6631      1\n",
      "6634      2\n",
      "6878      1\n",
      "8924      1\n",
      "8943      2\n",
      "8970      1\n",
      "9208      1\n",
      "9243      1\n",
      "9248      1\n",
      "9448      5\n",
      "9454      1\n",
      "9461      1\n",
      "9471      1\n",
      "9551      1\n",
      "9655      2\n",
      "9741      1\n",
      "9754      2\n",
      "9756      1\n",
      "9765      2\n",
      "523101    1\n",
      "527101    3\n",
      "528701    2\n",
      "529001    1\n",
      "529101    1\n",
      "897102    2\n",
      "974102    1\n",
      "Name: orderDirection, dtype: int64\n",
      "=======================================================================================\n",
      "2. same date, secid, vai, accCode: one insertion\n",
      "more than one insertion at same time\n",
      "             date      colo  accCode    secid        vai          sdd  \\\n",
      "1574263  20210108  zs_96_08     6237  1603317  1375708.0  103134000.0   \n",
      "\n",
      "         clockAtArrival  \n",
      "1574263               2  \n",
      "date\n",
      "20210108    1\n",
      "Name: accCode, dtype: int64\n",
      "date      accCode\n",
      "20210108  6237       1\n",
      "Name: sdd, dtype: int64\n",
      "=======================================================================================\n",
      "3. IPO stocks selling (ars = 301, 302)\n",
      "=======================================================================================\n",
      "4. updateType 7 orders\n",
      "=======================================================================================\n",
      "5. updateType 6 orders\n",
      "=======================================================================================\n",
      "6. CYB stocks order size < 30w\n",
      "=======================================================================================\n",
      "7. unexpected updateType\n",
      "updateType\n",
      "(0, 2, 1, 3, 4)                     34\n",
      "(0, 2, 1, 4, 3, 4)                   5\n",
      "(0, 2, 2, 2)                        78\n",
      "(0, 2, 2, 2, 1, 3)                   2\n",
      "(0, 2, 2, 2, 2)                     10\n",
      "(0, 2, 2, 2, 2, 2)                   3\n",
      "(0, 2, 2, 2, 2, 2, 2)                1\n",
      "(0, 2, 2, 2, 2, 2, 2, 2, 1, 3)       1\n",
      "(0, 2, 4, 1)                        13\n",
      "(0, 2, 4, 1, 3, 4)                  26\n",
      "(0, 2, 4, 1, 4, 3, 4)                6\n",
      "(0, 2, 4, 3)                         5\n",
      "(0, 2, 6)                          112\n",
      "(0, 6)                            1041\n",
      "(0, 8)                              21\n",
      "Name: order, dtype: int64\n",
      "=======================================================================================\n",
      "8. status == 0: all traded\n",
      "in total trade, any fill != total cases\n",
      "             date    order  filled  total\n",
      "5297     20201229     7181    4200   6300\n",
      "5874     20201229     8070     600   5600\n",
      "7512     20201229    10421     100   1500\n",
      "8699     20201229    12110     300    600\n",
      "9691     20201229    13488    1200   2400\n",
      "...           ...      ...     ...    ...\n",
      "1780894  20210113  2354453    8000  21100\n",
      "1782772  20210113  2357333    1200   1800\n",
      "1787625  20210113  2364372    1500   2000\n",
      "1791741  20210113  2370170     100    600\n",
      "1816283  20210113  2403759    1100   1400\n",
      "\n",
      "[288 rows x 4 columns]\n",
      "=======================================================================================\n",
      "9. status == 1: partial traded\n",
      "in partial trade, any fill >= total or fill is 0 cases for updateType 4\n",
      "Empty DataFrame\n",
      "Columns: [date, order, filled, total]\n",
      "Index: []\n",
      "=======================================================================================\n",
      "10. no cancellation within 1 sec\n",
      "any cancellation within 1 sec\n",
      "         Unnamed: 0  ApplSeqNum aaa  absFilledThisUpdate  absOrderSize  \\\n",
      "1372876    148575.0         0.0  -1                    0           100   \n",
      "1372988    189358.0         0.0  -1                    0           100   \n",
      "1373019    195686.0         0.0  -1                    0           200   \n",
      "1373090    205040.0         0.0  -1                    0           100   \n",
      "1373161    213178.0         0.0  -1                    0           100   \n",
      "...             ...         ...  ..                  ...           ...   \n",
      "3185846    530282.0         0.0  -1                    0           200   \n",
      "3185885    547850.0         0.0  -1                    0           900   \n",
      "3185889    547853.0         0.0  -1                    0           900   \n",
      "3185925    574317.0         0.0  -1                    0           100   \n",
      "3185985    652581.0         0.0  -1                    0          1300   \n",
      "\n",
      "         absOrderSizeCumFilled  accCode  ars             caamd  \\\n",
      "1372876                      0     8854  1.0  1609307843130063   \n",
      "1372988                      0     8854  1.0  1609298373762077   \n",
      "1373019                      0     8854  1.0  1609296809192182   \n",
      "1373090                      0     8854  1.0  1609306975678291   \n",
      "1373161                      0     8854  1.0  1609307131162699   \n",
      "...                        ...      ...  ...               ...   \n",
      "3185846                      0   966301  2.0  1609723936630655   \n",
      "3185885                      0   966301  2.0  1609723949533510   \n",
      "3185889                      0   966301  2.0  1609723950622143   \n",
      "3185925                      0   966301  1.0  1609724838773633   \n",
      "3185985                    800   966301  2.0  1609723930017591   \n",
      "\n",
      "         cancellationPending         cfe                      clock  \\\n",
      "1372876                  1.0  5423341.79 2020-12-30 13:57:23.309056   \n",
      "1372988                  1.0  4339395.87 2020-12-30 11:19:34.180024   \n",
      "1373019                  1.0  4226087.47 2020-12-30 10:53:29.509160   \n",
      "1373090                  1.0  5409570.09 2020-12-30 13:42:56.338860   \n",
      "1373161                  1.0  5418525.78 2020-12-30 13:45:31.933621   \n",
      "...                      ...         ...                        ...   \n",
      "3185846                  1.0    53455.40 2021-01-04 09:32:17.501808   \n",
      "3185885                  1.0    58174.40 2021-01-04 09:32:30.495846   \n",
      "3185889                  1.0    58174.40 2021-01-04 09:32:30.914660   \n",
      "3185925                  1.0    34669.75 2021-01-04 09:47:19.569383   \n",
      "3185985                  1.0    29716.18 2021-01-04 09:32:10.278895   \n",
      "\n",
      "           clockAtArrival  cumSharesBought  cumSharesBuyInserted  \\\n",
      "1372876  1609307843309056              0.0                   0.0   \n",
      "1372988  1609298374180024              0.0                   0.0   \n",
      "1373019  1609296809509160            600.0                 800.0   \n",
      "1373090  1609306976338860              0.0                   0.0   \n",
      "1373161  1609307131933621           2800.0                5600.0   \n",
      "...                   ...              ...                   ...   \n",
      "3185846  1609723937501808              0.0                 200.0   \n",
      "3185885  1609723950495846              0.0                1800.0   \n",
      "3185889  1609723950914660              0.0                2700.0   \n",
      "3185925  1609724839569383              0.0                 100.0   \n",
      "3185985  1609723930278895            800.0                1300.0   \n",
      "\n",
      "         cumSharesSellInserted  cumSharesSold      date  finalState  \\\n",
      "1372876                  100.0            0.0  20201230         0.0   \n",
      "1372988                  200.0          100.0  20201230         0.0   \n",
      "1373019                    0.0            0.0  20201230         0.0   \n",
      "1373090                  100.0            0.0  20201230         0.0   \n",
      "1373161                    0.0            0.0  20201230         0.0   \n",
      "...                        ...            ...       ...         ...   \n",
      "3185846                    0.0            0.0  20210104         0.0   \n",
      "3185885                    0.0            0.0  20210104         0.0   \n",
      "3185889                    0.0            0.0  20210104         0.0   \n",
      "3185925                    0.0            0.0  20210104         0.0   \n",
      "3185985                    0.0            0.0  20210104         0.0   \n",
      "\n",
      "                gfe  hee  insertedShortOrder  insertionPending  internalId  \\\n",
      "1372876  5423340.79 -1.0                 0.0               0.0       190.0   \n",
      "1372988  4339394.87 -1.0                 0.0               0.0       287.0   \n",
      "1373019  4226086.47 -1.0                 0.0               0.0       201.0   \n",
      "1373090  5409569.09 -1.0                 0.0               0.0       152.0   \n",
      "1373161  5418524.78 -1.0                 0.0               0.0       170.0   \n",
      "...             ...  ...                 ...               ...         ...   \n",
      "3185846    53454.40 -1.0                 0.0               0.0        20.0   \n",
      "3185885    58173.40 -1.0                 0.0               0.0        27.0   \n",
      "3185889    58173.40 -1.0                 0.0               0.0        28.0   \n",
      "3185925    34668.75 -1.0                 0.0               0.0        80.0   \n",
      "3185985    29715.18 -1.0                 0.0               0.0         5.0   \n",
      "\n",
      "          inv_L  inv_L0  inv_S  inv_S0   l4algoDebug  l4tr  locateShares  \\\n",
      "1372876   100.0     0.0    0.0     0.0  1345.000000|   0.0           0.0   \n",
      "1372988  6700.0     0.0    0.0     0.0  1115.000000|   0.0           0.0   \n",
      "1373019   600.0   600.0    0.0     0.0  1045.000000|   0.0           0.0   \n",
      "1373090  4250.0     0.0    0.0     0.0  1330.000000|   0.0           0.0   \n",
      "1373161  5710.0  5700.0    0.0     0.0  1345.000000|   0.0           0.0   \n",
      "...         ...     ...    ...     ...           ...   ...           ...   \n",
      "3185846     0.0     0.0    0.0     0.0   932.000000|   0.0           0.0   \n",
      "3185885     0.0     0.0    0.0     0.0   932.000000|   0.0           0.0   \n",
      "3185889     0.0     0.0    0.0     0.0   932.000000|   0.0           0.0   \n",
      "3185925     0.0     0.0    0.0     0.0   945.000000|   0.0           0.0   \n",
      "3185985   800.0   800.0    0.0     0.0   932.000000|   0.0           0.0   \n",
      "\n",
      "         locateSharesTotal  mfe   mra100   mrb100       mrm     mrm25  mrmum  \\\n",
      "1372876                0.0 -1.0   1957.0   1951.0 -0.004078  0.000603   -1.0   \n",
      "1372988                0.0 -1.0   3494.0   3475.0 -0.000817  0.002538   -1.0   \n",
      "1373019                0.0 -1.0   7262.0   7261.0  0.001725  0.004244   -1.0   \n",
      "1373090                0.0 -1.0   6699.0   6637.0  0.002238  -6.9e-05   -1.0   \n",
      "1373161                0.0 -1.0   1559.0   1552.0  0.000841  0.003929   -1.0   \n",
      "...                    ...  ...      ...      ...       ...       ...    ...   \n",
      "3185846                0.0 -1.0  10561.0  10504.0 -0.001579  0.005775   -1.0   \n",
      "3185885                0.0 -1.0   2645.0   2643.0 -0.000005  0.004194   -1.0   \n",
      "3185889                0.0 -1.0   2645.0   2639.0 -0.000018  0.004194   -1.0   \n",
      "3185925                0.0 -1.0  14511.0  14507.0  0.001088  0.002808   -1.0   \n",
      "3185985                0.0 -1.0   2408.0   2406.0  0.000951  0.003843   -1.0   \n",
      "\n",
      "         mrrlma   mrsb300    mrsb90   mrss300    mrss90  mrstaat  mrstauc  \\\n",
      "1372876    -1.0 -0.003175 -0.001534  0.000110 -0.001057  13000.0  11000.0   \n",
      "1372988    -1.0 -0.002911 -0.003110 -0.002534 -0.002361  13000.0  11000.0   \n",
      "1373019    -1.0  0.001422  0.000137 -0.001558 -0.000264  13000.0  11000.0   \n",
      "1373090    -1.0 -0.004424 -0.006091 -0.004853 -0.002701  13000.0  11000.0   \n",
      "1373161    -1.0 -0.001153 -0.001560 -0.003341 -0.002308  13000.0  11000.0   \n",
      "...         ...       ...       ...       ...       ...      ...      ...   \n",
      "3185846    -1.0        -1 -0.002121 -1.000000 -0.003390   1000.0      0.0   \n",
      "3185885    -1.0        -1 -0.001647 -1.000000  0.000912   1000.0      0.0   \n",
      "3185889    -1.0        -1 -0.002272 -1.000000  0.000001   1000.0      0.0   \n",
      "3185925    -1.0        -1  0.000265 -1.000000 -0.000506   1000.0      0.0   \n",
      "3185985    -1.0        -1 -0.000592 -1.000000 -0.000350   1000.0      0.0   \n",
      "\n",
      "         mrstaum         mrv               ms  mse   mt mta   mv  \\\n",
      "1372876     -1.0  17761035.0  13:57:23.307447   22 -1.0  -1  0.0   \n",
      "1372988     -1.0   3483963.0  11:19:34.178594   22 -1.0  -1  0.0   \n",
      "1373019     -1.0   1703499.0  10:53:29.507618   22 -1.0  -1  0.0   \n",
      "1373090     -1.0   6335649.0  13:42:56.337460   22 -1.0  -1  0.0   \n",
      "1373161     -1.0   1747688.0  13:45:31.932458   22 -1.0  -1  0.0   \n",
      "...          ...         ...              ...  ...  ...  ..  ...   \n",
      "3185846     -1.0     89807.0  09:32:17.501095  100 -1.0  -1  0.0   \n",
      "3185885     -1.0    221900.0  09:32:30.495095  100 -1.0  -1  0.0   \n",
      "3185889     -1.0    222000.0  09:32:30.914095  100 -1.0  -1  0.0   \n",
      "3185925     -1.0    229400.0  09:47:19.569041  100 -1.0  -1  0.0   \n",
      "3185985     -1.0   2887159.0  09:32:10.278096  100 -1.0  -1  0.0   \n",
      "\n",
      "         orderDirection       orderId  orderOutstanding  orderPrice  \\\n",
      "1372876              -1  8.885000e+03               1.0       19.58   \n",
      "1372988              -1  6.477000e+03               1.0       34.96   \n",
      "1373019               1  5.459000e+03               1.0       72.54   \n",
      "1373090              -1  8.476000e+03               1.0       67.00   \n",
      "1373161               1  8.624000e+03               1.0       15.51   \n",
      "...                 ...           ...               ...         ...   \n",
      "3185846               1  7.213655e+17               1.0      105.03   \n",
      "3185885               1  7.213655e+17               1.0       26.38   \n",
      "3185889               1  7.213655e+17               1.0       26.38   \n",
      "3185925               1  7.213655e+17               1.0      144.96   \n",
      "3185985               1  7.213655e+17               1.0       24.05   \n",
      "\n",
      "                    orderSysId  resa          sdd    secid  sequenceNo  \\\n",
      "1372876            5.10089e+07   2.0  135722000.0  1603008  10463942.0   \n",
      "1372988            5.10065e+07   2.0  111933000.0  1603456   4386801.0   \n",
      "1373019            5.10055e+07   2.0  105328000.0  1603583   2334346.0   \n",
      "1373090            5.10085e+07   2.0  134254000.0  1603678   9310481.0   \n",
      "1373161            5.10086e+07   2.0  134530000.0  1603728   9527330.0   \n",
      "...                        ...   ...          ...      ...         ...   \n",
      "3185846  7.213654928407931e+17   2.0   93216690.0  2002568   8205452.0   \n",
      "3185885  7.213654928407931e+17   2.0   93229590.0  2002648   8582197.0   \n",
      "3185889  7.213654928407931e+17   2.0   93230680.0  2002648   8598538.0   \n",
      "3185925  7.213654928407932e+17   2.0   94718840.0  2002791  28116354.0   \n",
      "3185985  7.213654928407931e+17   2.0   93210080.0  2300146   7993595.0   \n",
      "\n",
      "         session  threadId  totalActions  totalCanceled tradeId  tradePrice  \\\n",
      "1372876        2  122924.0         571.0           42.0     NaN        -1.0   \n",
      "1372988        3  114097.0         307.0           20.0     NaN        -1.0   \n",
      "1373019        3  114104.0         213.0           12.0     NaN        -1.0   \n",
      "1373090        2  122930.0         530.0           39.0     NaN        -1.0   \n",
      "1373161        2  122924.0         551.0           41.0     NaN        -1.0   \n",
      "...          ...       ...           ...            ...     ...         ...   \n",
      "3185846        0     354.0          23.0            3.0     NaN        -1.0   \n",
      "3185885        0     354.0          33.0            6.0     NaN        -1.0   \n",
      "3185889        0     354.0          35.0            7.0     NaN        -1.0   \n",
      "3185925        0     347.0          97.0           17.0     NaN        -1.0   \n",
      "3185985        0     352.0           6.0            1.0     NaN        -1.0   \n",
      "\n",
      "         underlyingIndex  updateType         vai  \\\n",
      "1372876              852           1  17760235.0   \n",
      "1372988              852           1   3483663.0   \n",
      "1373019              852           1   1703299.0   \n",
      "1373090              852           1   6317849.0   \n",
      "1373161              852           1   1738888.0   \n",
      "...                  ...         ...         ...   \n",
      "3185846              905           1     89807.0   \n",
      "3185885              905           1    221900.0   \n",
      "3185889              905           1    222000.0   \n",
      "3185925              905           1    229300.0   \n",
      "3185985              905           1   2882959.0   \n",
      "\n",
      "                                   zipFile      colo  caa_orderLog  \\\n",
      "1372876    logs_20201230_zt_88_06_day_8854  zt_88_06           NaN   \n",
      "1372988    logs_20201230_zt_88_06_day_8854  zt_88_06           NaN   \n",
      "1373019    logs_20201230_zt_88_06_day_8854  zt_88_06           NaN   \n",
      "1373090    logs_20201230_zt_88_06_day_8854  zt_88_06           NaN   \n",
      "1373161    logs_20201230_zt_88_06_day_8854  zt_88_06           NaN   \n",
      "...                                    ...       ...           ...   \n",
      "3185846  logs_20210104_zt_96_01_day_966301  zt_96_01           NaN   \n",
      "3185885  logs_20210104_zt_96_01_day_966301  zt_96_01           NaN   \n",
      "3185889  logs_20210104_zt_96_01_day_966301  zt_96_01           NaN   \n",
      "3185925  logs_20210104_zt_96_01_day_966301  zt_96_01           NaN   \n",
      "3185985  logs_20210104_zt_96_01_day_966301  zt_96_01           NaN   \n",
      "\n",
      "         start_time  Price  OrderQty  Side statusLs TradePriceLs TradeQtyLs  \\\n",
      "1372876         NaN    NaN       NaN   NaN      NaN          NaN        NaN   \n",
      "1372988         NaN    NaN       NaN   NaN      NaN          NaN        NaN   \n",
      "1373019         NaN    NaN       NaN   NaN      NaN          NaN        NaN   \n",
      "1373090         NaN    NaN       NaN   NaN      NaN          NaN        NaN   \n",
      "1373161         NaN    NaN       NaN   NaN      NaN          NaN        NaN   \n",
      "...             ...    ...       ...   ...      ...          ...        ...   \n",
      "3185846         NaN    NaN       NaN   NaN      NaN          NaN        NaN   \n",
      "3185885         NaN    NaN       NaN   NaN      NaN          NaN        NaN   \n",
      "3185889         NaN    NaN       NaN   NaN      NaN          NaN        NaN   \n",
      "3185925         NaN    NaN       NaN   NaN      NaN          NaN        NaN   \n",
      "3185985         NaN    NaN       NaN   NaN      NaN          NaN        NaN   \n",
      "\n",
      "          beta_60  adjMid_F30s  adjMid_F90s  adjMid_F300s  indexClose  \\\n",
      "1372876  0.823186    19.564615    19.568571     19.830833   6527.2886   \n",
      "1372988  1.138497    34.924545    35.016154     34.854000   6534.0868   \n",
      "1373019  1.583953    72.606667    72.725000     73.204615   6526.7336   \n",
      "1373090  1.003676    66.483333    66.538750     66.908438   6523.0712   \n",
      "1373161  0.832495    15.549796    15.545113     15.560455   6524.4181   \n",
      "...           ...          ...          ...           ...         ...   \n",
      "3185846  0.405798   105.458824   105.917500    105.505000   6391.4393   \n",
      "3185885  0.653811    26.336667    26.395000     25.999286   6390.1339   \n",
      "3185889  0.653811    26.336667    26.395000     25.999286   6390.1339   \n",
      "3185925  0.861326   144.945000   144.833333    145.330000   6405.5747   \n",
      "3185985  0.400156    24.163182    24.185405     24.091569   6391.1441   \n",
      "\n",
      "         indexClose_F30s  indexClose_F90s  indexClose_F300s    test  broker  \\\n",
      "1372876        6527.3770        6527.7307         6532.0858  342850      88   \n",
      "1372988        6535.3699        6538.0923         6536.0611  342887      88   \n",
      "1373019        6528.0027        6531.0701         6533.7960  342896      88   \n",
      "1373090        6522.6492        6523.4124         6526.4314  342914      88   \n",
      "1373161        6524.2923        6525.1404         6526.1806  342924      88   \n",
      "...                  ...              ...               ...     ...     ...   \n",
      "3185846        6390.4400        6379.3929         6371.2586  782418      96   \n",
      "3185885        6389.4658        6378.2599         6372.1196  782429      96   \n",
      "3185889        6389.4658        6378.2599         6372.1196  782430      96   \n",
      "3185925        6405.8063        6404.6290         6406.3410  782441      96   \n",
      "3185985        6389.3186        6379.6238         6371.3220  782459      96   \n",
      "\n",
      "        colo_broker   order   group        startClock  duration  \\\n",
      "1372876       zt_88  343120  143875  1609307843130266    178790   \n",
      "1372988       zt_88  343155  149777  1609298373762174    417850   \n",
      "1373019       zt_88  343163  150707  1609296809192395    316765   \n",
      "1373090       zt_88  343184  152150  1609306975678489    660371   \n",
      "1373161       zt_88  343207  153268  1609307131162941    770680   \n",
      "...             ...     ...     ...               ...       ...   \n",
      "3185846       zt_96  783323  433195  1609723936630724    871084   \n",
      "3185885       zt_96  783335  436057  1609723949533576    962270   \n",
      "3185889       zt_96  783336  436058  1609723950622199    292461   \n",
      "3185925       zt_96  783347  440108  1609724838773703    795680   \n",
      "3185985       zt_96  783364  452923  1609723930017655    261240   \n",
      "\n",
      "         orderDirection1  directNum  isMsg  status  \n",
      "1372876               -1        1.0    0.0       2  \n",
      "1372988               -1        1.0    0.0       2  \n",
      "1373019                1        1.0    0.0       2  \n",
      "1373090               -1        1.0    0.0       2  \n",
      "1373161                1        1.0    0.0       2  \n",
      "...                  ...        ...    ...     ...  \n",
      "3185846                1        NaN    1.0       2  \n",
      "3185885                1        NaN    1.0       2  \n",
      "3185889                1        NaN    1.0       2  \n",
      "3185925                1        1.0    1.0       2  \n",
      "3185985                1        NaN    1.0       0  \n",
      "\n",
      "[119 rows x 99 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================================\n",
      "11. Orders with size > 80w or notional > 800w\n",
      "date      accCode\n",
      "20201229  9448       1\n",
      "20201230  5289       1\n",
      "          9551       1\n",
      "          527101     1\n",
      "          968501     1\n",
      "20201231  5225       1\n",
      "          5273       1\n",
      "          6237       1\n",
      "          6634       2\n",
      "          8865       1\n",
      "          9435       1\n",
      "          9655       1\n",
      "          522501     1\n",
      "20210104  5470       1\n",
      "          522601     1\n",
      "          529001     1\n",
      "          966701     1\n",
      "20210105  5474       1\n",
      "          6627       1\n",
      "          8886       1\n",
      "          9448       1\n",
      "          522901     1\n",
      "20210106  5230       1\n",
      "          5275       1\n",
      "          5292       1\n",
      "          5386       1\n",
      "20210107  8943       1\n",
      "          9448       1\n",
      "20210108  9758       1\n",
      "          522501     1\n",
      "          527101     1\n",
      "          537403     1\n",
      "          968501     1\n",
      "          975601     1\n",
      "20210111  5292       1\n",
      "          523001     1\n",
      "20210112  5264       1\n",
      "          5332       1\n",
      "          8833       1\n",
      "          8865       1\n",
      "          8970       1\n",
      "          9471       1\n",
      "20210113  5474       1\n",
      "          6623       1\n",
      "          8865       1\n",
      "          9435       1\n",
      "          9685       1\n",
      "          528101     1\n",
      "          528401     1\n",
      "          528703     1\n",
      "          897002     1\n",
      "Name: secid, dtype: int64\n",
      "         Unnamed: 0  ApplSeqNum       aaa  absFilledThisUpdate  absOrderSize  \\\n",
      "8738919         NaN         NaN  0.000657                    0          2900   \n",
      "8751976         NaN         NaN  0.001156                    0           300   \n",
      "8908200         NaN         NaN  0.000365                    0         13000   \n",
      "9052204         NaN         NaN  0.001703                    0          1900   \n",
      "9255591         NaN         NaN  0.002768                    0           100   \n",
      "9324697         NaN         NaN  0.002661                    0           500   \n",
      "9458500         NaN         NaN  0.004079                    0           200   \n",
      "9538240         NaN         NaN  0.000707                    0          3600   \n",
      "9538241         NaN         NaN  0.004467                    0           300   \n",
      "\n",
      "         absOrderSizeCumFilled  accCode  ars             caamd  \\\n",
      "8738919                      0   897002  1.0  1610520672098669   \n",
      "8751976                      0   528703  1.0  1610520948623970   \n",
      "8908200                      0   528101  1.0  1610521003211674   \n",
      "9052204                      0   528401  1.0  1610521015125235   \n",
      "9255591                      0     9435  1.0  1610520966355361   \n",
      "9324697                      0     9685  1.0  1610521003172720   \n",
      "9458500                      0     5474  1.0  1610521002073395   \n",
      "9538240                      0     8865  1.0  1610520998925215   \n",
      "9538241                      0     6623  1.0  1610520928462586   \n",
      "\n",
      "         cancellationPending           cfe                      clock  \\\n",
      "8738919                  0.0  1.270731e+06 2021-01-13 14:51:12.098761   \n",
      "8751976                  0.0  3.637152e+05 2021-01-13 14:55:48.624171   \n",
      "8908200                  0.0  1.807786e+06 2021-01-13 14:56:43.211724   \n",
      "9052204                  0.0  9.375675e+06 2021-01-13 14:56:55.125386   \n",
      "9255591                  0.0  7.377395e+04 2021-01-13 14:56:06.355418   \n",
      "9324697                  0.0  8.252751e+05 2021-01-13 14:56:43.172784   \n",
      "9458500                  0.0  8.309768e+05 2021-01-13 14:56:42.073429   \n",
      "9538240                  0.0  2.171600e+05 2021-01-13 14:56:38.925269   \n",
      "9538241                  0.0  1.544339e+06 2021-01-13 14:55:28.462648   \n",
      "\n",
      "           clockAtArrival  cumSharesBought  cumSharesBuyInserted  \\\n",
      "8738919  1610520672098761              NaN                   NaN   \n",
      "8751976  1610520948624171              NaN                   NaN   \n",
      "8908200  1610521003211724              NaN                   NaN   \n",
      "9052204  1610521015125386              NaN                   NaN   \n",
      "9255591  1610520966355418              NaN                   NaN   \n",
      "9324697  1610521003172784              NaN                   NaN   \n",
      "9458500  1610521002073429              NaN                   NaN   \n",
      "9538240  1610520998925269              NaN                   NaN   \n",
      "9538241  1610520928462648              NaN                   NaN   \n",
      "\n",
      "         cumSharesSellInserted  cumSharesSold      date  finalState  \\\n",
      "8738919                    NaN            NaN  20210113         0.0   \n",
      "8751976                    NaN            NaN  20210113         0.0   \n",
      "8908200                    NaN            NaN  20210113         0.0   \n",
      "9052204                    NaN            NaN  20210113         0.0   \n",
      "9255591                    NaN            NaN  20210113         0.0   \n",
      "9324697                    NaN            NaN  20210113         0.0   \n",
      "9458500                    NaN            NaN  20210113         0.0   \n",
      "9538240                    NaN            NaN  20210113         0.0   \n",
      "9538241                    NaN            NaN  20210113         0.0   \n",
      "\n",
      "                  gfe       hee  insertedShortOrder  insertionPending  \\\n",
      "8738919  1.270731e+06  0.000413                 0.0               1.0   \n",
      "8751976  3.637142e+05  0.000975                 0.0               1.0   \n",
      "8908200  1.807785e+06  0.000329                 0.0               1.0   \n",
      "9052204  9.375674e+06  0.001541                 0.0               1.0   \n",
      "9255591  7.377295e+04  0.002288                 0.0               1.0   \n",
      "9324697  8.252741e+05  0.001965                 0.0               1.0   \n",
      "9458500  8.309758e+05  0.002433                 0.0               1.0   \n",
      "9538240  2.171590e+05 -0.000100                 0.0               1.0   \n",
      "9538241  1.544338e+06  0.000219                 0.0               1.0   \n",
      "\n",
      "         internalId    inv_L   inv_L0  inv_S  inv_S0 l4algoDebug  l4tr  \\\n",
      "8738919       827.0  40100.0  34900.0    0.0     0.0         NaN   NaN   \n",
      "8751976  21001028.0   5600.0   5600.0    0.0     0.0         NaN   NaN   \n",
      "8908200      3460.0  16400.0      0.0    0.0     0.0         NaN   NaN   \n",
      "9052204      3352.0      0.0      0.0    0.0     0.0         NaN   NaN   \n",
      "9255591       347.0   2800.0   2800.0    0.0     0.0         NaN   NaN   \n",
      "9324697      2492.0      0.0      0.0    0.0     0.0         NaN   NaN   \n",
      "9458500      3126.0   3900.0   3900.0    0.0     0.0         NaN   NaN   \n",
      "9538240      2574.0  21100.0  17200.0    0.0     0.0         NaN   NaN   \n",
      "9538241      5552.0  16700.0  12700.0    0.0     0.0         NaN   NaN   \n",
      "\n",
      "         locateShares  locateSharesTotal  mfe  mra100  mrb100       mrm  \\\n",
      "8738919           0.0                0.0  0.0     NaN     NaN -0.000586   \n",
      "8751976           0.0                0.0 -1.0     NaN     NaN  0.000000   \n",
      "8908200           0.0                0.0 -1.0     NaN     NaN       NaN   \n",
      "9052204           0.0                0.0 -1.0     NaN     NaN  0.001566   \n",
      "9255591           0.0                0.0 -1.0     NaN     NaN  0.002500   \n",
      "9324697           0.0                0.0 -1.0     NaN     NaN       NaN   \n",
      "9458500           0.0                0.0 -1.0     NaN     NaN       NaN   \n",
      "9538240           0.0                0.0 -1.0     NaN     NaN       NaN   \n",
      "9538241           0.0                0.0 -1.0     NaN     NaN       NaN   \n",
      "\n",
      "            mrm25  mrmum  mrrlma mrsb300  mrsb90  mrss300  mrss90  mrstaat  \\\n",
      "8738919  0.001186    NaN     NaN     NaN     NaN      NaN     NaN      NaN   \n",
      "8751976       NaN    NaN     NaN     NaN     NaN      NaN     NaN      NaN   \n",
      "8908200       NaN    NaN     NaN     NaN     NaN      NaN     NaN      NaN   \n",
      "9052204  0.001554    0.0     0.0     NaN     NaN      NaN     NaN    300.0   \n",
      "9255591       NaN    NaN     NaN     NaN     NaN      NaN     NaN      NaN   \n",
      "9324697       NaN    NaN     NaN     NaN     NaN      NaN     NaN      NaN   \n",
      "9458500       NaN    NaN     NaN     NaN     NaN      NaN     NaN      NaN   \n",
      "9538240       NaN    NaN     NaN     NaN     NaN      NaN     NaN      NaN   \n",
      "9538241       NaN    NaN     NaN     NaN     NaN      NaN     NaN      NaN   \n",
      "\n",
      "         mrstauc  mrstaum  mrv               ms  mse   mt  ... orderPrice  \\\n",
      "8738919      NaN      NaN  NaN  14:51:12.097919   23  0.0  ...      27.94   \n",
      "8751976      NaN      NaN  NaN  14:55:48.622923   23  0.0  ...      44.28   \n",
      "8908200      NaN      NaN  NaN  14:56:43.211356  100  0.0  ...       7.35   \n",
      "9052204   1000.0      NaN  NaN  14:56:55.124452   23  0.0  ...     121.09   \n",
      "9255591      NaN      NaN  NaN  14:56:06.354924  100  0.0  ...      46.35   \n",
      "9324697      NaN      NaN  NaN  14:56:43.172621  100  0.0  ...      51.30   \n",
      "9458500      NaN      NaN  NaN  14:56:42.072081  100  0.0  ...      23.31   \n",
      "9538240      NaN      NaN  NaN  14:56:38.924417  100  0.0  ...       8.42   \n",
      "9538241      NaN      NaN  NaN  14:55:28.461816  100  0.0  ...       8.45   \n",
      "\n",
      "         orderSysId  resa          sdd    secid   sequenceNo session  \\\n",
      "8738919         NaN   1.0  145107000.0  1600079  154956548.0       0   \n",
      "8751976         NaN   1.0  145545000.0  1600161  205605097.0       0   \n",
      "8908200         NaN   1.0  145643000.0  1601177  206578716.0       0   \n",
      "9052204         NaN   1.0  145648000.0  1603713  206661782.0       0   \n",
      "9255591         NaN   1.0  145605480.0  2002230  282996762.0       0   \n",
      "9324697         NaN   NaN  145643140.0  2002541  282348549.0       0   \n",
      "9458500         NaN   NaN  145632410.0  2300046  195054689.0       0   \n",
      "9538240         NaN   NaN  145638360.0  2300366  310787828.0       0   \n",
      "9538241         NaN   NaN  145528110.0  2300366  285473347.0       0   \n",
      "\n",
      "         threadId  totalActions  totalCanceled  tradeId  tradePrice  \\\n",
      "8738919    2526.0        1047.0          220.0      NaN        -1.0   \n",
      "8751976    1113.0        1029.0          223.0      NaN        -1.0   \n",
      "8908200  286747.0        3461.0          868.0      NaN        -1.0   \n",
      "9052204    3798.0        3353.0          760.0      NaN        -1.0   \n",
      "9255591    5526.0         347.0           19.0      NaN        -1.0   \n",
      "9324697    4478.0        2957.0          465.0      NaN        -1.0   \n",
      "9458500   18950.0        3126.0          582.0      NaN        -1.0   \n",
      "9538240  288701.0        2965.0          391.0      NaN        -1.0   \n",
      "9538241  224468.0        5552.0          764.0      NaN        -1.0   \n",
      "\n",
      "         underlyingIndex  updateType         vai  \\\n",
      "8738919              905           0  30339032.0   \n",
      "8751976              300           0  12771295.0   \n",
      "8908200              852           0   2910701.0   \n",
      "9052204              852           0   1074813.0   \n",
      "9255591              300           0  95749108.0   \n",
      "9324697              852           0  16588961.0   \n",
      "9458500              852           0         0.0   \n",
      "9538240              852           0       107.0   \n",
      "9538241              852           0      1025.0   \n",
      "\n",
      "                                   zipFile      colo  caa_orderLog  \\\n",
      "8738919  logs_20210113_zt_88_03_day_897002  zt_88_03           NaN   \n",
      "8751976  logs_20210113_zt_52_05_day_528703  zt_52_05           NaN   \n",
      "8908200  logs_20210113_zt_52_07_day_528101  zt_52_07           NaN   \n",
      "9052204  logs_20210113_zt_52_04_day_528401  zt_52_04           NaN   \n",
      "9255591    logs_20210113_zs_94_05_day_9435  zs_94_05           NaN   \n",
      "9324697    logs_20210113_zs_96_08_day_9685  zs_96_08           NaN   \n",
      "9458500    logs_20210113_zs_54_01_day_5474  zs_54_01           NaN   \n",
      "9538240    logs_20210113_zs_88_04_day_8865  zs_88_04           NaN   \n",
      "9538241    logs_20210113_zs_66_01_day_6623  zs_66_01           NaN   \n",
      "\n",
      "         start_time  Price OrderQty Side  statusLs  TradePriceLs  TradeQtyLs  \\\n",
      "8738919         NaN    NaN      NaN  NaN       NaN           NaN         NaN   \n",
      "8751976         NaN    NaN      NaN  NaN       NaN           NaN         NaN   \n",
      "8908200         NaN    NaN      NaN  NaN       NaN           NaN         NaN   \n",
      "9052204         NaN    NaN      NaN  NaN       NaN           NaN         NaN   \n",
      "9255591         NaN    NaN      NaN  NaN       NaN           NaN         NaN   \n",
      "9324697         NaN    NaN      NaN  NaN       NaN           NaN         NaN   \n",
      "9458500         NaN    NaN      NaN  NaN       NaN           NaN         NaN   \n",
      "9538240         NaN    NaN      NaN  NaN       NaN           NaN         NaN   \n",
      "9538241         NaN    NaN      NaN  NaN       NaN           NaN         NaN   \n",
      "\n",
      "          beta_60  adjMid_F30s adjMid_F90s adjMid_F300s indexClose  \\\n",
      "8738919  0.925041    27.924902   27.881756    27.838824  6491.5147   \n",
      "8751976  0.266871    44.371160   44.450000    44.501854  5573.2572   \n",
      "8908200  0.648012     7.360000    7.360000     7.348534  6513.8241   \n",
      "9052204  0.824123   121.100000  121.430000   121.715833  6513.8241   \n",
      "9255591  1.098127    46.400451   46.410000    46.391172  5574.1149   \n",
      "9324697  0.412166    51.360000   51.360000    51.369482  6513.8241   \n",
      "9458500  1.332735    24.285000   24.338571    24.391200  6567.4105   \n",
      "9538240  1.430931     8.576296    8.507778     8.442811  6567.4105   \n",
      "9538241  1.430931     8.576296    8.507778     8.442811  6567.4105   \n",
      "\n",
      "         indexClose_F30s  indexClose_F90s  indexClose_F300s     test  broker  \\\n",
      "8738919        6490.2200        6491.2294         6493.4254  2376536      89   \n",
      "8751976        5574.1885        5576.2166         5577.9711  2342063      52   \n",
      "8908200        6514.5730        6514.5730         6513.6399  2351111      52   \n",
      "9052204        6514.5730        6514.5730         6513.6399  2329586      52   \n",
      "9255591        5575.3195        5576.2166         5577.9711  2275413      94   \n",
      "9324697        6514.5730        6514.5730         6513.6399  2302392      96   \n",
      "9458500        6559.9048        6559.3115         6541.2074  2237010      54   \n",
      "9538240        6559.9048        6559.3115         6541.2074  2265997      88   \n",
      "9538241        6559.9048        6559.3115         6541.2074  2245297      66   \n",
      "\n",
      "         colo_broker    order    group        startClock  duration  \\\n",
      "8738919        zt_89  2380176  1368866  1610520672098761         0   \n",
      "8751976        zt_52  2345701  1370702  1610520948624171         0   \n",
      "8908200        zt_52  2354748  1392381  1610521003211724         0   \n",
      "9052204        zt_52  2333222  1414496  1610521015125386         0   \n",
      "9255591        zs_94  2279053  1447070  1610520966355418         0   \n",
      "9324697        zs_96  2306028  1458369  1610521003172784         0   \n",
      "9458500        zs_54  2240167  1480351  1610521002073429         0   \n",
      "9538240        zs_88  2269631  1493714  1610520998925269         0   \n",
      "9538241        zs_66  2248461  1493715  1610520928462648         0   \n",
      "\n",
      "        orderDirection1  directNum  isMsg  status  orderNtl  exchange  \\\n",
      "8738919              -1        1.0    0.0       2   81026.0       SSE   \n",
      "8751976               1        1.0    0.0       2   13284.0       SSE   \n",
      "8908200              -1        1.0    1.0       2   95550.0       SSE   \n",
      "9052204               1        1.0    0.0       2  230071.0       SSE   \n",
      "9255591               1        1.0    1.0       2    4635.0       SZE   \n",
      "9324697               1        1.0    1.0       2   25650.0       SZE   \n",
      "9458500               1        1.0    1.0       2    4662.0       SZE   \n",
      "9538240              -1        1.0    1.0       2   30312.0       SZE   \n",
      "9538241              -1        1.0    1.0       2    2535.0       SZE   \n",
      "\n",
      "         tradeNtl     m1      m2   sta  \n",
      "8738919       0.0    NaN     NaN  else  \n",
      "8751976       0.0    NaN     NaN  else  \n",
      "8908200       0.0    NaN     NaN  else  \n",
      "9052204       0.0  300.0  1000.0  else  \n",
      "9255591       0.0    NaN     NaN  else  \n",
      "9324697       0.0    NaN     NaN  else  \n",
      "9458500       0.0    NaN     NaN  else  \n",
      "9538240       0.0    NaN     NaN  else  \n",
      "9538241       0.0    NaN     NaN  else  \n",
      "\n",
      "[9 rows x 105 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrstaat  mrstauc\n",
      "1000.0   0.0         318887\n",
      "3000.0   1000.0     1114779\n",
      "         2000.0       89593\n",
      "         3000.0       36663\n",
      "11000.0  10000.0      30987\n",
      "         20000.0       2677\n",
      "         30000.0       1691\n",
      "13000.0  11000.0     704626\n",
      "         12000.0      21582\n",
      "         13000.0       3970\n",
      "         21000.0      22466\n",
      "         22000.0      21747\n",
      "         23000.0       3673\n",
      "         31000.0      11243\n",
      "         32000.0       8265\n",
      "         33000.0       9448\n",
      "Name: date, dtype: int64\n",
      "99.29% SZE orders triggered by msg data\n",
      "         date  accCode  secid_x  secid_y      perc\n",
      "96   20201230     8970     1204     1952  0.616803\n",
      "209  20210104     7293      139      220  0.631818\n",
      "263  20210105     7293      126      223  0.565022\n",
      "314  20210106     7293      253      397  0.637280\n",
      "315  20210106     8833      228     1054  0.216319\n",
      "316  20210106     8854       16      584  0.027397\n",
      "320  20210106     8970      116     2146  0.054054\n",
      "335  20210106   897102      316     1833  0.172395\n",
      "543  20210112     6878      287      481  0.596674\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cur_perc</th>\n",
       "      <th>prev_perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSE</th>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SZE</th>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n",
      "Empty DataFrame\n",
      "Columns: [prev_fillRate, cur_fillRate]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:581: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:582: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prev_fillRate</th>\n",
       "      <th>cur_fillRate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <th>sta</th>\n",
       "      <th>colo</th>\n",
       "      <th>accCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:678: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prev_med</th>\n",
       "      <th>cur_med</th>\n",
       "      <th>prev_95p</th>\n",
       "      <th>cur_95p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <th>sta</th>\n",
       "      <th>colo</th>\n",
       "      <th>accCode</th>\n",
       "      <th>isMsg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">SSE</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2. statwo</th>\n",
       "      <th>zs_52_09</th>\n",
       "      <th>5264</th>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>192</td>\n",
       "      <td>770</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs_96_08</th>\n",
       "      <th>974102</th>\n",
       "      <th>1</th>\n",
       "      <td>191</td>\n",
       "      <td>257</td>\n",
       "      <td>1139</td>\n",
       "      <td>1245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">zt_52_05</th>\n",
       "      <th>522901</th>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>138</td>\n",
       "      <td>272</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528701</th>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>137</td>\n",
       "      <td>265</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">zt_88_06</th>\n",
       "      <th>8854</th>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "      <td>204</td>\n",
       "      <td>633</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897102</th>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>171</td>\n",
       "      <td>544</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zt_94_06</th>\n",
       "      <th>9561</th>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>102</td>\n",
       "      <td>157</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">3. sta300</th>\n",
       "      <th>zs_52_09</th>\n",
       "      <th>5264</th>\n",
       "      <th>1</th>\n",
       "      <td>96</td>\n",
       "      <td>123</td>\n",
       "      <td>500</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">zs_96_06</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">9765</th>\n",
       "      <th>0</th>\n",
       "      <td>185</td>\n",
       "      <td>207</td>\n",
       "      <td>589</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>226</td>\n",
       "      <td>284</td>\n",
       "      <td>958</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">zt_52_10</th>\n",
       "      <th>522501</th>\n",
       "      <th>1</th>\n",
       "      <td>117</td>\n",
       "      <td>150</td>\n",
       "      <td>438</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523101</th>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>155</td>\n",
       "      <td>443</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529001</th>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>156</td>\n",
       "      <td>428</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:681: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:770: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prev_med</th>\n",
       "      <th>cur_med</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sta</th>\n",
       "      <th>colo</th>\n",
       "      <th>accCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:773: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are stocks with zero trade size\n",
      "colo      accCode\n",
      "zs_88_04  8924       6\n",
      "zt_88_06  8886       2\n",
      "          8971       1\n",
      "Name: secid, dtype: int64\n",
      "There are stocks with null beta\n",
      "         Unnamed: 0  ApplSeqNum       aaa  absFilledThisUpdate  absOrderSize  \\\n",
      "24029       24058.0         0.0  0.001064                 1000          1700   \n",
      "24034       24062.0         0.0  0.000567                 2400          2400   \n",
      "24037       24064.0         0.0  0.003055                 2000          2000   \n",
      "24040       24066.0         0.0  0.003466                  800           800   \n",
      "51577       51637.0         0.0 -0.000262                  400           400   \n",
      "...             ...         ...       ...                  ...           ...   \n",
      "2341802    879156.0         0.0  0.002240                  100           100   \n",
      "2341805    879035.0         0.0  0.001978                  400           400   \n",
      "2341808    879037.0         0.0  0.003710                  300           300   \n",
      "2341819    879039.0         0.0  0.003615                  900          1200   \n",
      "2341840    879191.0         0.0  0.001952                  300           300   \n",
      "\n",
      "         absOrderSizeCumFilled  accCode  ars             caamd  \\\n",
      "24029                     1000     9248  1.0  1609219385093123   \n",
      "24034                     2400     9248  1.0  1609219515574425   \n",
      "24037                     2000     9248  1.0  1609224367498526   \n",
      "24040                      800     9248  1.0  1609224370496600   \n",
      "51577                      400     9248  1.0  1609207099347271   \n",
      "...                        ...      ...  ...               ...   \n",
      "2341802                    100     5470  1.0  1609391805694128   \n",
      "2341805                    400     5225  1.0  1609395070675744   \n",
      "2341808                    300     5225  1.0  1609396275355390   \n",
      "2341819                    900     5225  1.0  1609397546247104   \n",
      "2341840                    300     6631  1.0  1609397547081765   \n",
      "\n",
      "         cancellationPending           cfe                      clock  \\\n",
      "24029                    0.0  2.294351e+05 2020-12-29 13:23:05.525180   \n",
      "24034                    0.0  2.366401e+05 2020-12-29 13:25:15.940087   \n",
      "24037                    0.0  8.084177e+04 2020-12-29 14:46:07.900158   \n",
      "24040                    0.0  7.859377e+04 2020-12-29 14:46:10.895935   \n",
      "51577                    0.0  3.641548e+05 2020-12-29 09:58:19.878375   \n",
      "...                      ...           ...                        ...   \n",
      "2341802                  0.0  1.141863e+06 2020-12-31 13:16:45.696688   \n",
      "2341805                  0.0  7.504252e+06 2020-12-31 14:11:10.679564   \n",
      "2341808                  0.0  6.457848e+06 2020-12-31 14:31:15.359361   \n",
      "2341819                  0.0  4.242813e+06 2020-12-31 14:52:26.250113   \n",
      "2341840                  0.0  1.267015e+06 2020-12-31 14:52:27.084646   \n",
      "\n",
      "           clockAtArrival  cumSharesBought  cumSharesBuyInserted  \\\n",
      "24029    1609219385525180              0.0                   0.0   \n",
      "24034    1609219515940087              0.0                   0.0   \n",
      "24037    1609224367900158           2000.0                2000.0   \n",
      "24040    1609224370895935           2800.0                2800.0   \n",
      "51577    1609207099878375              0.0                   0.0   \n",
      "...                   ...              ...                   ...   \n",
      "2341802  1609391805696688            700.0                 700.0   \n",
      "2341805  1609395070679564           1400.0                1800.0   \n",
      "2341808  1609396275359361           1700.0                2100.0   \n",
      "2341819  1609397546250113           2600.0                3300.0   \n",
      "2341840  1609397547084646           1200.0                1400.0   \n",
      "\n",
      "         cumSharesSellInserted  cumSharesSold      date  finalState  \\\n",
      "24029                   1700.0         1000.0  20201229         0.0   \n",
      "24034                   4100.0         3400.0  20201229         1.0   \n",
      "24037                   4100.0         3400.0  20201229         1.0   \n",
      "24040                   4100.0         3400.0  20201229         1.0   \n",
      "51577                    400.0          400.0  20201229         1.0   \n",
      "...                        ...            ...       ...         ...   \n",
      "2341802                    0.0            0.0  20201231         1.0   \n",
      "2341805                 3100.0         3100.0  20201231         1.0   \n",
      "2341808                 3100.0         3100.0  20201231         1.0   \n",
      "2341819                 3100.0         3100.0  20201231         0.0   \n",
      "2341840                    0.0            0.0  20201231         1.0   \n",
      "\n",
      "                  gfe  hee  insertedShortOrder  insertionPending  internalId  \\\n",
      "24029    2.294341e+05 -1.0                 0.0               0.0       589.0   \n",
      "24034    2.366391e+05 -1.0                 0.0               0.0       593.0   \n",
      "24037    8.084077e+04 -1.0                 0.0               0.0       918.0   \n",
      "24040    7.859277e+04 -1.0                 0.0               0.0       919.0   \n",
      "51577    3.641538e+05 -1.0                 0.0               0.0        95.0   \n",
      "...               ...  ...                 ...               ...         ...   \n",
      "2341802  1.141862e+06 -1.0                 0.0               0.0      2220.0   \n",
      "2341805  7.504251e+06 -1.0                 0.0               0.0      4032.0   \n",
      "2341808  6.457847e+06 -1.0                 0.0               0.0      4284.0   \n",
      "2341819  4.242812e+06 -1.0                 0.0               0.0      4561.0   \n",
      "2341840  1.267014e+06 -1.0                 0.0               0.0      3465.0   \n",
      "\n",
      "          inv_L  inv_L0  inv_S  inv_S0 l4algoDebug  l4tr  locateShares  \\\n",
      "24029    2400.0     0.0    0.0     0.0         NaN   0.0           0.0   \n",
      "24034       0.0     0.0    0.0     0.0         NaN   0.0           0.0   \n",
      "24037    2000.0  2000.0    0.0     0.0         NaN   0.0           0.0   \n",
      "24040    2800.0  2800.0    0.0     0.0         NaN   0.0           0.0   \n",
      "51577       0.0     0.0    0.0     0.0         NaN   0.0           0.0   \n",
      "...         ...     ...    ...     ...         ...   ...           ...   \n",
      "2341802   700.0   700.0    0.0     0.0         NaN   0.0           0.0   \n",
      "2341805  1400.0  1400.0    0.0     0.0         NaN   0.0           0.0   \n",
      "2341808  1700.0  1700.0    0.0     0.0         NaN   0.0           0.0   \n",
      "2341819  2600.0  2600.0    0.0     0.0         NaN   0.0           0.0   \n",
      "2341840  1200.0  1200.0    0.0     0.0         NaN   0.0           0.0   \n",
      "\n",
      "         locateSharesTotal  mfe  mra100  mrb100       mrm     mrm25  mrmum  \\\n",
      "24029                  0.0 -1.0   286.0   285.0 -0.002385         0    0.0   \n",
      "24034                  0.0 -1.0   286.0   285.0 -0.002371         0    0.0   \n",
      "24037                  0.0 -1.0   281.0   280.0  0.000000         0    0.0   \n",
      "24040                  0.0 -1.0   281.0   280.0  0.000000         0    0.0   \n",
      "51577                  0.0 -1.0   282.0   281.0 -0.005053         0    0.0   \n",
      "...                    ...  ...     ...     ...       ...       ...    ...   \n",
      "2341802                0.0 -1.0  6050.0  6047.0  0.000816  0.001397    1.0   \n",
      "2341805                0.0 -1.0  6018.0  6017.0 -0.000092  -5.4e-05    0.0   \n",
      "2341808                0.0 -1.0  6039.0  6021.0  0.000372  -5.5e-05    0.0   \n",
      "2341819                0.0 -1.0  6057.0  6030.0  0.001273   0.00141    0.0   \n",
      "2341840                0.0 -1.0  6030.0  6024.0  0.001583   0.00141    1.0   \n",
      "\n",
      "         mrrlma   mrsb300    mrsb90   mrss300    mrss90  mrstaat  mrstauc  \\\n",
      "24029       0.0        -1 -0.004452 -1.000000  0.001064   1000.0      0.0   \n",
      "24034       0.0        -1 -0.003943 -1.000000  0.000567   1000.0      0.0   \n",
      "24037       0.0        -1  0.003055 -1.000000 -0.006469   1000.0      0.0   \n",
      "24040       0.0        -1  0.003466 -1.000000 -0.006958   1000.0      0.0   \n",
      "51577       0.0        -1 -0.003391 -1.000000 -0.000262   1000.0      0.0   \n",
      "...         ...       ...       ...       ...       ...      ...      ...   \n",
      "2341802     0.0        -1  0.002240 -1.000000 -0.002725   1000.0      0.0   \n",
      "2341805     0.0        -1 -0.001924 -1.000000  0.001825  13000.0  11000.0   \n",
      "2341808     0.0 -0.000649  0.001633 -0.002333 -0.001736  13000.0  11000.0   \n",
      "2341819     0.0  -0.00178  0.001953 -0.002683 -0.002821  13000.0  11000.0   \n",
      "2341840     0.0        -1  0.001952 -1.000000 -0.002820   3000.0   1000.0   \n",
      "\n",
      "         mrstaum         mrv               ms  mse   mt  ... resa  \\\n",
      "24029        0.0  10122161.0  13:23:05.523540    0 -1.0  ...  1.0   \n",
      "24034        0.0  10128061.0  13:25:15.938543    0 -1.0  ...  1.0   \n",
      "24037        0.0  15259801.0  14:46:07.898653    0 -1.0  ...  1.0   \n",
      "24040        0.0  15278901.0  14:46:10.894653    0 -1.0  ...  1.0   \n",
      "51577        0.0  26252085.0  09:58:19.877263    0 -1.0  ...  1.0   \n",
      "...          ...         ...              ...  ...  ...  ...  ...   \n",
      "2341802      0.0    754724.0  13:16:45.695838    0 -1.0  ...  1.0   \n",
      "2341805      1.0    893924.0  14:11:10.678315    0 -1.0  ...  1.0   \n",
      "2341808      1.0   1010575.0  14:31:15.358359    0 -1.0  ...  1.0   \n",
      "2341819      1.0   1127375.0  14:52:26.249404    0 -1.0  ...  1.0   \n",
      "2341840      0.0   1126475.0  14:52:27.083502    0 -1.0  ...  1.0   \n",
      "\n",
      "                 sdd    secid   sequenceNo  session  threadId totalActions  \\\n",
      "24029    132308000.0  1600186  103386762.0        0   54748.0        588.0   \n",
      "24034    132518000.0  1600186  104251853.0        0   54748.0        592.0   \n",
      "24037    144607000.0  1600186  141292981.0        0   54748.0        917.0   \n",
      "24040    144613000.0  1600186  141317959.0        0   54748.0        918.0   \n",
      "51577     95821000.0  1600396   39595692.0        0   54748.0         94.0   \n",
      "...              ...      ...          ...      ...       ...          ...   \n",
      "2341802  131635160.0  2300858  113316289.0        0   19973.0       2220.0   \n",
      "2341805  141111540.0  2300858  202789791.0        0  185910.0       4033.0   \n",
      "2341808  143116220.0  2300858  218537351.0        0  185910.0       4285.0   \n",
      "2341819  145227120.0  2300858  238848266.0        0  185910.0       4562.0   \n",
      "2341840  145227120.0  2300858  244192986.0        0  409869.0       3465.0   \n",
      "\n",
      "         totalCanceled     tradeId  tradePrice  underlyingIndex  updateType  \\\n",
      "24029             95.0  18314741.0        2.85              852           4   \n",
      "24034             96.0  18453097.0        2.85              852           4   \n",
      "24037            157.0  25064882.0        2.81              852           4   \n",
      "24040            157.0  25069284.0        2.81              852           4   \n",
      "51577              9.0   7348170.0        2.81              852           4   \n",
      "...                ...         ...         ...              ...         ...   \n",
      "2341802          322.0    1.04e+14       60.50              852           4   \n",
      "2341805          764.0    1.04e+14       60.17              852           4   \n",
      "2341808          838.0    1.04e+14       60.21              852           4   \n",
      "2341819          920.0    1.04e+14       60.30              852           4   \n",
      "2341840          198.0    1.04e+14       60.30              852           4   \n",
      "\n",
      "                vai                          zipFile      colo caa_orderLog  \\\n",
      "24029    10121461.0  logs_20201229_zt_92_01_day_9248  zt_92_01          NaN   \n",
      "24034    10125361.0  logs_20201229_zt_92_01_day_9248  zt_92_01          NaN   \n",
      "24037    15256601.0  logs_20201229_zt_92_01_day_9248  zt_92_01          NaN   \n",
      "24040    15278901.0  logs_20201229_zt_92_01_day_9248  zt_92_01          NaN   \n",
      "51577    26249485.0  logs_20201229_zt_92_01_day_9248  zt_92_01          NaN   \n",
      "...             ...                              ...       ...          ...   \n",
      "2341802    754724.0  logs_20201231_zs_54_01_day_5470  zs_54_01          NaN   \n",
      "2341805    893524.0  logs_20201231_zs_52_09_day_5225  zs_52_09          NaN   \n",
      "2341808   1010275.0  logs_20201231_zs_52_09_day_5225  zs_52_09          NaN   \n",
      "2341819   1126175.0  logs_20201231_zs_52_09_day_5225  zs_52_09          NaN   \n",
      "2341840   1126175.0  logs_20201231_zs_66_01_day_6631  zs_66_01          NaN   \n",
      "\n",
      "         start_time  Price  OrderQty  Side statusLs TradePriceLs  TradeQtyLs  \\\n",
      "24029           NaN    NaN       NaN   NaN      NaN          NaN         NaN   \n",
      "24034           NaN    NaN       NaN   NaN      NaN          NaN         NaN   \n",
      "24037           NaN    NaN       NaN   NaN      NaN          NaN         NaN   \n",
      "24040           NaN    NaN       NaN   NaN      NaN          NaN         NaN   \n",
      "51577           NaN    NaN       NaN   NaN      NaN          NaN         NaN   \n",
      "...             ...    ...       ...   ...      ...          ...         ...   \n",
      "2341802         NaN    NaN       NaN   NaN      NaN          NaN         NaN   \n",
      "2341805         NaN    NaN       NaN   NaN      NaN          NaN         NaN   \n",
      "2341808         NaN    NaN       NaN   NaN      NaN          NaN         NaN   \n",
      "2341819         NaN    NaN       NaN   NaN      NaN          NaN         NaN   \n",
      "2341840         NaN    NaN       NaN   NaN      NaN          NaN         NaN   \n",
      "\n",
      "         beta_60  adjMid_F30s  adjMid_F90s  adjMid_F300s indexClose  \\\n",
      "24029        NaN          NaN          NaN           NaN        NaN   \n",
      "24034        NaN          NaN          NaN           NaN        NaN   \n",
      "24037        NaN          NaN          NaN           NaN        NaN   \n",
      "24040        NaN          NaN          NaN           NaN        NaN   \n",
      "51577        NaN          NaN          NaN           NaN        NaN   \n",
      "...          ...          ...          ...           ...        ...   \n",
      "2341802      NaN          NaN          NaN           NaN        NaN   \n",
      "2341805      NaN          NaN          NaN           NaN        NaN   \n",
      "2341808      NaN          NaN          NaN           NaN        NaN   \n",
      "2341819      NaN          NaN          NaN           NaN        NaN   \n",
      "2341840      NaN          NaN          NaN           NaN        NaN   \n",
      "\n",
      "        indexClose_F30s indexClose_F90s  indexClose_F300s    test  broker  \\\n",
      "24029               NaN             NaN               NaN  186892      92   \n",
      "24034               NaN             NaN               NaN  186893      92   \n",
      "24037               NaN             NaN               NaN  186895      92   \n",
      "24040               NaN             NaN               NaN  186894      92   \n",
      "51577               NaN             NaN               NaN  187008      92   \n",
      "...                 ...             ...               ...     ...     ...   \n",
      "2341802             NaN             NaN               NaN  434953      54   \n",
      "2341805             NaN             NaN               NaN  409672      52   \n",
      "2341808             NaN             NaN               NaN  409679      52   \n",
      "2341819             NaN             NaN               NaN  409681      52   \n",
      "2341840             NaN             NaN               NaN  449055      66   \n",
      "\n",
      "         colo_broker   order   group        startClock  duration  \\\n",
      "24029          zt_92  186930    3213  1609219385093180    432000   \n",
      "24034          zt_92  186931    3214  1609219515574494    365593   \n",
      "24037          zt_92  186932    3215  1609224367498567    401591   \n",
      "24040          zt_92  186933    3216  1609224370496633    399302   \n",
      "51577          zt_92  187046    7053  1609207099347309    531066   \n",
      "...              ...     ...     ...               ...       ...   \n",
      "2341802        zs_54  435224  357589  1609391805694165      2523   \n",
      "2341805        zs_52  409949  357590  1609395070675812      3752   \n",
      "2341808        zs_52  409950  357591  1609396275355453      3908   \n",
      "2341819        zs_52  409951  357592  1609397546247179      2934   \n",
      "2341840        zs_66  449326  357592  1609397547081825      2821   \n",
      "\n",
      "         orderDirection1  directNum isMsg  status  orderNtl  exchange  \\\n",
      "24029                 -1        1.0   0.0       1    4845.0       SSE   \n",
      "24034                 -1        1.0   0.0       0    6840.0       SSE   \n",
      "24037                  1        1.0   1.0       0    5620.0       SSE   \n",
      "24040                  1        1.0   1.0       0    2248.0       SSE   \n",
      "51577                 -1        1.0   1.0       0    1124.0       SSE   \n",
      "...                  ...        ...   ...     ...       ...       ...   \n",
      "2341802                1        1.0   1.0       0    6050.0       SZE   \n",
      "2341805               -1        1.0   1.0       0   24068.0       SZE   \n",
      "2341808                1        1.0   1.0       0   18063.0       SZE   \n",
      "2341819                1        1.0   1.0       1   72360.0       SZE   \n",
      "2341840                1        1.0   1.0       0   18090.0       SZE   \n",
      "\n",
      "         tradeNtl      m1      m2        sta       tag  num  \n",
      "24029      2850.0  1000.0     0.0  1. staone  previous    1  \n",
      "24034      6840.0  1000.0     0.0  1. staone  previous    1  \n",
      "24037      5620.0  1000.0     0.0  1. staone  previous    1  \n",
      "24040      2248.0  1000.0     0.0  1. staone  previous    1  \n",
      "51577      1124.0  1000.0     0.0  1. staone  previous    2  \n",
      "...           ...     ...     ...        ...       ...  ...  \n",
      "2341802    6050.0  1000.0     0.0  1. staone  previous    2  \n",
      "2341805   24068.0  3000.0  1000.0  3. sta300  previous    2  \n",
      "2341808   18063.0  3000.0  1000.0  3. sta300  previous    2  \n",
      "2341819   54270.0  3000.0  1000.0  3. sta300  previous    2  \n",
      "2341840   18090.0  3000.0  1000.0  2. statwo  previous    2  \n",
      "\n",
      "[14438 rows x 107 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:814: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:815: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:816: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:818: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:820: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:821: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:824: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:825: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:827: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:828: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:829: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:830: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:835: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:837: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sellOrderNum</th>\n",
       "      <th>sellRet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <th>date</th>\n",
       "      <th>sta</th>\n",
       "      <th>server_account</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SSE</th>\n",
       "      <th>20201231</th>\n",
       "      <th>2. statwo</th>\n",
       "      <th>zt8806_8854</th>\n",
       "      <td>131</td>\n",
       "      <td>-40.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210112</th>\n",
       "      <th>1. staone</th>\n",
       "      <th>zt5205_527601</th>\n",
       "      <td>148</td>\n",
       "      <td>-26.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210113</th>\n",
       "      <th>2. statwo</th>\n",
       "      <th>zt5212_537301</th>\n",
       "      <td>251</td>\n",
       "      <td>-27.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"25\" valign=\"top\">SZE</th>\n",
       "      <th>20201229</th>\n",
       "      <th>1. staone</th>\n",
       "      <th>zs9608_9741</th>\n",
       "      <td>126</td>\n",
       "      <td>-26.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">20201230</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1. staone</th>\n",
       "      <th>zs5209_5291</th>\n",
       "      <td>237</td>\n",
       "      <td>-34.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zt8806_897102</th>\n",
       "      <td>131</td>\n",
       "      <td>-43.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. statwo</th>\n",
       "      <th>zs9606_9765</th>\n",
       "      <td>139</td>\n",
       "      <td>-34.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201231</th>\n",
       "      <th>1. staone</th>\n",
       "      <th>zs5209_5291</th>\n",
       "      <td>202</td>\n",
       "      <td>-44.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">20210104</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1. staone</th>\n",
       "      <th>zs5209_5291</th>\n",
       "      <td>239</td>\n",
       "      <td>-22.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs9608_9741</th>\n",
       "      <td>242</td>\n",
       "      <td>-42.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">20210105</th>\n",
       "      <th>1. staone</th>\n",
       "      <th>zs5208_5281</th>\n",
       "      <td>217</td>\n",
       "      <td>-25.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2. statwo</th>\n",
       "      <th>zs5209_5264</th>\n",
       "      <td>135</td>\n",
       "      <td>-32.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs9606_9765</th>\n",
       "      <td>162</td>\n",
       "      <td>-35.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210106</th>\n",
       "      <th>1. staone</th>\n",
       "      <th>zs5206_5332</th>\n",
       "      <td>123</td>\n",
       "      <td>-32.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">20210111</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1. staone</th>\n",
       "      <th>zs9608_9741</th>\n",
       "      <td>168</td>\n",
       "      <td>-40.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zt8806_8970</th>\n",
       "      <td>170</td>\n",
       "      <td>-24.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">20210112</th>\n",
       "      <th rowspan=\"9\" valign=\"top\">1. staone</th>\n",
       "      <th>zs5206_5275</th>\n",
       "      <td>775</td>\n",
       "      <td>-20.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs5206_5384</th>\n",
       "      <td>156</td>\n",
       "      <td>-47.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs5209_5291</th>\n",
       "      <td>304</td>\n",
       "      <td>-46.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs5213_5329</th>\n",
       "      <td>123</td>\n",
       "      <td>-29.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs6601_6631</th>\n",
       "      <td>287</td>\n",
       "      <td>-38.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs8804_8924</th>\n",
       "      <td>234</td>\n",
       "      <td>-55.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs9606_9758</th>\n",
       "      <td>370</td>\n",
       "      <td>-39.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs9608_9754</th>\n",
       "      <td>127</td>\n",
       "      <td>-28.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zt8803_8833</th>\n",
       "      <td>194</td>\n",
       "      <td>-35.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">20210113</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">2. statwo</th>\n",
       "      <th>zs5209_5264</th>\n",
       "      <td>133</td>\n",
       "      <td>-26.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs8804_8924</th>\n",
       "      <td>458</td>\n",
       "      <td>-31.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs9606_9765</th>\n",
       "      <td>128</td>\n",
       "      <td>-45.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>buyOrderNum</th>\n",
       "      <th>buyRet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <th>date</th>\n",
       "      <th>sta</th>\n",
       "      <th>server_account</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSE</th>\n",
       "      <th>20210108</th>\n",
       "      <th>1. staone</th>\n",
       "      <th>zt5205_527601</th>\n",
       "      <td>264</td>\n",
       "      <td>-33.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">SZE</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">20201229</th>\n",
       "      <th>1. staone</th>\n",
       "      <th>zs5206_5275</th>\n",
       "      <td>127</td>\n",
       "      <td>-44.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. statwo</th>\n",
       "      <th>zs5206_5384</th>\n",
       "      <td>148</td>\n",
       "      <td>-23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210111</th>\n",
       "      <th>1. staone</th>\n",
       "      <th>zs5208_5281</th>\n",
       "      <td>115</td>\n",
       "      <td>-47.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210112</th>\n",
       "      <th>2. statwo</th>\n",
       "      <th>zs8804_8924</th>\n",
       "      <td>195</td>\n",
       "      <td>-40.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smtp server connected\n",
      "login\n",
      "send mail\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "pd.set_option('max_rows', 100)\n",
    "pd.set_option('max_columns', 100)\n",
    "\n",
    "perc = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "\n",
    "def generate_report(dd):\n",
    "    \n",
    "    import numpy as np\n",
    "    import os\n",
    "    import glob\n",
    "    import datetime\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    import pickle\n",
    "\n",
    "    \n",
    "    print('start')\n",
    "    readPath = '/mnt/orderLog/data/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    path = np.sort(dataPathLs)[-11:]\n",
    "    cur = np.max([int(os.path.basename(i).split('.')[0]) for i in path])\n",
    "    assert(cur == int(dd))\n",
    "\n",
    "\n",
    "    body = \"<html><body><div>\" + 'Hi all,<p>The following is daily report based on ' + str(cur) + ' data.</p>'\n",
    "    body += '<p><b>I. Assertions</p></b>'\n",
    "    count = 0\n",
    "\n",
    "    # load data\n",
    "    print('-----------------------------------------------------------------------------------------------')\n",
    "    print('load data')\n",
    "    rawOrderLog = []\n",
    "    for thisPath in path:\n",
    "        print(thisPath)\n",
    "        data = pickle.load(open(thisPath, 'rb'))\n",
    "        data = data.rename(columns={'mdClockAtArrival': 'caamd'})\n",
    "        rawOrderLog += [data]\n",
    "    rawOrderLog = pd.concat(rawOrderLog, sort=False)\n",
    "\n",
    "    for col in ['clockAtArrival', 'caamd', 'secid', 'updateType', 'vai', 'absFilledThisUpdate', 'orderDirection', 'absOrderSize',\n",
    "                'absOrderSizeCumFilled', 'date', 'accCode', 'mse']:\n",
    "        rawOrderLog[col] = rawOrderLog[col].fillna(0).astype('int64')   \n",
    "    rawOrderLog = rawOrderLog.sort_values(by=['date', 'secid', 'vai', 'accCode', 'clockAtArrival']).reset_index(drop=True)\n",
    "\n",
    "    rawOrderLog = rawOrderLog[rawOrderLog[\"secid\"] >= 1000000]\n",
    "\n",
    "    if rawOrderLog[rawOrderLog.duplicated(['date', 'secid', 'vai', 'accCode', 'clockAtArrival', 'updateType', \\\n",
    "                                        'orderDirection', 'absOrderSize'], keep=False)].shape[0] != 0:\n",
    "        print('There are accounts with duplicated ticks:')\n",
    "        print(rawOrderLog[rawOrderLog.duplicated(['date', 'secid', 'vai', 'accCode', 'clockAtArrival', 'updateType', \\\n",
    "                                        'orderDirection', 'absOrderSize'], keep=False)]\\\n",
    "    .groupby(['date', 'colo', 'accCode'])['ars'].size())\n",
    "        rawOrderLog = rawOrderLog.drop_duplicates(['date', 'secid', 'vai', 'accCode', 'clockAtArrival', 'updateType', \\\n",
    "                                        'orderDirection', 'absOrderSize'], keep='first')\n",
    "    \n",
    "    \n",
    "    print('There are ticks with orderDirection 0')\n",
    "    print(rawOrderLog[rawOrderLog['orderDirection'] == 0][['date', 'colo', 'accCode', \\\n",
    "                'secid', 'vai', 'updateType', 'sdd', 'orderDirection', 'absOrderSize', 'internalId', 'orderId']])\n",
    "    try:\n",
    "        num1 = rawOrderLog[(rawOrderLog['orderDirection'] == 0) & (rawOrderLog['date'] == cur)].shape[0]\n",
    "        assert(num1 < 30)\n",
    "    except:\n",
    "        count += 1\n",
    "        body += str(count) + '. There are in total ' + str(num1) + ' orders with orderDirection 0.<div>'\n",
    "\n",
    "\n",
    "    assert(rawOrderLog[rawOrderLog['updateType'] == 0][rawOrderLog[rawOrderLog['updateType'] == 0]\\\n",
    "                                                       .duplicated(['date', 'colo', 'accCode', 'secid', 'orderDirection',\n",
    "                                                                    'vai', 'absOrderSize', 'internalId'], keep=False)].shape[0] == 0)\n",
    "    try:\n",
    "        assert(rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)][rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)]\\\n",
    "                                                           .duplicated(['date', 'colo', 'accCode', 'secid', 'orderDirection',\n",
    "                                                                        'absOrderSize', 'internalId'], keep=False)].shape[0] == 0)\n",
    "    except:\n",
    "        print('There are orders with all things same except sdd')\n",
    "        print(rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)][rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)]\\\n",
    "                                                           .duplicated(['date', 'colo', 'accCode', 'secid', 'orderDirection',\n",
    "                                                                        'absOrderSize', 'internalId'], keep=False)])\n",
    "        assert(rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)][rawOrderLog[(rawOrderLog['updateType'] == 0) & (rawOrderLog['accCode'] != 8856)]\\\n",
    "                                                           .duplicated(['date', 'colo', 'accCode', 'secid', 'orderDirection',\n",
    "                                                                        'absOrderSize', 'internalId', 'sdd'], keep=False)].shape[0] == 0)\n",
    "    try:\n",
    "        assert(sum(rawOrderLog[(rawOrderLog['updateType'] != 0) & (rawOrderLog['accCode'] != 8856)].groupby(['date', 'colo', 'accCode', 'secid', \n",
    "                    'orderDirection', 'absOrderSize', 'internalId'])['orderId'].nunique() != 1) == 0) \n",
    "    except:\n",
    "        print('There are orders with same internalId but different orderId other than accCode 8856 case')\n",
    "        print(rawOrderLog[(rawOrderLog['updateType'] != 0) & (rawOrderLog['accCode'] != 8856)].groupby(['date', 'colo', 'accCode', 'secid', \n",
    "                    'orderDirection', 'absOrderSize', 'internalId'])['orderId'].nunique()[rawOrderLog[(rawOrderLog['updateType'] != 0) & (rawOrderLog['accCode'] != 8856)].groupby(['date', 'colo', 'accCode', 'secid', \n",
    "                    'orderDirection', 'absOrderSize', 'internalId'])['orderId'].nunique() > 1])\n",
    "\n",
    "    r2 = rawOrderLog[(rawOrderLog['accCode'] != 8856) & (rawOrderLog['orderDirection'] != 0)]\n",
    "    r1 = rawOrderLog[(rawOrderLog['accCode'] == 8856) & (rawOrderLog['orderDirection'] != 0)]\n",
    "    r1['test'] = r1.groupby(['date', 'colo', 'accCode', 'secid', \n",
    "                'orderDirection', 'absOrderSize']).grouper.group_info[0]\n",
    "    r1 = r1.sort_values(by=['test', 'clockAtArrival'])\n",
    "    r1.loc[r1['updateType'] != 0, 'vai'] = np.nan\n",
    "    r1['vai'] = r1.groupby('test')['vai'].ffill()\n",
    "    r2['test'] = r2.groupby(['date', 'colo', 'accCode', 'secid', \n",
    "                'orderDirection', 'absOrderSize', 'internalId']).grouper.group_info[0]\n",
    "    r2 = r2.sort_values(by=['test', 'clockAtArrival'])\n",
    "    r2.loc[r2['updateType'] != 0, 'vai'] = np.nan\n",
    "    r2['vai'] = r2.groupby('test')['vai'].ffill()\n",
    "    try:\n",
    "        assert(sum(r1[r1['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique() != 1) == 0)\n",
    "    except:\n",
    "        a = r1[r1['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique()[r1[r1['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique() != 1].reset_index()\n",
    "        print('There are orders in 8856 with same internalId and various orderId!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        print(pd.merge(r1, a[['test', 'vai']], on=['test', 'vai'], how='inner')[['secid', 'accCode', 'colo', 'vai', 'updateType', 'sdd', 'internalId', 'orderId', 'absOrderSize', 'absFilledThisUpdate', 'absOrderSizeCumFilled', 'orderPrice', 'tradePrice']])\n",
    "    \n",
    "    try:\n",
    "        assert(sum(r2[r2['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique() != 1) == 0)\n",
    "    except:\n",
    "        a = r2[r2['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique()[r2[r2['updateType'] != 0].groupby(['test', 'vai'])['orderId'].nunique() != 1].reset_index()\n",
    "        print('There are orders out of 8856 with same internalId and various orderId!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        print(pd.merge(r2, a[['test', 'vai']], on=['test', 'vai'], how='inner')[['secid', 'accCode', 'colo', 'vai', 'updateType', 'sdd', 'internalId', 'orderId', 'absOrderSize', 'absFilledThisUpdate', 'absOrderSizeCumFilled', 'orderPrice', 'tradePrice']])\n",
    "    orderLog = pd.concat([r1, r2])\n",
    "    del r1\n",
    "    del r2    \n",
    "\n",
    "    orderLog = orderLog.sort_values(by=['date', 'colo', 'accCode', 'secid', 'vai', 'clockAtArrival']).reset_index(drop=True)\n",
    "    orderLog['clock'] = orderLog['clockAtArrival'].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    orderLog[\"broker\"] = np.where(orderLog[\"accCode\"].astype(str).apply(lambda x: len(x) == 6), orderLog['accCode'] // 10000, orderLog['accCode'] // 100)\n",
    "    orderLog['colo_broker'] = orderLog['colo'].str[:2] + '_' + orderLog['broker'].astype('str')\n",
    "    orderLog['order'] = orderLog.groupby(['date', 'colo', 'accCode', 'secid', 'vai', 'orderDirection', 'absOrderSize', 'internalId']).grouper.group_info[0]\n",
    "    orderLog['group'] = orderLog.groupby(['date', 'secid', 'vai']).grouper.group_info[0]\n",
    "    orderLog['startClock'] = orderLog.groupby(['order'])['clockAtArrival'].transform('first')\n",
    "    orderLog['duration'] = orderLog['clockAtArrival'] - orderLog['startClock']\n",
    "    orderLog['orderPrice'] = orderLog['orderPrice'].apply(lambda x: round(x, 2))\n",
    "    orderLog['tradePrice'] = orderLog['tradePrice'].apply(lambda x: round(x, 2))\n",
    "    orderLog['orderDirection1'] = np.where(orderLog[\"orderDirection\"] == -2, -1, np.where(\n",
    "        orderLog[\"orderDirection\"] == 2, 1, orderLog[\"orderDirection\"]))\n",
    "    orderLog[\"ars\"] = orderLog.groupby(['order'])['ars'].transform('first')\n",
    "    orderLog['sdd'] = orderLog.groupby('order')['sdd'].transform('first')\n",
    "    orderLog['caamd'] = orderLog.groupby('order')['caamd'].transform('first')\n",
    "\n",
    "\n",
    "    ### Assertion 1:  make sure same direction in same date, secid, vai\n",
    "    print('=======================================================================================')\n",
    "    print('1. same date, secid, vai: same direction')\n",
    "    taking = orderLog[orderLog['ars'].isin([1, 7])]\n",
    "    making = orderLog[orderLog['ars'].isin([2, 3])]\n",
    "    else_orders = orderLog[~(orderLog['ars'].isin([1, 2, 3, 7]))]\n",
    "    if else_orders.shape[0] != 0:\n",
    "        print('orders with abnormal ars values')\n",
    "        print(else_orders[(else_orders['updateType'] == 0) & (else_orders['date'] == cur)].groupby('ars')['date'].size().sort_values(ascending=False))\n",
    "        print(else_orders[(else_orders['updateType'] == 0) & (else_orders['date'] == cur)].groupby('accCode')['date'].size().sort_values(ascending=False))\n",
    "        ars_list = else_orders[(else_orders['updateType'] == 0) & (else_orders['date'] == cur)].groupby('ars')['date'].size().sort_values(ascending=False).reset_index()['ars'].values\n",
    "        ars_list = ', '.join([str(x) for x in ars_list])\n",
    "        count += 1\n",
    "        body += str(count) + '. There are abnormal ars values in data: ' + ars_list + '.<div>'\n",
    "        kk = else_orders[(else_orders['updateType'] == 0) & (else_orders['date'] == cur)].groupby('accCode')['date'].size().sort_values(ascending=False)\n",
    "        if kk[kk > 20].shape[0] > 0:\n",
    "            count += 1\n",
    "            stock_list = ', '.join([str(x) for x in kk[kk > 20].index.values])\n",
    "            body += str(count) + '. These accounts have more than 20 abnormal ars orders: ' + stock_list + '.<div>'\n",
    "    taking['directNum'] = taking.groupby(['date', 'secid', 'vai', 'sdd'])['orderDirection1'].transform('nunique')\n",
    "    if taking[(taking['directNum'] != 1)].shape[0] > 0:\n",
    "        print('opposite direction for same date, same secid, same vai')\n",
    "        print(taking[(taking['directNum'] != 1) & (taking['updateType'] == 0)].groupby(['accCode'])['orderDirection'].size())\n",
    "        try:\n",
    "            num1 = taking[(taking['directNum'] != 1) & (taking['updateType'] == 0) & (taking['date'] == cur)].shape[0]\n",
    "            assert(num1 < 20)\n",
    "        except:\n",
    "            count += 1\n",
    "            body += str(count) + '. There are in total ' + str(num1) + ' orders with opposite directions under same date, secid, vai.<div>'\n",
    "        try:\n",
    "            num2 = list(taking[(taking['directNum'] != 1) & (taking['updateType'] == 0) & (taking['date'] == \\\n",
    "                cur)].groupby('accCode')['date'].size()[taking[(taking['directNum'] != 1) & \\\n",
    "               (taking['updateType'] == 0) & (taking['date'] == cur)].\\\n",
    "                                                                           groupby('accCode')['date'].size() > 10].index)\n",
    "            assert(len(num2) == 0)\n",
    "        except:\n",
    "            count += 1\n",
    "            num2 = ', '.join([str(x) for x in num2])\n",
    "            body += str(count) + '. ' + num2 + ' has more than 10 orders with opposite directions under same date, secid, vai.<div>'\n",
    "        taking = taking[taking['directNum'] == 1]\n",
    "\n",
    "    assert((taking.groupby(['date', 'secid', 'vai', 'sdd'])['orderDirection1'].nunique() == 1).all() == True)\n",
    "    orderLog = pd.concat([taking, making]).sort_values(by=['date', 'colo', 'accCode', 'secid', 'vai', 'clockAtArrival']).reset_index(drop=True)\n",
    "\n",
    "    ## Assertion 2:  make sure each account, secid, vai only has one insertion\n",
    "    print('=======================================================================================')\n",
    "    print('2. same date, secid, vai, accCode: one insertion')\n",
    "    a = orderLog[orderLog['updateType'] == 0].groupby(['date', 'colo', 'accCode', 'secid', 'vai', 'sdd'])['clockAtArrival'].count().reset_index()\n",
    "    if a[a['clockAtArrival'] > 1].shape[0] > 0:\n",
    "        print('more than one insertion at same time')\n",
    "        a = a[(a['clockAtArrival'] > 1)]\n",
    "        print(a)\n",
    "        print(a.groupby(['date'])['accCode'].size())\n",
    "        print(a.groupby(['date', 'accCode'])['sdd'].size())\n",
    "        try:\n",
    "            num1 = a[a['date'] == cur].shape[0]\n",
    "            assert(num1 < 20)\n",
    "        except:\n",
    "            count += 1\n",
    "            body += str(count) + '. There are in total ' + str(num1) + ' orders with more than one insertion in same order.<div>'\n",
    "        try:\n",
    "            num2 = list(a[a['date'] == cur].groupby(['accCode'])['date'].size()[a[a['date'] == cur].groupby(['accCode'])['date'].size() > 10].index)\n",
    "            assert(len(num2) == 0)\n",
    "        except:\n",
    "            count += 1\n",
    "            num2 = ', '.join([str(x) for x in num2])\n",
    "            body += str(count) + '. ' + num2 + ' has more than 10 orders with more than one insertion in same order.<div>'        \n",
    "        d_el = pd.merge(orderLog, a, on=['date', 'colo', 'accCode', 'secid', 'vai', 'sdd'])['order'].unique()\n",
    "        orderLog = orderLog[~(orderLog['order'].isin(d_el))]\n",
    "\n",
    "    orderLog['isMsg'] = np.where(orderLog['updateType'] == 0, \n",
    "                                 np.where(orderLog['mse'] == 100, 1, 0), np.nan)\n",
    "    orderLog['isMsg'] = orderLog.groupby(['order'])['isMsg'].ffill()\n",
    "\n",
    "\n",
    "    ### Assertion 3:  check IPO stocks selling status\n",
    "    print('=======================================================================================')\n",
    "    print('3. IPO stocks selling (ars = 301, 302)')\n",
    "    if orderLog[(orderLog['ars'].isin([301, 302])) & (orderLog['date'] == cur)].shape[0] != 0:\n",
    "        kk = orderLog[(orderLog['ars'].isin([301, 302])) & (orderLog['date'] == cur)]\n",
    "        print(kk)\n",
    "        try:\n",
    "            assert(kk[kk['orderDirection1'] == 1].shape[0] == 0)\n",
    "            print('we only sell, never buy')\n",
    "        except:\n",
    "            print('There are IPO buy side orders!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "            count += 1\n",
    "            num1 = kk[kk['orderDirection1'] == 1].shape[0]\n",
    "            body += str(count) + '. There are ' + str(num1) + ' IPO buy side orders.<div>'\n",
    "            print(kk[kk['orderDirection1'] == 1])\n",
    "        kk1 = kk[kk['updateType'] == 0]\n",
    "        kk1 = kk1.sort_values(by=['accCode', 'secid','clockAtArrival'])\n",
    "        kk1['diff'] = kk1.groupby(['accCode', 'secid'])['clockAtArrival'].apply(lambda x: x-x.shift(1))\n",
    "        kk1['diff'] = kk1['diff'].fillna(0)\n",
    "        try:\n",
    "            assert(kk1[kk1['diff'] < 10e6].shape[0] == 0)\n",
    "            print('for each stock in the same account, there is no insertion within 10 seconds of the previous insertion')\n",
    "        except:\n",
    "            count += 1\n",
    "            kk1 = kk1.reset_index()\n",
    "            num2 = kk1[kk1['diff'] < 10e6].shape[0]\n",
    "            body += str(count) + '. There are ' + str(num2) + ' over ' + str(kk1.shape[0]) + ' orders with insertion within 10 seconds for orders under same account same stock.<div>'\n",
    "            print('There are insertion within 10 seconds for orders under same account same stock!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')        \n",
    "            print(kk1[kk1['diff'] < 10e6])\n",
    "        kk2 = kk[(kk['updateType'] == 1)]\n",
    "\n",
    "        try:\n",
    "            assert(kk2[kk2['duration'] < 3e6].shape[0] == 0)\n",
    "            print('for each stock in the same account, the cancellation of an order happens more than 3 seconds after the insertion')\n",
    "        except:\n",
    "            count += 1\n",
    "            num2 = kk2[kk2['duration'] < 3e6].shape[0]\n",
    "            body += str(count) + '. There are ' + str(num2) + ' over ' + str(kk1.shape[0]) + ' orders with cancellation within 3 seconds after insertion.<div>'        \n",
    "            print('There are cancellation within 3 seconds for orders under same account same stock!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "            print(kk2[kk2['duration'] < 3e6])\n",
    "\n",
    "\n",
    "    ### Assertion 4: check updateType == 7 orders, make sure updateType == 7 orders < 20 per account, < 100 in total\n",
    "    print('=======================================================================================')\n",
    "    print('4. updateType 7 orders')\n",
    "    if orderLog[(orderLog['updateType'] == 7) & (orderLog['date'] == cur)].shape[0] != 0:\n",
    "        try:\n",
    "            assert(orderLog[(orderLog['updateType'] == 7) & (orderLog['date'] == cur)].groupby(['date', 'accCode'])['order'].nunique().max() < 20)\n",
    "        except:\n",
    "            print('There are more than 20 updateType 7 orders per account')\n",
    "            count += 1\n",
    "            a = list(orderLog[(orderLog['updateType'] == 7) & (orderLog['date'] == cur)].groupby(['accCode'])['order'].nunique()[\n",
    "                orderLog[(orderLog['updateType'] == 7) & (orderLog['date'] == cur)].groupby(['accCode'])['order'].nunique() >= 20\n",
    "            ].index)\n",
    "            a = ', '.join([str(x) for x in a])\n",
    "            body += str(count) + '. ' + a + ' has more than 20 updateType 7 orders.<div>'\n",
    "        try:      \n",
    "            assert(orderLog[(orderLog['updateType'] == 7) & (orderLog['date'] == cur)]['order'].nunique() < 100)\n",
    "        except:\n",
    "            print('Ther are more than 100 updateType 7 orders in total')\n",
    "            count += 1\n",
    "            body += str(count) + '. There are more than 100 updateType 7 orders in total.<div>'\n",
    "\n",
    "\n",
    "    ### Assertion 5: check updateType == 6 orders, make sure updateType == 6 orders < 5% per account\n",
    "    ### order being rejected by broker\n",
    "    print('=======================================================================================')\n",
    "    print('5. updateType 6 orders')\n",
    "    k1 = orderLog[(orderLog['updateType'] == 6) & (orderLog['date'] == cur)].groupby(['accCode'])['order'].nunique().reset_index()\n",
    "    k2 = orderLog[(orderLog['date'] == cur)].groupby(['accCode'])['order'].nunique().reset_index()\n",
    "    k = pd.merge(k1, k2, on=['accCode'], how='left')\n",
    "    k['prob'] = k['order_x']/k['order_y']\n",
    "    try:\n",
    "        assert(sum(k['prob'] >= 0.05) == 0)\n",
    "    except:\n",
    "        print('There are accounts with more than 5% updateType 6 orders!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        print(k[k['prob'] >= 0.05])\n",
    "        a = k[k['prob'] >= 0.05]['accCode'].unique()\n",
    "        a = ', '.join([str(x) for x in a])\n",
    "        count += 1\n",
    "        body += str(count) + '. ' + a + ' has more than 5% updateType 6 orders.<div>'\n",
    "\n",
    "    ### Assertion 6: check CYB orders, make sure all CYB stocks have absOrderSize < 30w\n",
    "    print('=======================================================================================')\n",
    "    print('6. CYB stocks order size < 30w')\n",
    "    try:\n",
    "        cyb = orderLog[(orderLog['secid'] >= 2300000) & (orderLog['updateType'] == 0) & (orderLog['date'] == cur)]\n",
    "        assert(cyb[cyb['absOrderSize'] > 300000].shape[0] == 0)\n",
    "    except:\n",
    "        print('CYB stocks total absOrderSize >= 30w!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        num1 = cyb[cyb['absOrderSize'] > 300000].shape[0]\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(num1) + ' orders with CYB absOrderSize > 30w.<div>'\n",
    "\n",
    "\n",
    "    ### Assertion 7:  make sure there is no unexpected updateType \n",
    "    print('=======================================================================================')\n",
    "    print('7. unexpected updateType')\n",
    "    def getTuple(x):\n",
    "        return tuple(i for i in x)\n",
    "\n",
    "    checkLog = orderLog[~((orderLog['updateType'] == 4) & (orderLog.groupby(['order'])['updateType'].shift(-1) == 4))]\n",
    "    checkLog = checkLog.groupby(['order'])['updateType'].apply(lambda x: getTuple(x)).reset_index()\n",
    "    checkLog['status'] = np.where(checkLog['updateType'].isin([(0, 2, 4), (0, 2, 1, 4), (0, 2, 1, 2, 4), (0, 2, 4, 1, 4), (0, 4), (0, 1, 4), (0, 4, 1, 4), (0, 2, 2, 4), (0, 4, 2, 4), (0, 2, 2, 1, 4), (0, 2, 2, 4, 1, 4)]),0,\n",
    "                         np.where(checkLog['updateType'].isin([(0, 2, 4, 1, 3), (0, 2, 4, 1, 4, 3), (0, 2, 1, 4, 3), (0, 4, 1, 3), (0, 1, 4, 3),\n",
    "                                                                   (0, 2, 2, 4, 1, 3), (0, 2, 2, 4, 1, 4, 3), (0, 2, 2, 1, 4, 3), (0, 4, 2, 4, 1, 3),\n",
    "                                                                   (0, 4, 2, 1, 3), (0, 4, 1, 4, 3), (0, 4, 1)]), 1,\n",
    "                         np.where(checkLog['updateType'].isin([(0, 2, 1, 3), (0, 2, 2, 1, 3), (0, 2, 3), (0, 3), (0, 1, 3), (0, ), (0, 2), (0, 2, 1), (0, 2, 2)]), 2, 3)))\n",
    "    print(checkLog[checkLog['status'] == 3].groupby('updateType')['order'].size())\n",
    "    orderLog = pd.merge(orderLog, checkLog[['order', 'status']], how='left', on=['order'], validate='many_to_one')\n",
    "    orderLog = orderLog[orderLog['status'].isin([0, 1, 2])].reset_index(drop=True)\n",
    "\n",
    "    ### Assertion 8:  make sure status==0 got all traded\n",
    "    print('=======================================================================================')\n",
    "    print('8. status == 0: all traded')\n",
    "    a = orderLog[(orderLog['status'] == 0)]\n",
    "    a = a.groupby(['date', 'order'])[['absOrderSizeCumFilled', 'absOrderSize']].max().reset_index()\n",
    "    a.columns = ['date', 'order', 'filled', 'total']\n",
    "    print('in total trade, any fill != total cases')\n",
    "    print(a[a['filled'] != a['total']])\n",
    "    if a[a['filled'] != a['total']].shape[0] > 0:\n",
    "        removeOrderLs = a[a['filled'] != a['total']]['order'].unique()\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(a[(a['filled'] != a['total']) & (a['date'] == cur)]['order'].nunique()) + \\\n",
    "        ' over ' + str(a[(a['date'] == cur)]['order'].nunique()) + ' orders status == 0 but not all traded.<div>'\n",
    "        orderLog = orderLog[~(orderLog['order'].isin(removeOrderLs))]\n",
    "\n",
    "    ### Assertion 9:  make sure status==1 got partial traded\n",
    "    print('=======================================================================================')\n",
    "    print('9. status == 1: partial traded')\n",
    "    a = orderLog[orderLog['status'] == 1]\n",
    "    a = a.groupby(['date', 'order'])[['absOrderSizeCumFilled', 'absOrderSize']].max().reset_index()\n",
    "    a.columns = ['date', 'order', 'filled', 'total']\n",
    "    print('in partial trade, any fill >= total or fill is 0 cases for updateType 4')\n",
    "    print(a[(a['filled'] >= a['total']) | (a['filled'] == 0)])\n",
    "    if a[(a['filled'] >= a['total']) | (a['filled'] == 0)].shape[0] > 0:\n",
    "        removeOrderLs = a[(a['filled'] >= a['total']) | (a['filled'] == 0)]['order'].unique()\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(a[((a['filled'] >= a['total']) | (a['filled'] == 0)) & (a['date'] == cur)]['order'].nunique()) + \\\n",
    "        ' over ' + str(a[(a['date'] == cur)]['order'].nunique()) + ' orders status == 1 but not partial traded.<div>'\n",
    "        orderLog = orderLog[~(orderLog['order'].isin(removeOrderLs))]\n",
    "\n",
    "    ### Assertion 10: make sure no cancellation within 1 sec\n",
    "    print('=======================================================================================')\n",
    "    print('10. no cancellation within 1 sec')\n",
    "    a = orderLog[(orderLog['updateType'] == 1) & (orderLog['duration'] < 1e6)]\n",
    "    print('any cancellation within 1 sec')\n",
    "    print(a)\n",
    "    if a[a['date'] == cur].shape[0] > 0:\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(a[(a['date'] == cur)]['order'].nunique()) + ' orders cancel within 1s.<div>'    \n",
    "    if a.shape[0] > 0:\n",
    "        removeOrderLs = a['order'].unique()\n",
    "        orderLog = orderLog[~(orderLog['order'].isin(removeOrderLs))]\n",
    "\n",
    "\n",
    "    ### Assertion 11: make sure no order has shares > 80w or notional > 800w\n",
    "    print('=======================================================================================')\n",
    "    print('11. Orders with size > 80w or notional > 800w')\n",
    "    orderLog['orderNtl'] = orderLog['absOrderSize'] * orderLog['orderPrice']\n",
    "    if orderLog[(orderLog['absOrderSize'] > 800000) & (orderLog['date'] == cur)].shape[0] > 0:\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(orderLog[(orderLog['absOrderSize'] > 800000) & (orderLog['date'] == cur)]['order'].nunique()) + ' orders shares > 80w.<div>'    \n",
    "    if orderLog[orderLog['absOrderSize'] > 800000].shape[0] > 0:\n",
    "        print('some order quantity are > 80w')\n",
    "        print(orderLog[orderLog['absOrderSize'] > 800000].groupby(['colo', 'accCode'])['order'].nunique())\n",
    "        print(orderLog[orderLog['absOrderSize'] > 800000][['date', 'accCode', 'secid', 'vai', 'absOrderSize', 'orderPrice',\n",
    "                                                             'orderNtl', 'orderDirection', 'clock', 'order']])\n",
    "    if orderLog[(orderLog['orderNtl'] > 8000000) & (orderLog['date'] == cur)].shape[0] > 0:\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(orderLog[(orderLog['orderNtl'] > 8000000) & (orderLog['date'] == cur)]['order'].nunique()) + ' orders notional > 800w.<div>'                \n",
    "    if orderLog[orderLog['orderNtl'] > 8000000].shape[0] > 0:\n",
    "        print('some order ntl are > 800w')\n",
    "        print(orderLog[orderLog['orderNtl'] > 8000000].groupby(['colo', 'accCode'])['order'].nunique())\n",
    "        print(orderLog[orderLog['orderNtl'] > 8000000][['date', 'accCode', 'secid', 'vai', 'absOrderSize', 'orderPrice',\n",
    "                                                          'orderNtl', 'orderDirection', 'clock', 'order', \"updateType\", \n",
    "                                                          \"tradePrice\", \"absOrderSizeCumFilled\", \"absFilledThisUpdate\"]])\n",
    "\n",
    "    removeOrderLs = list(set(orderLog[orderLog['absOrderSize'] > 800000]['order'].unique()) | set(orderLog[orderLog['orderNtl'] > 8000000]['order'].unique()))\n",
    "    orderLog = orderLog[~(orderLog['order'].isin(removeOrderLs))]\n",
    "\n",
    "\n",
    "    orderLog = orderLog.sort_values(by=['date', 'secid', 'vai', 'accCode', 'order', 'clockAtArrival']).reset_index(drop=True)\n",
    "\n",
    "    orderLog['exchange'] = np.where(orderLog['secid'] >= 2000000, 'SZE', 'SSE')\n",
    "    orderLog['orderNtl'] = orderLog['orderPrice'] * orderLog['absOrderSize']\n",
    "    orderLog['tradeNtl'] = np.where(orderLog['updateType'] == 4, orderLog['tradePrice']*orderLog['absFilledThisUpdate'], 0)\n",
    "    orderLog[\"mrstaat\"] = orderLog.groupby(['order'])['mrstaat'].transform('first')\n",
    "    orderLog[\"ars\"] = orderLog.groupby(['order'])['ars'].transform('first')\n",
    "    orderLog[\"mrstauc\"] = orderLog.groupby(['order'])['mrstauc'].transform('first')\n",
    "    orderLog[\"mrsb90\"] = orderLog.groupby(['order'])['mrsb90'].transform('first')\n",
    "    orderLog[\"mrss90\"] = orderLog.groupby(['order'])['mrss90'].transform('first')\n",
    "    orderLog[\"aaa\"] = orderLog.groupby(['order'])['aaa'].transform('first')\n",
    "    orderLog = orderLog[~orderLog['ars'].isnull()]\n",
    "    # orderLog = orderLog[orderLog['ars'] % 10 == 1]\n",
    "\n",
    "\n",
    "    orderLog['m1'] = orderLog['mrstaat'].apply(lambda x: x - (x // 10000) * 10000)\n",
    "    orderLog['m2'] = orderLog['mrstauc'].apply(lambda x: x - (x // 10000) * 10000)\n",
    "    try:\n",
    "        orderLog['mrsb90'] = orderLog['mrsb90'].astype(float)\n",
    "    except:\n",
    "        print(orderLog[orderLog['mrsb90'] == '-'])\n",
    "        orderLog = orderLog[orderLog['mrsb90'] != '-']\n",
    "        orderLog['mrsb90'] = orderLog['mrsb90'].astype(float)\n",
    "    try:\n",
    "        orderLog['mrss90'] = orderLog['mrss90'].astype(float)\n",
    "    except:\n",
    "        print(orderLog[orderLog['mrss90'] == '-'])\n",
    "        orderLog = orderLog[orderLog['mrss90'] != '-']\n",
    "        orderLog['mrss90'] = orderLog['mrss90'].astype(float)\n",
    "    try:\n",
    "        orderLog['aaa'] = orderLog['aaa'].astype(float)\n",
    "    except:\n",
    "        print(orderLog[orderLog['aaa'] == '-'])\n",
    "        orderLog = orderLog[orderLog['aaa'] != '-']\n",
    "        orderLog['aaa'] = orderLog['aaa'].astype(float)\n",
    "    \n",
    "    orderLog.loc[(orderLog['orderDirection'] >= 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrsb90']) < 1e-12), 'mrstauc'] = \\\n",
    "    orderLog.loc[(orderLog['orderDirection'] >= 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrsb90']) < 1e-12), 'm2']\n",
    "\n",
    "    orderLog.loc[(orderLog['orderDirection'] >= 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrsb90']) < 1e-12), 'mrstaat'] = \\\n",
    "    orderLog.loc[(orderLog['orderDirection'] >= 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrsb90']) < 1e-12), 'm1']\n",
    "\n",
    "    orderLog.loc[(orderLog['orderDirection'] < 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrss90']) < 1e-12), 'mrstauc'] = \\\n",
    "    orderLog.loc[(orderLog['orderDirection'] < 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrss90']) < 1e-12), 'm2']\n",
    "\n",
    "    orderLog.loc[(orderLog['orderDirection'] < 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrss90']) < 1e-12), 'mrstaat'] = \\\n",
    "    orderLog.loc[(orderLog['orderDirection'] < 1) &\\\n",
    "             (orderLog['mrstaat'].isin([11000, 13000])) & (abs(orderLog['aaa'] - orderLog['mrss90']) < 1e-12), 'm1']    \n",
    "\n",
    "\n",
    "    orderLog['sta'] = np.where(orderLog['mrstaat'] == 1000, '1. staone', np.where(\n",
    "    orderLog['mrstaat'] == 3000, '2. statwo', np.where(\n",
    "    orderLog['mrstaat'].isin([11000, 13000]), '3. sta300', 'else')))\n",
    "    print(orderLog[(orderLog['sta'] == 'else') & (orderLog['updateType'] == 0)].groupby(['date', 'accCode'])['secid'].size())\n",
    "    print(orderLog[(orderLog['sta'] == 'else') & (orderLog['date'] == cur) & (orderLog['updateType'] == 0)])\n",
    "    m1 = orderLog[(orderLog['sta'] == 'else') & (orderLog['date'] == cur) & (orderLog['updateType'] == 0)].shape[0]\n",
    "    if m1 != 0:\n",
    "        count += 1\n",
    "        body += str(count) + '. There are ' + str(m1) + ' orders with invalid strategy.<div>'                    \n",
    "    orderLog = orderLog[orderLog['mrstaat'].isin([11000, 13000, 1000, 3000])]\n",
    "    print(orderLog[orderLog['updateType'] == 0].groupby(['mrstaat', 'mrstauc'])['date'].size())\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    body += '<p><b>II. fill rate</b></p>'\n",
    "\n",
    "    import pandas as pd\n",
    "    def convertToHtml(result,title):\n",
    "        #htmltable\n",
    "        #resultlist[list1,list2]\n",
    "        #titlelistresulttitleList[0]resultList[0]html\n",
    "        d = {}\n",
    "        index = 0\n",
    "        for t in title:\n",
    "            d[t]=result[index]\n",
    "            index = index+1\n",
    "        df = pd.DataFrame(d)\n",
    "        df = df[title]\n",
    "        h = df.to_html(index=False)\n",
    "        return h\n",
    "\n",
    "    placeSZE = orderLog[(orderLog['secid'] >= 2000000) & (orderLog['updateType'] == 0)]\n",
    "    print('%.2f%% SZE orders triggered by msg data'%(placeSZE[placeSZE['isMsg'] == 1].shape[0]/placeSZE.shape[0]*100))\n",
    "    body += '%.2f%% SZE orders triggered by msg data<div>'%(placeSZE[placeSZE['isMsg'] == 1].shape[0]/placeSZE.shape[0]*100)\n",
    "    placeSZE = orderLog[(orderLog['secid'] >= 2000000) & (orderLog['updateType'] == 0)]\n",
    "    r1 = placeSZE[placeSZE['isMsg'] == 1].groupby(['date', 'accCode'])['secid'].size().reset_index()\n",
    "    r2 = placeSZE.groupby(['date', 'accCode'])['secid'].size().reset_index()\n",
    "    re = pd.merge(r1, r2, on=['date', 'accCode'], how='inner')\n",
    "    re['perc'] = re['secid_x'] / re['secid_y']\n",
    "    print(re[re['perc'] < 0.8])\n",
    "    for i in re[re['perc'] < 0.8]['accCode'].unique():\n",
    "        a = list(re[(re['perc'] < 0.8) & (re['accCode'] == i)]['date'].unique())\n",
    "        a = ', '.join([str(x) for x in a])\n",
    "        body += 'accCode ' + str(i) + ' SZE orders on ' + a + ' has msg triggered percentage < 80%<div>'\n",
    "\n",
    "    orderLog['tag'] = 'previous'\n",
    "    orderLog.loc[orderLog['date'] == cur, 'tag'] = 'current'\n",
    "    o1 = orderLog[orderLog['updateType'] == 0].groupby(['tag', 'exchange'])['orderNtl'].sum().reset_index()\n",
    "    o2 = orderLog[orderLog['updateType'] == 4].groupby(['tag', 'exchange'])['tradeNtl'].sum().reset_index()\n",
    "    o = pd.merge(o1, o2, on=['tag', 'exchange'])\n",
    "    o['perc'] = o['tradeNtl'] / o['orderNtl']\n",
    "    o['perc'] = o['perc'].apply(lambda x: '%.f'%(x*100))\n",
    "    o1 = o[o['tag'] == 'current']\n",
    "    o1 = o1.rename(columns={'perc':'cur_perc'})\n",
    "    o2 = o[o['tag'] == 'previous']\n",
    "    o2 = o2.rename(columns={'perc':'prev_perc'})\n",
    "    re = pd.merge(o1[['exchange', 'cur_perc']], o2[['exchange', 'prev_perc']], on='exchange')\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(re.groupby(['exchange']).first().to_html()))\n",
    "    result = [re['exchange'].values, re['cur_perc'].values, re['prev_perc'].values]\n",
    "    title=['exchange', 'cur_perc', 'prev_perc']\n",
    "    body += convertToHtml(result,title)\n",
    "\n",
    "    orderLog['num'] = orderLog.groupby(['exchange', 'colo', 'accCode', 'secid'])['tag'].transform('nunique')\n",
    "    checkLog = orderLog[orderLog['num'] == 2]\n",
    "    # checkLog = orderLog\n",
    "    d1 = checkLog[(checkLog['updateType'] == 0)].groupby(['tag', 'exchange', 'sta', 'colo', 'accCode'])['orderNtl'].sum().reset_index()\n",
    "    d2 = checkLog[(checkLog['updateType'] == 4)].groupby(['tag', 'exchange', 'sta', 'colo', 'accCode'])['tradeNtl'].sum().reset_index()\n",
    "    dd = pd.merge(d1, d2, on=['tag', 'exchange', 'sta', 'colo', 'accCode'])\n",
    "    dd['fill rate'] = dd['tradeNtl'] / dd['orderNtl']\n",
    "    add = checkLog[(checkLog['updateType'] == 0)].groupby(['tag', 'exchange', 'sta', 'colo', 'accCode'])['order'].nunique().reset_index()\n",
    "    add = add.rename(columns={'order':'num'})\n",
    "    dd = pd.merge(dd, add, on=['tag', 'exchange', 'sta', 'colo', 'accCode'])\n",
    "    prev = dd[dd['tag'] == 'previous']\n",
    "    prev = prev.rename(columns={'num':'prev_num', 'fill rate':'prev_fillRate'})\n",
    "    cur = dd[dd['tag'] == 'current']\n",
    "    cur = cur.rename(columns={'num':'cur_num', 'fill rate':'cur_fillRate'})\n",
    "    report = pd.merge(prev[['exchange', 'sta', 'colo', 'accCode', 'prev_num', 'prev_fillRate']], \n",
    "                  cur[['exchange', 'sta', 'colo', 'accCode', 'cur_num', 'cur_fillRate']], on=['exchange', 'sta', 'colo', 'accCode'], how='inner')\n",
    "\n",
    "    a1 = checkLog[(checkLog['updateType'] == 0) & (checkLog['tag'] == 'previous')].groupby(['date', 'exchange', 'sta', 'colo', 'accCode'])['orderNtl'].sum().reset_index()\n",
    "    a2 = checkLog[(checkLog['updateType'] == 4) & (checkLog['tag'] == 'previous')].groupby(['date', 'exchange', 'sta', 'colo', 'accCode'])['tradeNtl'].sum().reset_index()\n",
    "    aa = pd.merge(a1, a2, on=['date', 'exchange', 'sta', 'colo', 'accCode'])\n",
    "    aa['fill rate'] = aa['tradeNtl'] / aa['orderNtl']\n",
    "    aa['count'] = aa.groupby(['exchange', 'sta', 'colo', 'accCode'])['date'].transform('nunique')\n",
    "    aa1 = aa.groupby(['exchange', 'sta', 'colo', 'accCode'])['fill rate'].describe()[['mean', 'std']].reset_index()\n",
    "    aa1 = aa1.fillna(0)\n",
    "    aa = pd.merge(aa, aa1, on=['exchange', 'sta', 'colo', 'accCode'])\n",
    "    for j in [1]:\n",
    "        aa[str(j) + 'std_low'] = aa['mean'] - j*aa['std']\n",
    "        aa[str(j) + 'std_high'] = aa['mean'] + j*aa['std']\n",
    "        aa['count1'] = np.where((aa['fill rate'] <= aa[str(j) + 'std_high']) & (aa['fill rate'] >= aa[str(j) + 'std_low']), 1, 0)\n",
    "        re1 = aa.groupby(['exchange', 'sta', 'colo', 'accCode'])['count1'].sum().reset_index()\n",
    "        re2 = aa.groupby(['exchange', 'sta', 'colo', 'accCode'])['count'].first().reset_index()\n",
    "        re1 = pd.merge(re2, re1, on=['exchange', 'sta', 'colo', 'accCode'])\n",
    "        re1['count1'] = re1['count1'] / re1['count']\n",
    "        re1 = re1.rename(columns={'count1':str(j)+'*std'})\n",
    "    for j in [1.5, 2, 2.5, 3, 3.5, 4, 4.5]:\n",
    "        aa[str(j) + 'std_low'] = aa['mean'] - j*aa['std']\n",
    "        aa[str(j) + 'std_high'] = aa['mean'] + j*aa['std']\n",
    "        aa['count1'] = np.where((aa['fill rate'] <= aa[str(j) + 'std_high']) & (aa['fill rate'] >= aa[str(j) + 'std_low']), 1, 0)\n",
    "        re = aa.groupby(['exchange', 'sta', 'colo', 'accCode'])['count1'].sum().reset_index()\n",
    "        re2 = aa.groupby(['exchange', 'sta', 'colo', 'accCode'])['count'].first().reset_index()\n",
    "        re = pd.merge(re2, re, on=['exchange', 'sta', 'colo', 'accCode'])\n",
    "        re['count1'] = re['count1'] / re['count']\n",
    "        re = re.rename(columns={'count1':str(j)+'*std'})\n",
    "        re1 = pd.merge(re1, re[['exchange', 'sta', 'colo', 'accCode', str(j)+'*std']], on=['exchange', 'sta', 'colo', 'accCode'])\n",
    "    nc = []\n",
    "    for i in range(0, re1.shape[0]):\n",
    "        nc.append(np.float(re1.columns[5:][(re1.iloc[i, 5:] == 1)][0].split('*')[0]))\n",
    "    re1['n'] = nc\n",
    "    print(re1.shape[0])\n",
    "    print(aa1.shape[0])\n",
    "    aa1 = pd.merge(aa1, re1[['exchange', 'sta', 'colo', 'accCode', 'n']], on=['exchange', 'sta', 'colo', 'accCode'])\n",
    "    aa1['min'] = aa1['mean'] - aa1['std'] * aa1['n']\n",
    "    aa1['max'] = aa1['mean'] + aa1['std'] * aa1['n']\n",
    "    report = pd.merge(report, aa1, on=['exchange', 'sta', 'colo', 'accCode'], how='left')\n",
    "    assert(report[report['mean'].isnull()].shape[0] == 0)\n",
    "    print(report[((report['cur_fillRate'] > report['max']) | (report['cur_fillRate'] < report['min'])) & (report['cur_num'] > 100) & (abs(report['cur_fillRate'] - report['prev_fillRate']) > 0.15)].groupby(['exchange', 'sta', 'colo', 'accCode'])['prev_fillRate', 'cur_fillRate'].first())\n",
    "    report = report[((report['cur_fillRate'] > report['max']) | (report['cur_fillRate'] < report['min'])) & (report['cur_num'] > 100) & (abs(report['cur_fillRate'] - report['prev_fillRate']) > 0.15)].groupby(['exchange', 'sta', 'colo', 'accCode'])['prev_fillRate', 'cur_fillRate'].first().reset_index()\n",
    "\n",
    "    for cols in ['prev_fillRate', 'cur_fillRate']:\n",
    "        report[cols] = report[cols].apply(lambda x: '%.f%%'%(100*x))\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(report.groupby(['exchange', 'sta', 'colo', 'accCode']).first().to_html()))\n",
    "    body += '<div>In the following cases, fill rate under given accCode pass the hurdle we set:'\n",
    "    result = [report['exchange'].values, report['sta'].values, report['colo'].values, report['accCode'].values, \n",
    "             report['prev_fillRate'].values, report['cur_fillRate'].values]\n",
    "    title = ['exchange', 'sta', 'colo', 'accCode', 'prev_fillRate', 'cur_fillRate']\n",
    "    body += convertToHtml(result,title)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    body += '<p><b>III. internal latency</b></p>'\n",
    "\n",
    "    orderLog['num'] = orderLog.groupby(['exchange', 'colo', 'accCode', 'secid'])['tag'].transform('nunique')\n",
    "    checkLog = orderLog[(orderLog[\"updateType\"] == 0) & (orderLog['num'] == 2)]\n",
    "    checkLog = checkLog[checkLog['caamd'] != 0]\n",
    "    checkLog['internal_latency'] = checkLog[\"clockAtArrival\"] - checkLog[\"caamd\"]\n",
    "    SZE = checkLog[checkLog['secid'] >= 2000000]\n",
    "    SSE = checkLog[checkLog['secid'] < 2000000]\n",
    "    SZE = SZE[SZE['isMsg'] == 1]\n",
    "    c1 = SZE.groupby(['tag', \"exchange\", \"colo\", \"accCode\", \"sta\", \"isMsg\"])[\"internal_latency\"].quantile(.95).reset_index()\n",
    "    c2 = SZE.groupby(['tag', \"exchange\", \"colo\", \"accCode\", \"sta\", \"isMsg\"])[\"internal_latency\"].median().reset_index()\n",
    "    c3 = SZE.groupby(['tag', \"exchange\", \"colo\", \"accCode\", \"sta\", \"isMsg\"])[\"internal_latency\"].count().reset_index()\n",
    "\n",
    "    re1 = pd.merge(c3, c1, on=['tag', \"exchange\", \"colo\", \"accCode\", \"sta\", \"isMsg\"])\n",
    "    re1 = re1.rename(columns = {'internal_latency_x': 'count', 'internal_latency_y': '95 percentile'})\n",
    "    re1 = pd.merge(re1, c2, on=['tag', \"exchange\", \"colo\", \"accCode\", \"sta\", \"isMsg\"])\n",
    "    re1 = re1.rename(columns = {'internal_latency': 'median'})\n",
    "    re1['isMsg'] = 1\n",
    "\n",
    "    c1 = SSE.groupby(['tag', \"exchange\", \"colo\", \"accCode\", \"sta\", \"isMsg\"])[\"internal_latency\"].quantile(.95).reset_index()\n",
    "    c2 = SSE.groupby(['tag', \"exchange\", \"colo\", \"accCode\", \"sta\", \"isMsg\"])[\"internal_latency\"].median().reset_index()\n",
    "    c3 = SSE.groupby(['tag', \"exchange\", \"colo\", \"accCode\", \"sta\", \"isMsg\"])[\"internal_latency\"].count().reset_index()\n",
    "\n",
    "    re2 = pd.merge(c3, c1, on=['tag', \"exchange\", \"colo\", \"accCode\", \"sta\", \"isMsg\"])\n",
    "    re2 = re2.rename(columns = {'internal_latency_x': 'count', 'internal_latency_y': '95 percentile'})\n",
    "    re2 = pd.merge(re2, c2, on=['tag', \"exchange\", \"colo\", \"accCode\", \"sta\", \"isMsg\"])\n",
    "    re2 = re2.rename(columns = {'internal_latency': 'median'})\n",
    "    re2\n",
    "\n",
    "    re = pd.concat([re1, re2]).reset_index(drop=True)\n",
    "\n",
    "    for col in ['isMsg','median', '95 percentile']:\n",
    "        re[col] = re[col].astype(int)\n",
    "\n",
    "    re1 = re[re['tag'] == 'current']\n",
    "    re1 = re1.rename(columns={'count':'cur_count', 'median':'cur_med', '95 percentile':'cur_95p'})\n",
    "    re2 = re[re['tag'] == 'previous']\n",
    "    re2 = re2.rename(columns={'count':'prev_count', 'median':'prev_med', '95 percentile':'prev_95p'})\n",
    "    report = pd.merge(re1, re2, on=['exchange', 'colo', 'accCode', 'sta', 'isMsg'])\n",
    "\n",
    "    checkLog[(checkLog['exchange'] == 'SSE') | ((checkLog['exchange'] == 'SZE') & (checkLog['isMsg'] == 1))]\n",
    "    aa = checkLog[(checkLog['tag'] == 'previous')].groupby(['date', 'exchange', 'sta', 'colo', 'accCode', 'isMsg'])['internal_latency'].median().reset_index()\n",
    "    aa['count'] = aa.groupby(['exchange', 'sta', 'colo', 'accCode', 'isMsg'])['date'].transform('nunique')\n",
    "    aa1 = aa.groupby(['exchange', 'sta', 'colo', 'accCode', 'isMsg'])['internal_latency'].describe()[['mean', 'std']].reset_index()\n",
    "    aa1 = aa1.fillna(0)\n",
    "    aa = pd.merge(aa, aa1, on=['exchange', 'sta', 'colo', 'accCode', 'isMsg'])\n",
    "    for j in [1]:\n",
    "        aa[str(j) + 'std_low'] = aa['mean'] - j*aa['std']\n",
    "        aa[str(j) + 'std_high'] = aa['mean'] + j*aa['std']\n",
    "        aa['count1'] = np.where((aa['internal_latency'] <= aa[str(j) + 'std_high']) & (aa['internal_latency'] >= aa[str(j) + 'std_low']), 1, 0)\n",
    "        re1 = aa.groupby(['exchange', 'sta', 'colo', 'accCode', 'isMsg'])['count1'].sum().reset_index()\n",
    "        re2 = aa.groupby(['exchange', 'sta', 'colo', 'accCode', 'isMsg'])['count'].first().reset_index()\n",
    "        re1 = pd.merge(re2, re1, on=['exchange', 'sta', 'colo', 'accCode', 'isMsg'])\n",
    "        re1['count1'] = re1['count1'] / re1['count']\n",
    "        re1 = re1.rename(columns={'count1':str(j)+'*std'})\n",
    "    for j in [1.5, 2, 2.5, 3, 3.5, 4, 4.5]:\n",
    "        aa[str(j) + 'std_low'] = aa['mean'] - j*aa['std']\n",
    "        aa[str(j) + 'std_high'] = aa['mean'] + j*aa['std']\n",
    "        aa['count1'] = np.where((aa['internal_latency'] <= aa[str(j) + 'std_high']) & (aa['internal_latency'] >= aa[str(j) + 'std_low']), 1, 0)\n",
    "        re = aa.groupby(['exchange', 'sta', 'colo', 'accCode', 'isMsg'])['count1'].sum().reset_index()\n",
    "        re2 = aa.groupby(['exchange', 'sta', 'colo', 'accCode', 'isMsg'])['count'].first().reset_index()\n",
    "        re = pd.merge(re2, re, on=['exchange', 'sta', 'colo', 'accCode', 'isMsg'])\n",
    "        re['count1'] = re['count1'] / re['count']\n",
    "        re = re.rename(columns={'count1':str(j)+'*std'})\n",
    "        re1 = pd.merge(re1, re[['exchange', 'sta', 'colo', 'accCode', 'isMsg', str(j)+'*std']], on=['exchange', 'sta', 'colo', 'accCode', 'isMsg'])\n",
    "    nc = []\n",
    "    for i in range(0, re1.shape[0]):\n",
    "        nc.append(np.float(re1.columns[6:][(re1.iloc[i, 6:] == 1)][0].split('*')[0]))\n",
    "    re1['n'] = nc\n",
    "    print(re1.shape[0])\n",
    "    print(aa1.shape[0])\n",
    "    aa1 = pd.merge(aa1, re1[['exchange', 'sta', 'colo', 'accCode', 'isMsg', 'n']], on=['exchange', 'sta', 'colo', 'accCode', 'isMsg'])\n",
    "    aa1['min'] = aa1['mean'] - aa1['std'] * aa1['n']\n",
    "    aa1['max'] = aa1['mean'] + aa1['std'] * aa1['n']\n",
    "    report = pd.merge(report, aa1, on=['exchange', 'sta', 'colo', 'accCode', 'isMsg'], how='left')\n",
    "    assert(report[report['mean'].isnull()].shape[0] == 0)\n",
    "\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(report[((report['cur_med'] > report['max']) | (report['cur_med'] < report['min'])) \\\n",
    "                        & (report['cur_count'] > 100) & (abs(report['cur_med'] - report['prev_med']) > 20)] \\\n",
    "                 .groupby(['exchange', 'sta', 'colo', 'accCode', 'isMsg'])['prev_med', 'cur_med', 'prev_95p', 'cur_95p'].first().to_html()))\n",
    "    report = report[((report['cur_med'] > report['max']) | (report['cur_med'] < report['min'])) \\\n",
    "                        & (report['cur_count'] > 100) & (abs(report['cur_med'] - report['prev_med']) > 20)] \\\n",
    "                 .groupby(['exchange', 'sta', 'colo', 'accCode', 'isMsg'])['prev_med', 'cur_med', 'prev_95p', 'cur_95p'].first().reset_index()\n",
    "\n",
    "    body += '<div>In the following cases, internal latency under given accCode pass the hurdle we set:'\n",
    "    result = [report['exchange'].values, report['sta'].values, report['colo'].values, report['accCode'].values, report['isMsg'].values, \n",
    "             report['prev_med'].values, report['prev_95p'].values, report['cur_med'].values, report['cur_95p'].values]\n",
    "    title = ['exchange', 'sta', 'colo', 'accCode', 'isMsg', 'prev_med', 'prev_95p', 'cur_med', 'cur_95p']\n",
    "    body += convertToHtml(result,title)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    body += '<p><b>IV. tickToMBD</b></p>'\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "    import datetime\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    checkLog = orderLog[~orderLog['start_time'].isnull()]\n",
    "    checkLog = checkLog.drop_duplicates(['date', 'secid', 'Price', 'OrderQty', 'Side', 'statusLs', 'TradePriceLs', 'TradeQtyLs', 'ApplSeqNum'], keep=False)\n",
    "    checkLog = checkLog[~checkLog['accCode'].isnull()]\n",
    "    checkLog['tag'] = 'previous'\n",
    "    checkLog.loc[checkLog['date'] == orderLog['date'].max(), 'tag'] = 'current'\n",
    "\n",
    "    cc1 = checkLog\n",
    "    cc1 = cc1.reset_index(drop=True)\n",
    "    cc1['ordering'] = cc1.index\n",
    "    cc1['time_diff'] = cc1['caa_orderLog'] - cc1['start_time']\n",
    "    cc1['colo1'] = cc1['colo'].str[:2] + cc1['colo'].str[3:5] + cc1['colo'].str[6:8]\n",
    "    cc1['colo_broker'] = cc1['colo1'] + '_' + cc1[\"accCode\"].astype(int).astype(str)\n",
    "\n",
    "\n",
    "    re1 = cc1.groupby(['tag', 'sta', 'colo', 'accCode'])['time_diff'].describe().fillna(0).astype(int).reset_index()\n",
    "    # re1 = re1[re1['count'] > 20].reset_index()\n",
    "    c1 = cc1.groupby(['tag', 'sta', 'colo', 'accCode'])['time_diff'].apply(lambda x: x.describe([0.1])['10%']).astype(int).reset_index()\n",
    "    c1 = c1.rename(columns={\"time_diff\":\"10%\"})\n",
    "    re1 = pd.merge(re1, c1[['tag', 'sta', 'colo', 'accCode', '10%']], on=['tag', 'sta', 'colo', 'accCode'])\n",
    "    c1 = cc1.groupby(['tag', 'sta', 'colo', 'accCode'])['time_diff'].apply(lambda x: x.describe([0.9])['90%']).astype(int).reset_index()\n",
    "    c1 = c1.rename(columns={\"time_diff\":\"90%\"})\n",
    "    re1 = pd.merge(re1, c1[['tag', 'sta', 'colo', 'accCode', '90%']], on=['tag', 'sta', 'colo', 'accCode'])\n",
    "    ree1 = re1[re1['tag'] == 'previous']\n",
    "    ree1 = ree1.rename(columns={'50%':'prev_med', 'count':'prev_count'})\n",
    "    ree2 = re1[re1['tag'] == 'current']\n",
    "    ree2 = ree2.rename(columns={'50%':'cur_med', 'count':'cur_count'})\n",
    "    report = pd.merge(ree1[['sta', 'colo', 'accCode', 'prev_count', 'prev_med']], \n",
    "                   ree2[['sta', 'colo', 'accCode', 'cur_count', 'cur_med']], on=['sta', 'colo', 'accCode'])\n",
    "\n",
    "\n",
    "    aa = cc1[(cc1['updateType'] == 0) & (cc1['tag'] == 'previous')].groupby(['date', 'sta', 'colo', 'accCode'])['time_diff'].median().reset_index()\n",
    "    aa['count'] = aa.groupby(['sta', 'colo', 'accCode'])['date'].transform('nunique')\n",
    "    aa1 = aa.groupby(['sta', 'colo', 'accCode'])['time_diff'].describe()[['mean', 'std']].reset_index()\n",
    "    aa1 = aa1.fillna(0)\n",
    "    aa = pd.merge(aa, aa1, on=['sta', 'colo', 'accCode'])\n",
    "    for j in [1]:\n",
    "        aa[str(j) + 'std_low'] = aa['mean'] - j*aa['std']\n",
    "        aa[str(j) + 'std_high'] = aa['mean'] + j*aa['std']\n",
    "        aa['count1'] = np.where((aa['time_diff'] <= aa[str(j) + 'std_high']) & (aa['time_diff'] >= aa[str(j) + 'std_low']), 1, 0)\n",
    "        re1 = aa.groupby(['sta', 'colo', 'accCode'])['count1'].sum().reset_index()\n",
    "        re2 = aa.groupby(['sta', 'colo', 'accCode'])['count'].first().reset_index()\n",
    "        re1 = pd.merge(re2, re1, on=['sta', 'colo', 'accCode'])\n",
    "        re1['count1'] = re1['count1'] / re1['count']\n",
    "        re1 = re1.rename(columns={'count1':str(j)+'*std'})\n",
    "    for j in [1.5, 2, 2.5, 3, 3.5, 4, 4.5]:\n",
    "        aa[str(j) + 'std_low'] = aa['mean'] - j*aa['std']\n",
    "        aa[str(j) + 'std_high'] = aa['mean'] + j*aa['std']\n",
    "        aa['count1'] = np.where((aa['time_diff'] <= aa[str(j) + 'std_high']) & (aa['time_diff'] >= aa[str(j) + 'std_low']), 1, 0)\n",
    "        re = aa.groupby(['sta', 'colo', 'accCode'])['count1'].sum().reset_index()\n",
    "        re2 = aa.groupby(['sta', 'colo', 'accCode'])['count'].first().reset_index()\n",
    "        re = pd.merge(re2, re, on=['sta', 'colo', 'accCode'])\n",
    "        re['count1'] = re['count1'] / re['count']\n",
    "        re = re.rename(columns={'count1':str(j)+'*std'})\n",
    "        re1 = pd.merge(re1, re[['sta', 'colo', 'accCode', str(j)+'*std']], on=['sta', 'colo', 'accCode'])\n",
    "    nc = []\n",
    "    for i in range(0, re1.shape[0]):\n",
    "        nc.append(np.float(re1.columns[6:][(re1.iloc[i, 6:] == 1)][0].split('*')[0]))\n",
    "    re1['n'] = nc\n",
    "    print(re1.shape[0])\n",
    "    print(aa1.shape[0])\n",
    "    aa1 = pd.merge(aa1, re1[['sta', 'colo', 'accCode', 'n']], on=['sta', 'colo', 'accCode'])\n",
    "    aa1['min'] = aa1['mean'] - aa1['std'] * aa1['n']\n",
    "    aa1['max'] = aa1['mean'] + aa1['std'] * aa1['n']\n",
    "    report = pd.merge(report, aa1, on=['sta', 'colo', 'accCode'], how='left')\n",
    "    assert(report[report['mean'].isnull()].shape[0] == 0)\n",
    "\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(report[((report['cur_med'] > report['max']) | (report['cur_med'] < report['min'])) \\\n",
    "                        & (report['cur_count'] > 100) & (abs(report['cur_med'] - report['prev_med']) > 1000)] \\\n",
    "                 .groupby(['sta', 'colo', 'accCode'])['prev_med', 'cur_med'].first().to_html()))\n",
    "    report = report[((report['cur_med'] > report['max']) | (report['cur_med'] < report['min'])) \\\n",
    "                        & (report['cur_count'] > 100) & (abs(report['cur_med'] - report['prev_med']) > 1000)] \\\n",
    "                 .groupby(['sta', 'colo', 'accCode'])['prev_med', 'cur_med'].first().reset_index()\n",
    "    body += '<div>In the following cases, tickToMBD under given accCode pass the hurdle we set:<div>'\n",
    "    result = [report['sta'].values, report['colo'].values, report['accCode'].values,\n",
    "             report['prev_med'].values, report['cur_med'].values]\n",
    "    title = ['sta', 'colo', 'accCode', 'prev_med', 'cur_med']\n",
    "    body += convertToHtml(result,title)\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "    import datetime\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    body += '<p><b>V. order return</b></p>'\n",
    "    checkLog = orderLog[orderLog['updateType'] == 4]\n",
    "    if checkLog[checkLog['absFilledThisUpdate'] == 0].shape[0] != 0:\n",
    "        print('There are stocks with zero trade size')\n",
    "        print(checkLog[checkLog['absFilledThisUpdate'] == 0].groupby(['colo', 'accCode'])['secid'].size())\n",
    "        checkLog = checkLog[checkLog['absFilledThisUpdate'] != 0]\n",
    "    if checkLog[checkLog['beta_60'].isnull()].shape[0] != 0:\n",
    "        print('There are stocks with null beta')\n",
    "        print(checkLog[checkLog['beta_60'].isnull()])\n",
    "        checkLog = checkLog[~checkLog['beta_60'].isnull()]\n",
    "    checkLog['max_trade'] = checkLog.groupby('order')['absOrderSizeCumFilled'].transform('max')\n",
    "    checkLog['last'] = 0\n",
    "    checkLog.loc[checkLog['max_trade'] == checkLog['absOrderSizeCumFilled'], 'last'] = 1\n",
    "    checkLog[\"buyRet\"] = np.where(checkLog[\"orderDirection\"].isin([1, 2]), checkLog[\"adjMid_F90s\"] / checkLog[\"tradePrice\"] - 1, np.nan)\n",
    "    checkLog[\"buyRet1\"] = np.where(checkLog[\"orderDirection\"].isin([1, 2]), checkLog[\"adjMid_F300s\"] / checkLog[\"tradePrice\"] - 1, np.nan)\n",
    "    checkLog[\"sellRet\"] = np.where(checkLog[\"orderDirection\"].isin([-1, -2]), checkLog[\"tradePrice\"] / checkLog[\"adjMid_F90s\"] - 1, np.nan)\n",
    "    checkLog[\"sellRet1\"] = np.where(checkLog[\"orderDirection\"].isin([-1, -2]), checkLog[\"tradePrice\"] / checkLog[\"adjMid_F300s\"] - 1, np.nan)\n",
    "    checkLog[\"buyNum\"] = np.where((checkLog[\"orderDirection\"].isin([1, 2])) & (checkLog['last'] == 1), 1, 0)\n",
    "    checkLog[\"sellNum\"] = np.where((checkLog[\"orderDirection\"].isin([-1, -2])) & (checkLog['last'] == 1), 1, 0)\n",
    "    checkLog[\"server\"] = checkLog[\"colo\"].apply(lambda x: x.split(\"_\")[0] + x.split(\"_\")[1] + x.split(\"_\")[2])\n",
    "    checkLog[\"server_account\"] = checkLog[\"server\"] + '_' + checkLog['accCode'].astype('str')\n",
    "    df = checkLog[(checkLog['ars']%10 == 1)]\n",
    "\n",
    "    df['tradeNtl'] = df['tradePrice']*df['absFilledThisUpdate']\n",
    "    df[\"buyNtl\"] = np.where(~df[\"buyRet\"].isnull(), df[\"tradeNtl\"], np.nan)\n",
    "    df[\"sellNtl\"] = np.where(~df[\"sellRet\"].isnull(), df[\"tradeNtl\"], np.nan)\n",
    "    df[\"sumbuyNtl\"] = df.groupby([\"date\", \"exchange\", \"sta\", \"server_account\"])[\"buyNtl\"].transform(sum)\n",
    "    df[\"sumsellNtl\"] = df.groupby([\"date\", \"exchange\", \"sta\", \"server_account\"])[\"sellNtl\"].transform(sum)\n",
    "\n",
    "    df[\"sumsellRet\"] = df[\"tradeNtl\"] * df[\"sellRet\"]\n",
    "    df[\"sumsellRet\"] = df.groupby([\"date\", \"exchange\", \"sta\", \"server_account\"])[\"sumsellRet\"].transform(sum)\n",
    "\n",
    "\n",
    "    df[\"sumbuyRet\"] = df[\"tradeNtl\"] * df[\"buyRet\"]\n",
    "    df[\"sumbuyRet\"] = df.groupby([\"date\", \"exchange\", \"sta\", \"server_account\"])[\"sumbuyRet\"].transform(sum)\n",
    "\n",
    "    df[\"buyRet\"] = df[\"sumbuyRet\"] / df[\"sumbuyNtl\"]\n",
    "    df[\"sellRet\"] = df[\"sumsellRet\"] / df[\"sumsellNtl\"]\n",
    "    df[\"buyOrderNum\"] = df.groupby([\"date\", \"exchange\", \"sta\", \"server_account\"])[\"buyNum\"].transform(sum)\n",
    "    df[\"sellOrderNum\"] = df.groupby([\"date\", \"exchange\", \"sta\", \"server_account\"])[\"sellNum\"].transform(sum)\n",
    "\n",
    "\n",
    "    from IPython.display import display, HTML\n",
    "    for col in [\"buyRet\", \"sellRet\"]:\n",
    "        df[col] = (df[col] * 10000).round(2)\n",
    "\n",
    "    re = df.groupby([\"exchange\", \"date\", \"sta\", \"server_account\"])[\"buyOrderNum\", \"buyRet\", \"sellOrderNum\", \"sellRet\"].first().reset_index()\n",
    "    re1 = re[(re['sellRet'] < -20) & (re['sellOrderNum'] > 100)]\n",
    "    re2 = re[(re['buyRet'] < -20) & (re['buyOrderNum'] > 100)]\n",
    "\n",
    "    display(HTML(re1.groupby([\"exchange\", 'date', 'sta', \"server_account\"])[['sellOrderNum', 'sellRet']].first().to_html()))\n",
    "    display(HTML(re2.groupby([\"exchange\", 'date', 'sta', \"server_account\"])[['buyOrderNum', 'buyRet']].first().to_html()))\n",
    "    pr1 = re1[re1['date'] == checkLog['date'].max()].groupby([\"exchange\", 'date', 'sta', \"server_account\"])[['sellOrderNum', 'sellRet']].first().reset_index()\n",
    "    pr2 = re2[re2['date'] == checkLog['date'].max()].groupby([\"exchange\", 'date', 'sta', \"server_account\"])[['buyOrderNum', 'buyRet']].first().reset_index()\n",
    "\n",
    "    if pr1.shape[0] != 0:\n",
    "        body += '<div>In the following cases, sell order return under given strategy and accCode < -20bps:<div>'\n",
    "        result = [pr1['exchange'].values, pr1['date'].values, pr1['sta'].values,\n",
    "                 pr1['server_account'].values, pr1['sellOrderNum'].values, pr1['sellRet'].values]\n",
    "        title = ['exchange', 'date', 'sta', 'server_account', 'sellOrderNum', 'sellRet']\n",
    "        body += convertToHtml(result,title)\n",
    "\n",
    "    if pr2.shape[0] != 0:\n",
    "        body += '<div>In the following cases, buy order return under given strategy and accCode < -20bps:<div>'\n",
    "        result = [pr2['exchange'].values, pr2['date'].values, pr2['sta'].values,\n",
    "                 pr2['server_account'].values, pr2['buyOrderNum'].values, pr2['buyRet'].values]\n",
    "        title = ['exchange', 'date', 'sta', 'server_account', 'buyOrderNum', 'buyRet']\n",
    "        body += convertToHtml(result,title)\n",
    "\n",
    "    pr1 = re1.groupby(['exchange', 'sta', 'server_account'])['date'].size()[\n",
    "        re1.groupby(['exchange', 'sta', 'server_account'])['date'].size() >= 2].reset_index().sort_values(by='date', ascending=False)\n",
    "    pr2 = re2.groupby(['exchange', 'sta', 'server_account'])['date'].size()[\n",
    "        re2.groupby(['exchange', 'sta', 'server_account'])['date'].size() >= 2].reset_index().sort_values(by='date', ascending=False)\n",
    "    add1 = pd.merge(re, pr1, on=['exchange', 'sta', 'server_account'], how='inner')\n",
    "    add1 = add1[(add1['sellRet'] < -20) & (add1['sellOrderNum'] > 100)]\n",
    "    add2 = pd.merge(re, pr2, on=['exchange', 'sta', 'server_account'], how='inner')\n",
    "    add2 = add2[(add2['buyRet'] < -20) & (add2['buyOrderNum'] > 100)]\n",
    "    \n",
    "    if add1.shape[0] != 0:\n",
    "        add1 = add1.groupby(['exchange', 'sta', 'server_account'])['sellRet'].describe()[['count', 'mean', 'min', 'max']].reset_index().sort_values(by='count', ascending=False)\n",
    "        for i in ['mean', 'min', 'max']:\n",
    "            add1[i] = add1[i].round(2)\n",
    "        for i in ['count']:\n",
    "            add1[i] = add1[i].astype(int)\n",
    "        body += '<div>In the following cases, more than 2 days sell order return under given strategy and accCode < -20bps in previous 10 days (include today):<div>'\n",
    "        result = [add1['exchange'].values, add1['sta'].values,\n",
    "                 add1['server_account'].values, add1['count'].values, add1['mean'].values, add1['min'].values, add1['max'].values]\n",
    "        title = ['exchange', 'sta', 'server_account', 'count', 'mean', 'min', 'max']\n",
    "        body += convertToHtml(result,title)\n",
    "\n",
    "    if add2.shape[0] != 0:\n",
    "        add2 = add2.groupby(['exchange', 'sta', 'server_account'])['buyRet'].describe()[['count', 'mean', 'min', 'max']].reset_index().sort_values(by='count', ascending=False)\n",
    "        for i in ['mean', 'min', 'max']:\n",
    "            add2[i] = add2[i].round(2)\n",
    "        for i in ['count']:\n",
    "            add2[i] = add2[i].astype(int)\n",
    "        body += '<div>In the following cases, more than 2 days buy order return under given strategy and accCode < -20bps in previous 10 days (include today):<div>'\n",
    "        result = [add2['exchange'].values, add2['sta'].values,\n",
    "                 add2['server_account'].values, add2['count'].values, add2['mean'].values, add2['min'].values, add2['max'].values]\n",
    "        title = ['exchange', 'sta', 'server_account', 'count', 'mean', 'min', 'max']\n",
    "        body += convertToHtml(result,title)\n",
    "    \n",
    "    \n",
    "    import smtplib\n",
    "    from email.mime.text import MIMEText\n",
    "    from email.mime.multipart import MIMEMultipart    \n",
    "    \n",
    "    title = str(orderLog['date'].max()) + ' daily report'\n",
    "    body = body + \"</div></body></html>\"\n",
    "    smtp_server = '42.120.226.4' # 'smtp.mxhichina.com'\n",
    "    user = 'zhenyu.yin@general-int.com'\n",
    "    passwd = 'Yqzy0063!'\n",
    "    from_addr = 'zhenyu.yin@general-int.com'\n",
    "    to_addr = ['zhenyu.yin@general-int.com', 'kevin.zhang@general-int.com']\n",
    "#     to_addr = ['zhenyu.yin@general-int.com']\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = from_addr\n",
    "    msg['To'] = ', '.join(to_addr)\n",
    "    msg['Subject'] = title\n",
    "    txt = MIMEText(body, _subtype='html', _charset='UTF-8')\n",
    "    msg.attach(txt)\n",
    "\n",
    "    smtp = None\n",
    "    while True:\n",
    "        try:\n",
    "            smtp = smtplib.SMTP(smtp_server)\n",
    "            print('smtp server connected')\n",
    "            smtp.login(user, passwd)\n",
    "            print('login')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    print('send mail')\n",
    "    smtp.sendmail(from_addr, to_addr, msg.as_string())\n",
    "    smtp.quit()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "from twisted.internet import task, reactor\n",
    "import schedule\n",
    "\n",
    "\n",
    "def sleeptime(hour,min,sec):\n",
    "    return hour*3600 + min*60 + sec\n",
    "\n",
    "\n",
    "class Test(object):\n",
    "    def __init__(self):\n",
    "        self.status = True        \n",
    "    def test(self):\n",
    "        while self.status == True:\n",
    "            try:\n",
    "                print(datetime.datetime.now())\n",
    "#                 date = (datetime.datetime.today()).strftime('%Y%m%d')\n",
    "                date = '20210113'\n",
    "                readPath = '/mnt/orderLog/data/***'\n",
    "                dataPathLs = np.array(glob.glob(readPath))\n",
    "                dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "                assert(np.max(dateLs) == int(date))\n",
    "                print('We start to generate report now')\n",
    "                generate_report(date)\n",
    "                self.status = False\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('still wait for data coming')  \n",
    "                second = sleeptime(0,5,0)\n",
    "                time.sleep(second)\n",
    "\n",
    "test1 = Test()\n",
    "schedule.every().day.at(\"22:03\").do(test1.test)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

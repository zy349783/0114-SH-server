{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:23.801086\n",
      "0:00:44.008296\n",
      "0:01:22.106863\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'d_cum_amount_y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'd_cum_amount_y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b9f979c69641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"d_cum_amount_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'd_cum_amount_y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'd_cum_amount_y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b9f979c69641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"d_cum_amount_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0mwr_ong\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"d_amount_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartTm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'd_cum_amount_y'"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "    \n",
    "    def read_daily(self, table_name, start_date=None, end_date=None, skey=None, index_id=None, interval=None, index_name=None, col=None, return_sdi=True): \n",
    "        collection = self.db[table_name]\n",
    "        # Build projection \n",
    "        prj = {'_id': 0} \n",
    "        if col is not None: \n",
    "            if return_sdi: \n",
    "                col = ['skey', 'date', 'index_id'] + col \n",
    "            for col_name in col: \n",
    "                prj[col_name] = 1 \n",
    "        # Build query \n",
    "        query = {} \n",
    "        if skey is not None: \n",
    "            query['skey'] = {'$in': skey} \n",
    "        if interval is not None: \n",
    "            query['interval'] = {'$in': interval} \n",
    "        if index_id is not None: \n",
    "            query['index_id'] = {'$in': index_id}    \n",
    "        if index_name is not None:\n",
    "            n = '' \n",
    "            for name in index_name: \n",
    "                try: \n",
    "                    name = re.compile('[\\u4e00-\\u9fff]+').findall(name)[0] \n",
    "                    if len(n) == 0: \n",
    "                        n = n = \"|\".join(name) \n",
    "                    else: \n",
    "                        n = n + '|' + \"|\".join(name) \n",
    "                except: \n",
    "                    if len(n) == 0: \n",
    "                        n = name \n",
    "                    else: \n",
    "                        n = n + '|' + name \n",
    "            query['index_name'] = {'$regex': n}\n",
    "        if start_date is not None: \n",
    "            if end_date is not None: \n",
    "                query['date'] = {'$gte': start_date, '$lte': end_date} \n",
    "            else: \n",
    "                query['date'] = {'$gte': start_date} \n",
    "        elif end_date is not None: \n",
    "            query['date'] = {'$lte': end_date} \n",
    "        # Load data \n",
    "        cur = collection.find(query, prj) \n",
    "        df = pd.DataFrame.from_records(cur) \n",
    "        if df.empty: \n",
    "            df = pd.DataFrame() \n",
    "        else:\n",
    "            if 'index_id' in df.columns:\n",
    "                df = df.sort_values(by=['date', 'index_id', 'skey']).reset_index(drop=True)\n",
    "            else:\n",
    "                df = df.sort_values(by=['date','skey']).reset_index(drop=True)\n",
    "        return df \n",
    " \n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "\n",
    "startDate = '20140102'\n",
    "endDate = '20140102'\n",
    "readPath = '/mnt/SH1/x64release/Tick/SH/***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "wr_ong = []\n",
    "mi_ss = []\n",
    "less = []\n",
    "\n",
    "for data in np.sort(dataPathLs)[::-1]:\n",
    "    readPath = data + '/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dataPathLs = np.array([i for i in dataPathLs if os.path.basename(i)[0] != 'H'])\n",
    "    dateLs = np.array([int(os.path.basename(i).split('.')[0]) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[((dateLs >= 600000) & (dateLs <= 700000))]\n",
    "    SH = []\n",
    "    ll = []\n",
    "    startTm = datetime.datetime.now()\n",
    "    for i in dataPathLs:\n",
    "        try:\n",
    "            df = pd.read_csv(i, encoding='GBK')\n",
    "        except:\n",
    "            print(\"empty data\")\n",
    "            print(i)\n",
    "            ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "            continue\n",
    "        SH += [df]\n",
    "    del df\n",
    "    SH = pd.concat(SH).reset_index(drop=True)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"skey\"] = SH[\"code\"] + 1000000\n",
    "    SH.drop([\"code\"],axis=1,inplace=True)\n",
    "    SH['clockAtArrival'] = SH['date'] * 1000000000 + SH['time']\n",
    "    SH[\"clockAtArrival\"] = SH[\"clockAtArrival\"].astype(str).apply(lambda x: np.int64(datetime.datetime.strptime(x, '%Y%m%d%H%M%S%f').timestamp()*1e6))\n",
    "    SH['datetime'] = SH[\"clockAtArrival\"].apply(lambda x: datetime.datetime.fromtimestamp(x/1e6))\n",
    "    SH['time'] = SH['time'] * 1000\n",
    "    print(datetime.datetime.now() - startTm)    \n",
    "    \n",
    "    for i in range(1, 11):\n",
    "        SH = SH.rename(columns={'ask'+str(i):'ask'+str(i)+'p', 'asize'+str(i):'ask'+str(i)+'q', \\\n",
    "                            'bid'+str(i):'bid'+str(i)+'p', 'bsize'+str(i):'bid'+str(i)+'q'})\n",
    "    SH = SH.rename(columns={'accvolume':'cum_volume', 'accturover':'cum_amount', 'match_items':'cum_trades_cnt', 'price':'close',\n",
    "                       'pre_close':'prev_close'})\n",
    "    SH = SH.fillna(0)\n",
    "    SH[\"ordering\"] = SH.groupby(\"skey\").cumcount()\n",
    "    SH[\"ordering\"] = SH[\"ordering\"] + 1\n",
    "    \n",
    "    SH[\"has_missing\"] = 0\n",
    "    \n",
    "    for col in [\"skey\", \"date\", \"cum_trades_cnt\", 'ordering']:\n",
    "        SH[col] = SH[col].astype('int32')\n",
    "    \n",
    "    for cols in [\"prev_close\", 'open', \"high\", \"low\", \"close\", 'bid10p','bid9p','bid8p','bid7p','bid6p','bid5p','bid4p','bid3p',\n",
    "             'bid2p','bid1p','ask1p','ask2p','ask3p','ask4p','ask5p','ask6p','ask7p','ask8p','ask9p','ask10p']:\n",
    "        SH[cols] = SH[cols] / 10000\n",
    "        \n",
    "    assert(sum(SH[SH[\"open\"] != 0].groupby(\"skey\")[\"open\"].nunique() != 1) == 0)\n",
    "    assert(sum(SH[SH[\"prev_close\"] != 0].groupby(\"skey\")[\"prev_close\"].nunique() != 1) == 0)\n",
    "    SH[\"prev_close\"] = np.where(SH[\"time\"] >= 91500000000, SH.groupby(\"skey\")[\"prev_close\"].transform(\"max\"), SH[\"prev_close\"]) \n",
    "    SH[\"open\"] = np.where(SH[\"cum_volume\"] > 0, SH.groupby(\"skey\")[\"open\"].transform(\"max\"), SH[\"open\"])\n",
    "    assert(sum(SH[SH[\"open\"] != 0].groupby(\"skey\")[\"open\"].nunique() != 1) == 0)\n",
    "    assert(sum(SH[SH[\"prev_close\"] != 0].groupby(\"skey\")[\"prev_close\"].nunique() != 1) == 0)\n",
    "    assert(SH[SH[\"cum_volume\"] > 0][\"open\"].min() > 0)\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    # check 1\n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "    tr = db1.read_daily('mdbar1d_tr', int(SH['date'].iloc[0]), int(SH['date'].iloc[0]))\n",
    "    tr = tr.rename(columns={'closeL1':'prev_close', 'volume':'cum_volume', 'amount':'cum_amount'})\n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"cum_max\"] = SH.groupby(\"skey\")[\"cum_volume\"].transform(max)\n",
    "    s2 = SH[SH[\"cum_volume\"] == SH[\"cum_max\"]].groupby(\"skey\").first().reset_index()\n",
    "    SH.drop(\"cum_max\", axis=1, inplace=True)\n",
    "    tr = tr[[\"skey\", \"date\", \"open\", \"prev_close\", \"high\", \"low\", \"close\", \"cum_volume\", \"cum_amount\"]]\n",
    "    s2 = s2[[\"skey\", \"date\", \"open\", \"prev_close\", \"high\", \"low\", \"close\", \"cum_volume\", \"cum_amount\"]]\n",
    "    tr = tr[(tr['skey'] >= 1600000) & (tr['skey'] < 1700000)]\n",
    "    re = pd.merge(tr, s2, on=[\"skey\", \"date\", \"open\", \"prev_close\", \"high\", \"low\", \"close\", \"cum_volume\"], how=\"outer\")\n",
    "    try:\n",
    "        assert(sum(re[\"cum_amount_y\"].isnull()) == 0)\n",
    "    except:\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(re[re[\"cum_amount_y\"].isnull()])\n",
    "        wr_ong += [re[re[\"cum_amount_y\"].isnull()]]\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "#     # check 2\n",
    "#     # first part\n",
    "#     startTm = datetime.datetime.now()\n",
    "#     date = pd.DataFrame(pd.date_range(start='2019-06-10 08:30:00', end='2019-06-10 18:00:00', freq='s'), columns=[\"Orig\"])\n",
    "#     date[\"time\"] = date[\"Orig\"].apply(lambda x: int(x.strftime(\"%H%M%S\"))*1000)\n",
    "#     date[\"group\"] = date[\"time\"]//10000\n",
    "#     SH[\"group\"] = SH[\"time\"]//10000000\n",
    "#     gl = date[((date[\"time\"] >= 93000000) & (date[\"time\"] < 113000000))|((date[\"time\"] >= 130000000) & (date[\"time\"] <= 150000000))][\"group\"].unique()\n",
    "#     l = set(gl) - set(SH[\"group\"].unique())\n",
    "#     SH[\"has_missing1\"] = 0 \n",
    "#     if len(l) != 0:\n",
    "#         print(\"massive missing\")\n",
    "#         print(l)\n",
    "#         SH[\"order\"] = SH.groupby([\"skey\", \"time\"]).cumcount()\n",
    "#         for i in l:\n",
    "#             SH[\"t\"] = SH[SH[\"group\"] > i].groupby(\"skey\")[\"time\"].transform(\"min\")\n",
    "#             SH[\"has_missing1\"] = np.where((SH[\"time\"] == SH[\"t\"]) & (SH[\"order\"] == 0), 1, 0)\n",
    "#         SH.drop([\"order\", \"t\", \"group\"], axis=1, inplace=True)   \n",
    "#     else:\n",
    "#         print(\"no massive missing\")\n",
    "#         SH.drop([\"group\"], axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#     # second part\n",
    "\n",
    "#     SH[\"time_interval\"] = SH.groupby(\"skey\")[\"datetime\"].apply(lambda x: x - x.shift(1))\n",
    "#     SH[\"time_interval\"] = SH[\"time_interval\"].apply(lambda x: x.seconds)\n",
    "#     SH[\"tn_update\"] = SH.groupby(\"skey\")[\"cum_trades_cnt\"].apply(lambda x: x-x.shift(1))\n",
    "\n",
    "#     f1 = SH[(SH[\"time\"] >= 93000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "#     f1 = f1.rename(columns={\"time\": \"time1\"})\n",
    "#     f2 = SH[(SH[\"time\"] >= 130000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "#     f2 = f2.rename(columns={\"time\": \"time2\"})\n",
    "#     f3 = SH[(SH[\"time\"] >= 150000000000) & (SH[\"tn_update\"] != 0)].groupby(\"skey\")[\"time\"].min().reset_index()\n",
    "#     f3 = f3.rename(columns={\"time\": \"time3\"})\n",
    "#     SH = pd.merge(SH, f1, on=\"skey\", how=\"left\")\n",
    "#     del f1\n",
    "#     SH = pd.merge(SH, f2, on=\"skey\", how=\"left\")\n",
    "#     del f2\n",
    "#     SH = pd.merge(SH, f3, on=\"skey\", how=\"left\")\n",
    "#     del f3\n",
    "#     p99 = SH[(SH[\"time\"] > 93000000000) & (SH[\"time\"] < 145700000000) & (SH[\"time\"] != SH[\"time2\"]) & (SH[\"tn_update\"] != 0)]\\\n",
    "#     .groupby(\"skey\")[\"tn_update\"].apply(lambda x: x.describe([0.99])[\"99%\"]).round(0).reset_index()\n",
    "#     p99 = p99.rename(columns={\"tn_update\":\"99%\"})\n",
    "#     SH = pd.merge(SH, p99, on=\"skey\", how=\"left\")\n",
    "\n",
    "#     SH[\"has_missing2\"] = 0\n",
    "#     SH[\"has_missing2\"] = np.where((SH[\"time_interval\"] > 60) & (SH[\"tn_update\"] > SH[\"99%\"]) & \n",
    "#          (SH[\"time\"] > SH[\"time1\"]) & (SH[\"time\"] != SH[\"time2\"]) & (SH[\"time\"] != SH[\"time3\"]) & (SH[\"time\"] != 100000000000), 1, 0)\n",
    "#     SH.drop([\"time_interval\", \"tn_update\", \"time1\", \"time2\", \"time3\", \"99%\"], axis=1, inplace=True) \n",
    "\n",
    "#     SH[\"has_missing\"] = np.where((SH[\"has_missing1\"] == 1) | (SH[\"has_missing2\"] == 1), 1, 0)\n",
    "#     SH.drop([\"has_missing1\", \"has_missing2\"], axis=1, inplace=True) \n",
    "#     if SH[SH[\"has_missing\"] == 1].shape[0] != 0:\n",
    "#         print(\"has missing!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "#         print(SH[SH[\"has_missing\"] == 1].shape[0])\n",
    "#         mi_ss += [SH[SH[\"has_missing\"] == 1]]\n",
    "#     print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     startTm = datetime.datetime.now()\n",
    "#     SH[\"has_missing\"] = SH[\"has_missing\"].astype('int32')\n",
    "#     SH = SH[[\"skey\", \"date\", \"time\", \"clockAtArrival\", \"datetime\", \"ordering\", \"has_missing\", \"cum_trades_cnt\", \"cum_volume\", \"cum_amount\", \"prev_close\",\n",
    "#                             \"open\", \"high\", \"low\", \"close\", 'bid10p','bid9p','bid8p','bid7p','bid6p','bid5p','bid4p','bid3p','bid2p','bid1p',\n",
    "#                             'ask1p','ask2p','ask3p','ask4p','ask5p','ask6p','ask7p','ask8p','ask9p','ask10p', 'bid10q','bid9q','bid8q',\n",
    "#                              'bid7q','bid6q','bid5q','bid4q','bid3q','bid2q','bid1q', 'ask1q','ask2q','ask3q','ask4q','ask5q','ask6q',\n",
    "#                              'ask7q','ask8q','ask9q','ask10q']]\n",
    "    \n",
    "#     display(SH[\"date\"].iloc[0])\n",
    "#     print(\"SH finished\")\n",
    "    \n",
    "#     database_name = 'com_md_eq_cn'\n",
    "#     user = \"zhenyuy\"\n",
    "#     password = \"bnONBrzSMGoE\"\n",
    "\n",
    "#     db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "#     db1.write('md_snapshot_l2', SH)\n",
    "    \n",
    "#     del SH\n",
    "#     print(datetime.datetime.now() - startTm)\n",
    "\n",
    "# wr_ong = pd.concat(wr_ong).reset_index(drop=True)\n",
    "# print(wr_ong)\n",
    "# mi_ss = pd.concat(mi_ss).reset_index(drop=True)\n",
    "# print(mi_ss)\n",
    "# print(less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "    tr = db1.read_daily('mdbar1d_tr', int(SH['date'].iloc[0]), int(SH['date'].iloc[0]))\n",
    "    tr = tr.rename(columns={'closeL1':'prev_close', 'volume':'cum_volume', 'amount':'cum_amount'})\n",
    "    startTm = datetime.datetime.now()\n",
    "    SH[\"cum_max\"] = SH.groupby(\"skey\")[\"cum_volume\"].transform(max)\n",
    "    s2 = SH[SH[\"cum_volume\"] == SH[\"cum_max\"]].groupby(\"skey\").last().reset_index()\n",
    "    SH.drop(\"cum_max\", axis=1, inplace=True)\n",
    "    tr = tr[[\"skey\", \"date\", \"open\", \"prev_close\", \"high\", \"low\", \"close\", \"cum_volume\", \"cum_amount\"]]\n",
    "    s2 = s2[[\"skey\", \"date\", \"open\", \"prev_close\", \"high\", \"low\", \"close\", \"cum_volume\", \"cum_amount\"]]\n",
    "    tr = tr[tr['skey'].isin(s2['skey'].unique())]\n",
    "    re = pd.merge(tr, s2, on=[\"skey\", \"date\", \"open\", \"prev_close\", \"high\", \"low\", \"close\", \"cum_volume\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SH = []\n",
    "for i in dataPathLs:\n",
    "    try:\n",
    "        df = pd.read_csv(i, encoding='GBK')\n",
    "    except:\n",
    "        print(\"empty data\")\n",
    "        print(i)\n",
    "        ll.append(int(os.path.basename(i).split('.')[0]))\n",
    "        continue\n",
    "    SH += [df]\n",
    "del df\n",
    "SH = pd.concat(SH).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>cum_volume</th>\n",
       "      <th>cum_amount_x</th>\n",
       "      <th>cum_amount_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>1600051</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>1600053</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>1600057</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>1600058</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>1600063</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>1600074</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>1600141</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>1600146</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>1600217</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>1600234</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>1600243</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>1600275</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>1600370</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1600381</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>1600444</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>1600485</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>1600572</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>1600576</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>1600599</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>1600603</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>1600606</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>1600639</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>1600652</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>1600686</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>1600727</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>1600732</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>1600734</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>1600856</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>1601012</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>1601901</td>\n",
       "      <td>20140102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        skey      date  open  prev_close  high  low  close  cum_volume  \\\n",
       "942  1600051  20140102   0.0        6.71   0.0  0.0    0.0           0   \n",
       "943  1600053  20140102   0.0        6.19   0.0  0.0    0.0           0   \n",
       "944  1600057  20140102   0.0        6.81   0.0  0.0    0.0           0   \n",
       "945  1600058  20140102   0.0       13.56   0.0  0.0    0.0           0   \n",
       "946  1600063  20140102   0.0        2.07   0.0  0.0    0.0           0   \n",
       "947  1600074  20140102   0.0        4.14   0.0  0.0    0.0           0   \n",
       "948  1600141  20140102   0.0       12.48   0.0  0.0    0.0           0   \n",
       "949  1600146  20140102   0.0        9.45   0.0  0.0    0.0           0   \n",
       "950  1600217  20140102   0.0        4.84   0.0  0.0    0.0           0   \n",
       "951  1600234  20140102   0.0        5.77   0.0  0.0    0.0           0   \n",
       "952  1600243  20140102   0.0        6.52   0.0  0.0    0.0           0   \n",
       "953  1600275  20140102   0.0        5.17   0.0  0.0    0.0           0   \n",
       "954  1600370  20140102   0.0        4.54   0.0  0.0    0.0           0   \n",
       "955  1600381  20140102   0.0        2.08   0.0  0.0    0.0           0   \n",
       "956  1600444  20140102   0.0       12.28   0.0  0.0    0.0           0   \n",
       "957  1600485  20140102   0.0       20.51   0.0  0.0    0.0           0   \n",
       "958  1600572  20140102   0.0       13.51   0.0  0.0    0.0           0   \n",
       "959  1600576  20140102   0.0        7.23   0.0  0.0    0.0           0   \n",
       "960  1600599  20140102   0.0        9.76   0.0  0.0    0.0           0   \n",
       "961  1600603  20140102   0.0        5.26   0.0  0.0    0.0           0   \n",
       "962  1600606  20140102   0.0        5.23   0.0  0.0    0.0           0   \n",
       "963  1600639  20140102   0.0       11.76   0.0  0.0    0.0           0   \n",
       "964  1600652  20140102   0.0        4.07   0.0  0.0    0.0           0   \n",
       "965  1600686  20140102   0.0        8.73   0.0  0.0    0.0           0   \n",
       "966  1600727  20140102   0.0        4.64   0.0  0.0    0.0           0   \n",
       "967  1600732  20140102   0.0        5.24   0.0  0.0    0.0           0   \n",
       "968  1600734  20140102   0.0        4.87   0.0  0.0    0.0           0   \n",
       "969  1600856  20140102   0.0        6.48   0.0  0.0    0.0           0   \n",
       "970  1601012  20140102   0.0       15.41   0.0  0.0    0.0           0   \n",
       "971  1601901  20140102   0.0        5.91   0.0  0.0    0.0           0   \n",
       "\n",
       "     cum_amount_x  cum_amount_y  \n",
       "942           NaN           0.0  \n",
       "943           NaN           0.0  \n",
       "944           NaN           0.0  \n",
       "945           NaN           0.0  \n",
       "946           NaN           0.0  \n",
       "947           NaN           0.0  \n",
       "948           NaN           0.0  \n",
       "949           NaN           0.0  \n",
       "950           NaN           0.0  \n",
       "951           NaN           0.0  \n",
       "952           NaN           0.0  \n",
       "953           NaN           0.0  \n",
       "954           NaN           0.0  \n",
       "955           NaN           0.0  \n",
       "956           NaN           0.0  \n",
       "957           NaN           0.0  \n",
       "958           NaN           0.0  \n",
       "959           NaN           0.0  \n",
       "960           NaN           0.0  \n",
       "961           NaN           0.0  \n",
       "962           NaN           0.0  \n",
       "963           NaN           0.0  \n",
       "964           NaN           0.0  \n",
       "965           NaN           0.0  \n",
       "966           NaN           0.0  \n",
       "967           NaN           0.0  \n",
       "968           NaN           0.0  \n",
       "969           NaN           0.0  \n",
       "970           NaN           0.0  \n",
       "971           NaN           0.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "re[re[\"cum_amount_x\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind_code</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>turover</th>\n",
       "      <th>cum_trades_cnt</th>\n",
       "      <th>interest</th>\n",
       "      <th>trade_flag</th>\n",
       "      <th>bs_flag</th>\n",
       "      <th>cum_volume</th>\n",
       "      <th>cum_amount</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>settle</th>\n",
       "      <th>position</th>\n",
       "      <th>curDelta</th>\n",
       "      <th>preSettle</th>\n",
       "      <th>prePosition</th>\n",
       "      <th>ask10p</th>\n",
       "      <th>ask9p</th>\n",
       "      <th>ask8p</th>\n",
       "      <th>ask7p</th>\n",
       "      <th>ask6p</th>\n",
       "      <th>ask5p</th>\n",
       "      <th>ask4p</th>\n",
       "      <th>ask3p</th>\n",
       "      <th>ask2p</th>\n",
       "      <th>ask1p</th>\n",
       "      <th>bid1p</th>\n",
       "      <th>bid2p</th>\n",
       "      <th>bid3p</th>\n",
       "      <th>bid4p</th>\n",
       "      <th>bid5p</th>\n",
       "      <th>bid6p</th>\n",
       "      <th>bid7p</th>\n",
       "      <th>bid8p</th>\n",
       "      <th>bid9p</th>\n",
       "      <th>bid10p</th>\n",
       "      <th>ask10q</th>\n",
       "      <th>ask9q</th>\n",
       "      <th>ask8q</th>\n",
       "      <th>ask7q</th>\n",
       "      <th>ask6q</th>\n",
       "      <th>ask5q</th>\n",
       "      <th>ask4q</th>\n",
       "      <th>ask3q</th>\n",
       "      <th>ask2q</th>\n",
       "      <th>ask1q</th>\n",
       "      <th>bid1q</th>\n",
       "      <th>bid2q</th>\n",
       "      <th>bid3q</th>\n",
       "      <th>bid4q</th>\n",
       "      <th>bid5q</th>\n",
       "      <th>bid6q</th>\n",
       "      <th>bid7q</th>\n",
       "      <th>bid8q</th>\n",
       "      <th>bid9q</th>\n",
       "      <th>bid10q</th>\n",
       "      <th>ask_av_price</th>\n",
       "      <th>bid_av_price</th>\n",
       "      <th>total_ask_volume</th>\n",
       "      <th>total_bid_volume</th>\n",
       "      <th>index</th>\n",
       "      <th>stocks</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>holdLines</th>\n",
       "      <th>nResv1</th>\n",
       "      <th>nResv2</th>\n",
       "      <th>nResv3</th>\n",
       "      <th>skey</th>\n",
       "      <th>clockAtArrival</th>\n",
       "      <th>datetime</th>\n",
       "      <th>ordering</th>\n",
       "      <th>has_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110190</th>\n",
       "      <td>600051.SH</td>\n",
       "      <td>宁波联合</td>\n",
       "      <td>20140102</td>\n",
       "      <td>74003000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1600051</td>\n",
       "      <td>1388619603000000</td>\n",
       "      <td>2014-01-02 07:40:03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wind_code  name      date         time  close  volume  turover  \\\n",
       "110190  600051.SH  宁波联合  20140102  74003000000    0.0       0        0   \n",
       "\n",
       "        cum_trades_cnt  interest  trade_flag  bs_flag  cum_volume  cum_amount  \\\n",
       "110190               0         0           0       32           0           0   \n",
       "\n",
       "        high  low  open  prev_close  settle  position  curDelta  preSettle  \\\n",
       "110190   0.0  0.0   0.0        6.71       0         0         0          0   \n",
       "\n",
       "        prePosition  ask10p  ask9p  ask8p  ask7p  ask6p  ask5p  ask4p  ask3p  \\\n",
       "110190            0     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "        ask2p  ask1p  bid1p  bid2p  bid3p  bid4p  bid5p  bid6p  bid7p  bid8p  \\\n",
       "110190    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "        bid9p  bid10p  ask10q  ask9q  ask8q  ask7q  ask6q  ask5q  ask4q  \\\n",
       "110190    0.0     0.0       0      0      0      0      0      0      0   \n",
       "\n",
       "        ask3q  ask2q  ask1q  bid1q  bid2q  bid3q  bid4q  bid5q  bid6q  bid7q  \\\n",
       "110190      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "        bid8q  bid9q  bid10q  ask_av_price  bid_av_price  total_ask_volume  \\\n",
       "110190      0      0       0             0             0                 0   \n",
       "\n",
       "        total_bid_volume  index  stocks  ups  downs  holdLines  nResv1  \\\n",
       "110190                 0      0       0    0      0          0       0   \n",
       "\n",
       "        nResv2  nResv3     skey    clockAtArrival            datetime  \\\n",
       "110190       0       0  1600051  1388619603000000 2014-01-02 07:40:03   \n",
       "\n",
       "        ordering  has_missing  \n",
       "110190         1            0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SH[SH['skey'].isin(list(set['SH']))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

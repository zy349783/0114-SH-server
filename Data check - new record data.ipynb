{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "20200618\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0c4926590a91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mdataPathLs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreadPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mstartTm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mlogSH1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataPathLs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstartTm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.ticker import Formatter\n",
    "import collections\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "\n",
    "\n",
    "for y in ['20200618']:\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(y)\n",
    "    readPath = '\\\\\\\\mentos\\\\dailyRawData\\\\logs_' + y + '_zt_52_03_day_pcap\\\\mdL2Pcap_SH_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    logSH1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    logSH1[\"StockID\"] = logSH1[\"ID\"] - 1000000\n",
    "    logSH1 = logSH1[[\"sequenceNo\", \"StockID\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                     \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\", \"bid3q\", \n",
    "                     \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \n",
    "                     \"ask2q\", \"ask3q\", \"ask4q\", \"ask5q\", \"open\", \"cum_tradesCnt\"]]\n",
    "    logSH1 = logSH1.rename(columns={\"open\":\"openPrice\", \"cum_tradesCnt\":\"numTrades\"})\n",
    "        \n",
    "    path1 = np.array(glob.glob('\\\\\\\\192.168.10.30\\\\Kevin_zhenyu\\\\rawData\\\\logs_' + y + '_zs_92_01_day_data\\\\mdLog_SH_*'))[0]\n",
    "    path2 = np.array(glob.glob('\\\\\\\\192.168.10.30\\\\Kevin_zhenyu\\\\rawData\\\\logs_' + y + '_zs_92_01_day_data\\\\mdLog_SZ_*'))[0]\n",
    "    path3 = np.array(glob.glob('\\\\\\\\192.168.10.30\\\\Kevin_zhenyu\\\\rawData\\\\logs_' + y + '_zt_96_04_day_96data\\\\mdLog_SH_*'))[0]\n",
    "    \n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    logSH2 = pd.read_csv(path3,\n",
    "                    encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"source\", \"StockID\",\n",
    "                                              \"exchange\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                                              \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                                              \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                                              \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                                              \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\"]]\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    logSH2[\"time\"] = logSH2[\"time\"].apply(lambda x: int((x.replace(':', \"\")).replace(\".\", \"\"))) \n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SH lv2 data:')\n",
    "    in_dex = [16, 300, 852, 905]\n",
    "    data1 = logSH2[~logSH2[\"StockID\"].isin(in_dex) & (logSH2[\"time\"] >= 91500000) & (logSH2[\"time\"] <= 150000000) \\\n",
    "              & (logSH2[\"source\"] == 13)]\n",
    "    data2 = logSH1[~logSH1[\"StockID\"].isin(in_dex) & (logSH1[\"time\"] >= 91500000) & (logSH1[\"time\"] <= 150000000)]\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "           \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "           \"ask4q\", \"ask5q\", \"openPrice\", \"time\", \"numTrades\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "\n",
    "    n1 = len(data1_1[\"StockID\"].unique())\n",
    "    n2 = len(data2_1[\"StockID\"].unique())\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique())))\n",
    "    print(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique()))\n",
    "    \n",
    "    if n1 != n2:\n",
    "        sl = list(set(data1_1[\"StockID\"].unique()) & set(data2_1[\"StockID\"].unique()))\n",
    "        data1_1 = data1_1[data1_1[\"StockID\"].isin(sl)]\n",
    "        data2_1 = data2_1[data2_1[\"StockID\"].isin(sl)]\n",
    "    \n",
    "    for cols in [\"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\",\"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"openPrice\"]:\n",
    "        data1_1[cols] = (data1_1[cols]*10000).round(0)\n",
    "    \n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    n1 = test[\"sequenceNo_x\"].count()\n",
    "    n2 = test[\"sequenceNo_y\"].count()\n",
    "    len1 = len(test)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(test[np.isnan(test[\"sequenceNo_y\"])])\n",
    "        display(len(test[np.isnan(test[\"sequenceNo_y\"])])/n1)\n",
    "        display(len(test[np.isnan(test[\"sequenceNo_y\"])][\"time\"].unique()))\n",
    "        display(test[np.isnan(test[\"sequenceNo_y\"])][\"time\"].unique())\n",
    "        display(len(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique()))\n",
    "        display(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique())\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        display(\"baseline is not complete:\")\n",
    "        display(test[np.isnan(test[\"sequenceNo_x\"])])\n",
    "        display(n2-n1)\n",
    "        print((n2-n1)/n1)\n",
    "    del logSH2\n",
    "    del data1\n",
    "    del data2\n",
    "    del test\n",
    "    del data1_1\n",
    "    del data2_1\n",
    "    \n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SH index data:')\n",
    "    \n",
    "    readPath = '\\\\\\\\mentos\\\\dailyRawData\\\\logs_' + y + '_zt_52_03_day_pcap\\\\mdIndexPcap_SH_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    index = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    index[\"StockID\"] = index[\"ID\"] - 1000000\n",
    "    index = index.rename(columns={\"open\":\"openPrice\"})\n",
    "\n",
    "    startTm = datetime.datetime.now()\n",
    "    logSH = pd.read_csv(path1,\n",
    "                    encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"source\", \"StockID\",\n",
    "                                              \"exchange\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                                              \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                                              \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                                              \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                                              \"ask4q\", \"ask5q\", \"openPrice\"]]\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    logSH[\"time\"] = logSH[\"time\"].apply(lambda x: int((x.replace(':', \"\")).replace(\".\", \"\")))\n",
    "    \n",
    "    in_dex = [16, 300, 852, 905]\n",
    "    index = index[index[\"StockID\"].isin(in_dex)]\n",
    "    print(index[\"StockID\"].unique())\n",
    "    \n",
    "    data1 = logSH[(logSH[\"StockID\"].isin(in_dex)) & (logSH[\"time\"] >= 91500000) & (logSH[\"time\"] <= 150000000)]\n",
    "    data2 = index[(index[\"time\"] >= 91500000) & (index[\"time\"] <= 150000000)]\n",
    "\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"openPrice\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    \n",
    "    for cols in [\"cum_amount\", \"close\", \"openPrice\"]:\n",
    "        data1_1[cols] = (data1_1[cols]*10000).round(0)\n",
    "        \n",
    "        \n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    n1 = test[\"sequenceNo_x\"].count()\n",
    "    n2 = test[\"sequenceNo_y\"].count()\n",
    "    len1 = len(test)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(test[np.isnan(test[\"sequenceNo_y\"])])\n",
    "    if (n2 == len1) & (n1 < len1):\n",
    "        display(\"baseline is not complete::\")\n",
    "        display(test[np.isnan(test[\"sequenceNo_x\"])])\n",
    "    \n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"openPrice\", \"time\"]\n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    n1 = test[\"sequenceNo_x\"].count()\n",
    "    n2 = test[\"sequenceNo_y\"].count()\n",
    "    len1 = len(test)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(test[np.isnan(test[\"sequenceNo_y\"])])\n",
    "    if (n2 == len1) & (n1 < len1):\n",
    "        display(\"baseline is not complete::\")\n",
    "        display(test[np.isnan(test[\"sequenceNo_x\"])])\n",
    "    \n",
    "    del index\n",
    "    del logSH\n",
    "    del data1\n",
    "    del data2\n",
    "    del test\n",
    "    del data1_1\n",
    "    del data2_1\n",
    "\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SZ lv2 data:')\n",
    "    \n",
    "    readPath = '\\\\\\\\mentos\\\\dailyRawData\\\\logs_' + y + '_zs_96_03_day_pcap\\\\mdL2Pcap_SZ_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    logSZ1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    logSZ1 = logSZ1.loc[:, [\"clockAtArrival\", \"sequenceNo\", \"ID\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                                              \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                                              \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                                              \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                                              \"ask4q\", \"ask5q\", \"open\", \"cum_tradesCnt\"]]\n",
    "    logSZ1 = logSZ1.rename(columns={\"open\":\"openPrice\", \"cum_tradesCnt\":\"numTrades\"})\n",
    "    logSZ1[\"StockID\"] = logSZ1[\"ID\"] - 2000000\n",
    "\n",
    "    startTm = datetime.datetime.now()\n",
    "    logSZ = pd.read_csv(path2,\n",
    "                    encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"source\", \"StockID\",\n",
    "                                              \"exchange\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                                              \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                                              \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                                              \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                                              \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\"]]\n",
    "    logSZ[\"time\"] = logSZ[\"time\"].apply(lambda x: int((x.replace(':', \"\")).replace(\".\", \"\")))\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    data1 = logSZ[(logSZ[\"time\"] >= 91500000) & (logSZ[\"time\"] < 150000000) & (logSZ[\"source\"] == 4)]\n",
    "    data2 = logSZ1[(logSZ1[\"time\"] >= 91500000) & (logSZ1[\"time\"] < 150000000)]\n",
    "\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "           \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "           \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\", \"time\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "\n",
    "    n1 = len(data1_1[\"StockID\"].unique())\n",
    "    n2 = len(data2_1[\"StockID\"].unique())\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique())))\n",
    "    print(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique()))\n",
    "   \n",
    "    if n1 != n2:\n",
    "        sl = list(set(data1_1[\"StockID\"].unique()) & set(data2_1[\"StockID\"].unique()))\n",
    "        data1_1 = data1_1[data1_1[\"StockID\"].isin(sl)]\n",
    "        data2_1 = data2_1[data2_1[\"StockID\"].isin(sl)]\n",
    "    for i in [\"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"openPrice\"]:\n",
    "        data1_1[i] = (data1_1[i] * 10000).round(0)\n",
    "\n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    n1 = test[\"sequenceNo_x\"].count()\n",
    "    n2 = test[\"sequenceNo_y\"].count()\n",
    "    len1 = len(test)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(test[np.isnan(test[\"sequenceNo_y\"])])\n",
    "        print(len(test[np.isnan(test[\"sequenceNo_y\"])])/n1)\n",
    "        print(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"time\"].unique()))\n",
    "        print(len(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique())))\n",
    "        print(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique()))\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        display(\"baseline is not complete:\")\n",
    "        display(test[np.isnan(test[\"sequenceNo_x\"])])\n",
    "        display(n2-n1)\n",
    "    del logSZ\n",
    "    del logSZ1\n",
    "    del data1\n",
    "    del data2\n",
    "    del test\n",
    "    del data1_1\n",
    "    del data2_1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    readPath = '\\\\\\\\mentos\\\\dailyRawData\\\\logs_' + y + '_zs_96_03_day_pcap\\\\mdOrderPcap_SZ_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    OrderLogSZ1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    OrderLogSZ1[\"SecurityID\"] = OrderLogSZ1[\"ID\"] - 2000000\n",
    "    OrderLogSZ1 = OrderLogSZ1.rename(columns={\"time\":'TransactTime'})\n",
    "    \n",
    "\n",
    "    path1 = np.array(glob.glob('\\\\\\\\192.168.10.30\\\\Kevin_zhenyu\\\\rawData\\\\logs_' + y + '_zs_92_01_day_data\\\\mdOrderLog_*'))[0]\n",
    "    OrderLogSZ = pd.read_csv(path1,\n",
    "                    encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"exchId\", \"TransactTime\",\n",
    "                                                 \"ApplSeqNum\", \"SecurityID\", \"Side\", \"OrderType\", \"Price\",\n",
    "                                                 \"OrderQty\"]]\n",
    "    OrderLogSZ[\"OrderType\"] = OrderLogSZ[\"OrderType\"].apply(lambda x: str(x))\n",
    "    \n",
    "    OrderLogSZ1[\"OrderType\"] = np.where(OrderLogSZ1[\"OrderType\"] == 2, '2', np.where(\n",
    "        OrderLogSZ1[\"OrderType\"] == 1, '1', OrderLogSZ1['OrderType']))\n",
    "    \n",
    "\n",
    "    display(len(OrderLogSZ[\"SecurityID\"].unique()))\n",
    "    display(len(OrderLogSZ1[\"SecurityID\"].unique()))\n",
    "    display(len(set(OrderLogSZ[\"SecurityID\"].unique()) - set(OrderLogSZ1[\"SecurityID\"].unique())))\n",
    "    display(set(OrderLogSZ[\"SecurityID\"].unique()) - set(OrderLogSZ1[\"SecurityID\"].unique()))\n",
    "\n",
    "\n",
    "    sl = list(set(OrderLogSZ[\"SecurityID\"].unique()) & set(OrderLogSZ1['SecurityID'].unique()))\n",
    "    OrderLogSZ = OrderLogSZ[OrderLogSZ[\"SecurityID\"].isin(sl)]\n",
    "    OrderLogSZ1 = OrderLogSZ1[OrderLogSZ1[\"SecurityID\"].isin(sl)]\n",
    "    print(len(OrderLogSZ[\"SecurityID\"].unique()))\n",
    "    print(len(OrderLogSZ1[\"SecurityID\"].unique()))\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SZ order data:')\n",
    "    \n",
    "    columns = [\"ApplSeqNum\", \"TransactTime\", \"Side\", 'OrderType', 'Price', 'OrderQty', \"SecurityID\"]\n",
    "    ree = pd.merge(OrderLogSZ, OrderLogSZ1, on=columns, how=\"outer\", validate='one_to_one')\n",
    "    n1 = ree[\"sequenceNo_x\"].count()\n",
    "    n2 = ree[\"sequenceNo_y\"].count()\n",
    "    len1 = len(ree)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(ree[np.isnan(ree[\"sequenceNo_y\"])])\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_y\"])]))\n",
    "        print(np.sort(ree[np.isnan(ree[\"sequenceNo_y\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_y\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_y\"])][\"SecurityID\"].unique())\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        display(\"test is complete, baseline is not complete:\")\n",
    "        display(ree[np.isnan(ree[\"sequenceNo_x\"])])\n",
    "        print(np.sort(ree[np.isnan(ree[\"sequenceNo_x\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_x\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_x\"])][\"SecurityID\"].unique())\n",
    "        display(n2-n1)\n",
    "    del OrderLogSZ\n",
    "    del OrderLogSZ1\n",
    "    del ree\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    readPath = '\\\\\\\\mentos\\\\dailyRawData\\\\logs_' + y + '_zt_52_03_day_pcap\\\\mdTradePcap_SH_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    SH1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    SH1[\"SecurityID\"] = SH1[\"ID\"] - 1000000\n",
    "    SH1 = SH1.rename(columns={\"time\":'TransactTime'})\n",
    "\n",
    "    path1 = np.array(glob.glob('\\\\\\\\192.168.10.30\\\\Kevin_zhenyu\\\\rawData\\\\logs_' + y + '_zs_92_01_day_data\\\\mdTradeLog_*'))[0]\n",
    "    SH = pd.read_csv(path1,\n",
    "                    encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"exchId\", \"TransactTime\",\n",
    "                                                 \"ApplSeqNum\", \"SecurityID\", \"ExecType\", \"TradeBSFlag\",\n",
    "                                                 \"TradePrice\", \"TradeQty\", \"TradeMoney\", \"BidApplSeqNum\",\n",
    "                                                 \"OfferApplSeqNum\"]]\n",
    "    SH = SH[SH[\"exchId\"] == 1]\n",
    "    \n",
    "    display(len(SH[\"SecurityID\"].unique()))\n",
    "    display(len(SH1[\"SecurityID\"].unique()))\n",
    "    display(len(set(SH[\"SecurityID\"].unique()) - set(SH1[\"SecurityID\"].unique())))\n",
    "    display(set(SH[\"SecurityID\"].unique()) - set(SH1[\"SecurityID\"].unique()))\n",
    "\n",
    "    \n",
    "    sl = list(set(SH[\"SecurityID\"].unique()) & set(SH1['SecurityID'].unique()))\n",
    "    SH = SH[SH[\"SecurityID\"].isin(sl)]\n",
    "    SH1 = SH1[SH1[\"SecurityID\"].isin(sl)]\n",
    "    print(len(SH[\"SecurityID\"].unique()))\n",
    "    print(len(SH1[\"SecurityID\"].unique()))\n",
    "\n",
    "    print(SH1.columns)\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SH trade data:')\n",
    "    \n",
    "    SH[\"ExecType\"] = SH[\"ExecType\"].apply(lambda x: str(x))\n",
    "    SH1[\"ExecType\"] = 'F'\n",
    "    columns = [\"TransactTime\", \"ApplSeqNum\", \"SecurityID\", \"TradePrice\", \"TradeQty\", \"TradeMoney\", \"TradeBSFlag\",\"ExecType\",\n",
    "           \"BidApplSeqNum\", \"OfferApplSeqNum\"]\n",
    "    re = pd.merge(SH, SH1, left_on=columns, right_on=columns, how=\"outer\", validate='one_to_one')\n",
    "    n1 = re[\"sequenceNo_x\"].count()\n",
    "    n2 = re[\"sequenceNo_y\"].count()\n",
    "    len1 = len(re)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(re[np.isnan(re[\"sequenceNo_y\"])])\n",
    "        print(len(re[np.isnan(re[\"sequenceNo_y\"])]))\n",
    "        print(np.sort(re[np.isnan(re[\"sequenceNo_y\"])][\"TransactTime\"].unique()))\n",
    "        print(len(re[np.isnan(re[\"sequenceNo_y\"])][\"SecurityID\"].unique()))\n",
    "        print(re[np.isnan(re[\"sequenceNo_y\"])][\"SecurityID\"].unique())\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        display(\"baseline is not complete:\")\n",
    "        display(re[np.isnan(re[\"sequenceNo_x\"])])\n",
    "        print(np.sort(re[np.isnan(re[\"sequenceNo_x\"])][\"TransactTime\"].unique()))\n",
    "        print(len(re[np.isnan(re[\"sequenceNo_x\"])][\"SecurityID\"].unique()))\n",
    "        print(re[np.isnan(re[\"sequenceNo_x\"])][\"SecurityID\"].unique())\n",
    "        display(n2-n1)\n",
    "    del SH\n",
    "    del SH1\n",
    "    del re\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    readPath = '\\\\\\\\mentos\\\\dailyRawData\\\\logs_' + y + '_zs_96_03_day_pcap\\\\mdTradePcap_SZ_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    TradeLogSZ1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    TradeLogSZ1[\"SecurityID\"] = TradeLogSZ1[\"ID\"] - 2000000\n",
    "    TradeLogSZ1 = TradeLogSZ1.rename(columns={\"time\":'TransactTime'})\n",
    "    TradeLogSZ1[\"TradeBSFlag\"] = 'N'\n",
    "    \n",
    "    startTm = datetime.datetime.now()\n",
    "    path1 = np.array(glob.glob('\\\\\\\\192.168.10.30\\\\Kevin_zhenyu\\\\rawData\\\\logs_' + y + '_zs_92_01_day_data\\\\mdTradeLog_*'))[0]\n",
    "\n",
    "    TradeLogSZ = pd.read_csv(path1,\n",
    "                    encoding=\"utf-8\").loc[:, [\"clockAtArrival\", \"sequenceNo\", \"exchId\", \"TransactTime\",\n",
    "                                                 \"ApplSeqNum\", \"SecurityID\", \"ExecType\", \"TradeBSFlag\",\n",
    "                                                 \"TradePrice\", \"TradeQty\", \"TradeMoney\", \"BidApplSeqNum\",\n",
    "                                                 \"OfferApplSeqNum\"]]\n",
    "    TradeLogSZ = TradeLogSZ[TradeLogSZ[\"exchId\"] != 1]\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    \n",
    "    \n",
    "    display(len(TradeLogSZ[\"SecurityID\"].unique()))\n",
    "    display(len(TradeLogSZ1[\"SecurityID\"].unique()))\n",
    "    display(len(set(TradeLogSZ[\"SecurityID\"].unique()) - set(TradeLogSZ1[\"SecurityID\"].unique())))\n",
    "    display(set(TradeLogSZ[\"SecurityID\"].unique()) - set(TradeLogSZ1[\"SecurityID\"].unique()))\n",
    "\n",
    "\n",
    "    sl = list(set(TradeLogSZ[\"SecurityID\"].unique()) & set(TradeLogSZ1['SecurityID'].unique()))\n",
    "    TradeLogSZ = TradeLogSZ[TradeLogSZ[\"SecurityID\"].isin(sl)]\n",
    "    TradeLogSZ1 = TradeLogSZ1[TradeLogSZ1[\"SecurityID\"].isin(sl)]\n",
    "    print(len(TradeLogSZ[\"SecurityID\"].unique()))\n",
    "    print(len(TradeLogSZ1[\"SecurityID\"].unique()))\n",
    "\n",
    "    print(TradeLogSZ1.columns)\n",
    "    \n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SZ trade data:')\n",
    "    \n",
    "    TradeLogSZ[\"ExecType\"] = TradeLogSZ[\"ExecType\"].apply(lambda x: str(x))\n",
    "    TradeLogSZ1[\"ExecType\"] = TradeLogSZ1[\"ExecType\"].apply(lambda x: str(x))\n",
    "\n",
    "    columns = [\"TransactTime\",\"ApplSeqNum\", \"SecurityID\", \"ExecType\", \"TradeBSFlag\",\"TradePrice\", \"TradeQty\", \"TradeMoney\", \"BidApplSeqNum\",\"OfferApplSeqNum\"]\n",
    "    re = pd.merge(TradeLogSZ, TradeLogSZ1, left_on=columns, right_on=columns, how=\"outer\", validate='one_to_one')\n",
    "    n1 = re[\"sequenceNo_x\"].count()\n",
    "    n2 = re[\"sequenceNo_y\"].count()\n",
    "    len1 = len(re)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        display(\"test is not complete:\")\n",
    "        display(re[np.isnan(re[\"sequenceNo_y\"])])\n",
    "        print(len(re[np.isnan(re[\"sequenceNo_y\"])]))\n",
    "        print(np.sort(re[np.isnan(re[\"sequenceNo_y\"])][\"TransactTime\"].unique()))\n",
    "        print(len(re[np.isnan(re[\"sequenceNo_y\"])][\"SecurityID\"].unique()))\n",
    "        print(re[np.isnan(re[\"sequenceNo_y\"])][\"SecurityID\"].unique())\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        display(\"baseline is not complete:\")\n",
    "        display(re[np.isnan(re[\"sequenceNo_x\"])])\n",
    "        print(np.sort(re[np.isnan(re[\"sequenceNo_x\"])][\"TransactTime\"].unique()))\n",
    "        print(len(re[np.isnan(re[\"sequenceNo_x\"])][\"SecurityID\"].unique()))\n",
    "        print(re[np.isnan(re[\"sequenceNo_x\"])][\"SecurityID\"].unique())\n",
    "        display(n2-n1)\n",
    "    del TradeLogSZ\n",
    "    del TradeLogSZ1\n",
    "    del re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readPath = r'\\\\mentos\\dailyRawData\\logs_20200618_zt_52_03_day_pcap\\***'\n",
    "dataPathLs = np.array(glob.glob(readPath))\n",
    "dataPathLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

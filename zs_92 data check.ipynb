{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import Formatter\n",
    "import collections\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "for y in ['20200812', '20200813', '20200814', '20200817', '20200821', '20200831', '20200901', '20200902']:\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(y)\n",
    "\n",
    "    re = {}\n",
    "    for col in ['date', 'data', 'baseline', 'test', 'merge', 'time', 'stock_list']:\n",
    "        re[col] = []\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/' + y + '/***_zs_96_03_day_96data/mdLog_SH_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    logSH1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    logSH1 = logSH1[[\"sequenceNo\", \"StockID\", \"source\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                     \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\", \"bid3q\",\n",
    "                     \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\",\n",
    "                     \"ask2q\", \"ask3q\", \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\"]]\n",
    "    logSH1[\"time\"] = logSH1[\"time\"].apply(lambda x: int(x.replace(':', \"\").replace('.', \"\")))\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/' + y + '/***_zt_88_03_day_88data/mdLog_SH_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    logSH2 = pd.read_csv(dataPathLs[0])\n",
    "    logSH2 = logSH2[[\"sequenceNo\", \"StockID\", \"source\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                     \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\", \"bid3q\",\n",
    "                     \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\",\n",
    "                     \"ask2q\", \"ask3q\", \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\"]]\n",
    "    logSH2[\"time\"] = logSH2[\"time\"].apply(lambda x: int(x.replace(':', \"\").replace('.', \"\")))\n",
    "\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SH lv2 data:')\n",
    "    in_dex = [16, 300, 852, 905]\n",
    "    data1 = logSH2[~logSH2[\"StockID\"].isin(in_dex) & (logSH2[\"time\"] >= 91500000) & (logSH2[\"time\"] <= 150000000)\n",
    "    & (logSH2['source'] == 23)]\n",
    "    data2 = logSH1[~logSH1[\"StockID\"].isin(in_dex) & (logSH1[\"time\"] >= 91500000) & (logSH1[\"time\"] <= 150000000) & (\n",
    "                logSH1['source'] == 13)]\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "               \"bid2q\",\n",
    "               \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "               \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\", \"time\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "\n",
    "    n1 = len(data1_1[\"StockID\"].unique())\n",
    "    n2 = len(data2_1[\"StockID\"].unique())\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique())))\n",
    "    print(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique()))\n",
    "\n",
    "    if n1 != n2:\n",
    "        sl = list(set(data1_1[\"StockID\"].unique()) & set(data2_1[\"StockID\"].unique()))\n",
    "        data1_1 = data1_1[data1_1[\"StockID\"].isin(sl)]\n",
    "        data2_1 = data2_1[data2_1[\"StockID\"].isin(sl)]\n",
    "\n",
    "    data2_1['cum_amount'] = data2_1['cum_amount'].round(2)\n",
    "    data1_1['cum_amount'] = data1_1['cum_amount'].round(2)\n",
    "    data1_1['openPrice'] = data1_1.groupby('StockID')['openPrice'].transform('max')\n",
    "    data2_1['openPrice'] = data2_1.groupby('StockID')['openPrice'].transform('max')\n",
    "\n",
    "    data2_1 = data2_1[~data2_1['bid1p'].isnull()]\n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    n1 = test[\"sequenceNo_x\"].count()\n",
    "    n2 = test[\"sequenceNo_y\"].count()\n",
    "    len1 = len(test)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SH lv2 data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        print(\"test is not complete:\")\n",
    "        print(test[np.isnan(test[\"sequenceNo_y\"])])\n",
    "        print(len(test[np.isnan(test[\"sequenceNo_y\"])]) / n1)\n",
    "        print(len(test[np.isnan(test[\"sequenceNo_y\"])][\"time\"].unique()))\n",
    "        print(test[np.isnan(test[\"sequenceNo_y\"])][\"time\"].unique())\n",
    "        print(len(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique()))\n",
    "        print(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique())\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"time\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique()))\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        print(\"baseline is not complete:\")\n",
    "        print(test[np.isnan(test[\"sequenceNo_x\"])])\n",
    "        print(n2 - n1)\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"sequenceNo_x\"])][\"time\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"sequenceNo_x\"])][\"StockID\"].unique()))\n",
    "        print((n2 - n1) / n1)\n",
    "    del data1\n",
    "    del data2\n",
    "    del test\n",
    "    del data1_1\n",
    "    del data2_1\n",
    "\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SH lv1 data:')\n",
    "    in_dex = [16, 300, 852, 905]\n",
    "    data1 = logSH2[~logSH2[\"StockID\"].isin(in_dex) & (logSH2[\"time\"] <= 150000000) & (\n",
    "                logSH2['source'] == 22)]\n",
    "    data2 = logSH1[~logSH1[\"StockID\"].isin(in_dex) & (logSH1[\"time\"] <= 150000000) & (\n",
    "                logSH1['source'] == 9)]\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "               \"bid2q\",  \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "               \"ask4q\", \"ask5q\", \"openPrice\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "\n",
    "    n1 = len(data1_1[\"StockID\"].unique())\n",
    "    n2 = len(data2_1[\"StockID\"].unique())\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique())))\n",
    "    print(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique()))\n",
    "\n",
    "    if n1 != n2:\n",
    "        sl = list(set(data1_1[\"StockID\"].unique()) & set(data2_1[\"StockID\"].unique()))\n",
    "        data1_1 = data1_1[data1_1[\"StockID\"].isin(sl)]\n",
    "        data2_1 = data2_1[data2_1[\"StockID\"].isin(sl)]\n",
    "    data1_1['cum_amount'] = data1_1['cum_amount'].round(2)\n",
    "    data2_1['cum_amount'] = data2_1['cum_amount'].round(2)\n",
    "\n",
    "    data2_1 = data2_1[(data2_1['bid1p'] != 0) | (data2_1['ask1p'] != 0) | (data2_1['cum_volume'] != 0)]\n",
    "    data1_1 = data1_1[(data1_1['bid1p'] != 0) | (data1_1['ask1p'] != 0) | (data1_1['cum_volume'] != 0)]\n",
    "\n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    n1 = test[\"sequenceNo_x\"].count()\n",
    "    n2 = test[\"sequenceNo_y\"].count()\n",
    "    len1 = len(test)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SH lv1 data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        print(\"test is not complete:\")\n",
    "        print(test[np.isnan(test[\"sequenceNo_y\"])])\n",
    "        print(len(test[np.isnan(test[\"sequenceNo_y\"])]) / n1)\n",
    "        print(len(test[np.isnan(test[\"sequenceNo_y\"])][\"time_x\"].unique()))\n",
    "        print(test[np.isnan(test[\"sequenceNo_y\"])][\"time_x\"].unique())\n",
    "        print(len(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique()))\n",
    "        print(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique())\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"time_x\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique()))\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        print(\"baseline is not complete:\")\n",
    "        print(test[np.isnan(test[\"sequenceNo_x\"])])\n",
    "        print(n2 - n1)\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"sequenceNo_x\"])][\"time_y\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"sequenceNo_x\"])][\"StockID\"].unique()))\n",
    "        print((n2 - n1) / n1)\n",
    "    del data1\n",
    "    del data2\n",
    "    del test\n",
    "    del data1_1\n",
    "    del data2_1\n",
    "\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SH index data:')\n",
    "\n",
    "    data1 = logSH2[(logSH2[\"StockID\"].isin(in_dex)) & (logSH2[\"time\"] >= 91500000) & (logSH2[\"time\"] <= 150000000)]\n",
    "    data2 = logSH1[(logSH1[\"StockID\"].isin(in_dex)) & (logSH1[\"time\"] >= 91500000) & (logSH1[\"time\"] <= 150000000) & (logSH1['source'] == 13)]\n",
    "\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"openPrice\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "\n",
    "    for cols in ['close', 'openPrice']:\n",
    "        data1_1[cols] = data1_1[cols].round(4)\n",
    "        data2_1[cols] = data2_1[cols].round(4)\n",
    "    for cols in ['cum_amount']:\n",
    "        data1_1[cols] = data1_1[cols].round(1)\n",
    "        data2_1[cols] = data2_1[cols].round(1)\n",
    "\n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    n1 = test[\"sequenceNo_x\"].count()\n",
    "    n2 = test[\"sequenceNo_y\"].count()\n",
    "    len1 = len(test)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SH index data without time column')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)\n",
    "    if n2 < len1:\n",
    "        print(\"test is not complete:\")\n",
    "        print(test[np.isnan(test[\"sequenceNo_y\"])])\n",
    "        re['time'].append(np.sort(test[np.isnan(test['sequenceNo_y'])]['time_x'].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test['sequenceNo_y'])]['StockID'].unique()))\n",
    "    if (n2 == len1) & (n1 < len1):\n",
    "        print(\"baseline is not complete::\")\n",
    "        print(test[np.isnan(test[\"sequenceNo_x\"])])\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"sequenceNo_x\"])]['time_y'].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test['sequenceNo_x'])]['StockID'].unique()))\n",
    "\n",
    "    del logSH1\n",
    "    del logSH2\n",
    "    del data1\n",
    "    del data2\n",
    "    del test\n",
    "    del data1_1\n",
    "    del data2_1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/' + y + '/***_zs_96_03_day_96data/mdTradeLog_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "\n",
    "    startTm = datetime.datetime.now()\n",
    "    SH1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/' + y + '/***_zt_88_03_day_88data/mdTradeLog_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "\n",
    "    startTm = datetime.datetime.now()\n",
    "    SH = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    print(len(SH[\"SecurityID\"].unique()))\n",
    "    print(len(SH1[\"SecurityID\"].unique()))\n",
    "    print(len(set(SH[\"SecurityID\"].unique()) - set(SH1[\"SecurityID\"].unique())))\n",
    "    print(set(SH[\"SecurityID\"].unique()) - set(SH1[\"SecurityID\"].unique()))\n",
    "\n",
    "    sl = list(set(SH[\"SecurityID\"].unique()) & set(SH1['SecurityID'].unique()))\n",
    "    SH = SH[SH[\"SecurityID\"].isin(sl)]\n",
    "    SH1 = SH1[SH1[\"SecurityID\"].isin(sl)]\n",
    "    print(len(SH[\"SecurityID\"].unique()))\n",
    "    print(len(SH1[\"SecurityID\"].unique()))\n",
    "\n",
    "    print(SH1.columns)\n",
    "\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SH trade data:')\n",
    "\n",
    "    SH[\"ExecType\"] = 'F'\n",
    "    SH1[\"ExecType\"] = 'F'\n",
    "    columns = [\"TransactTime\", \"ApplSeqNum\", \"SecurityID\", \"TradePrice\", \"TradeQty\", \"TradeMoney\", \"TradeBSFlag\",\n",
    "               \"ExecType\",  \"BidApplSeqNum\", \"OfferApplSeqNum\"]\n",
    "    ree = pd.merge(SH, SH1, left_on=columns, right_on=columns, how=\"outer\", validate='one_to_one')\n",
    "    n1 = ree[\"sequenceNo_x\"].count()\n",
    "    n2 = ree[\"sequenceNo_y\"].count()\n",
    "    len1 = len(ree)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SH trade data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        print(\"test is not complete:\")\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_y\"])])\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_y\"])]))\n",
    "        print(np.sort(ree[np.isnan(ree[\"sequenceNo_y\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_y\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_y\"])][\"SecurityID\"].unique())\n",
    "        re['time'].append(np.sort(ree[np.isnan(ree[\"sequenceNo_y\"])][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(np.sort(ree[np.isnan(ree[\"sequenceNo_y\"])][\"SecurityID\"].unique()))\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        print(\"baseline is not complete:\")\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_x\"])])\n",
    "        print(np.sort(ree[np.isnan(ree[\"sequenceNo_x\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_x\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_x\"])][\"SecurityID\"].unique())\n",
    "        print(n2 - n1)\n",
    "        re['time'].append(np.sort(ree[np.isnan(ree[\"sequenceNo_x\"])][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(np.sort(ree[np.isnan(ree[\"sequenceNo_x\"])][\"SecurityID\"].unique()))\n",
    "    del SH\n",
    "    del SH1\n",
    "    del ree\n",
    "    \n",
    "        print('----------------------------------------------------------------')\n",
    "    print('SZ lv2 data:')\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/' + y + '/***_zt_88_03_day_88data/mdLog_SZ_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    logSZ1 = pd.read_csv(dataPathLs[0])\n",
    "    logSZ1[\"time\"] = logSZ1[\"time\"].apply(lambda x: int(x.replace(':', \"\"))).astype('int64') * 1000\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    logSZ1 = logSZ1.loc[:, [\"clockAtArrival\", \"sequenceNo\", \"StockID\", \"source\", \"time\", \"cum_volume\", \"cum_amount\", \"close\",\n",
    "                            \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "                            \"bid2q\", \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\",\n",
    "                            \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "                            \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\"]]\n",
    "    logSZ1 = logSZ1[(logSZ1['StockID'] < 4000) | ((logSZ1['StockID'] > 300000) & (logSZ1['StockID'] < 310000))]\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/' + y + '/***_zs_96_03_day_96data/mdLog_SZ_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    logSZ = pd.read_csv(dataPathLs[0])\n",
    "    logSZ = logSZ[~logSZ['time'].isnull()]\n",
    "    logSZ[\"time\"] = logSZ[\"time\"].apply(lambda x: int(x.replace(':', \"\").replace('.', \"\")))\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    startTm = datetime.datetime.now()\n",
    "    data1 = logSZ[(logSZ[\"time\"] >= 91500000) & (logSZ[\"time\"] < 150000000) & (logSZ['source'] == 24)]\n",
    "    data2 = logSZ1[(logSZ1[\"time\"] >= 91500000) & (logSZ1[\"time\"] < 150000000) & (logSZ1['source'] == 12)]\n",
    "\n",
    "    columns = [\"StockID\", \"cum_volume\", \"cum_amount\", \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\",\n",
    "               \"bid2q\",\n",
    "               \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "               \"ask4q\", \"ask5q\", \"openPrice\", \"numTrades\", \"time\"]\n",
    "    data1_1 = data1.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "    data2_1 = data2.drop_duplicates(subset=columns, keep=\"first\").reset_index()\n",
    "\n",
    "    data1_1['cum_amount'] = data1_1['cum_amount'].astype(str).apply(lambda x: x.split('.')[0]).astype('int64')\n",
    "\n",
    "    n1 = len(data1_1[\"StockID\"].unique())\n",
    "    n2 = len(data2_1[\"StockID\"].unique())\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique())))\n",
    "    print(set(data1_1[\"StockID\"].unique()) - set(data2_1[\"StockID\"].unique()))\n",
    "    if n1 != n2:\n",
    "        sl = list(set(data1_1[\"StockID\"].unique()) & set(data2_1[\"StockID\"].unique()))\n",
    "        data1_1 = data1_1[data1_1[\"StockID\"].isin(sl)]\n",
    "        data2_1 = data2_1[data2_1[\"StockID\"].isin(sl)]\n",
    "    for cols in ['close']:\n",
    "        data1_1[cols] = data1_1[cols].round(2)\n",
    "        data2_1[cols] = data2_1[cols].round(2)\n",
    "    test = pd.merge(data1_1, data2_1, left_on=columns, right_on=columns, how=\"outer\")\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    n1 = test[\"sequenceNo_x\"].count()\n",
    "    n2 = test[\"sequenceNo_y\"].count()\n",
    "    len1 = len(test)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SZ lv2 data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        print(\"test is not complete:\")\n",
    "        print(test[np.isnan(test[\"sequenceNo_y\"])])\n",
    "        print(len(test[np.isnan(test[\"sequenceNo_y\"])]) / n1)\n",
    "        print(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"time\"].unique()))\n",
    "        print(len(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique())))\n",
    "        print(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique()))\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"time\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"sequenceNo_y\"])][\"StockID\"].unique()))\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        print(\"baseline is not complete:\")\n",
    "        print(test[np.isnan(test[\"sequenceNo_x\"])])\n",
    "        print(n2 - n1)\n",
    "        re['time'].append(np.sort(test[np.isnan(test[\"sequenceNo_x\"])][\"time\"].unique()))\n",
    "        re['stock_list'].append(np.sort(test[np.isnan(test[\"sequenceNo_x\"])][\"StockID\"].unique()))\n",
    "    del logSZ\n",
    "    del logSZ1\n",
    "    del data1\n",
    "    del data2\n",
    "    del test\n",
    "    del data1_1\n",
    "    del data2_1\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/' + y + '/***_zt_88_03_day_88data/mdOrderLog_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    OrderLogSZ1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/' + y + '/***_zs_96_03_day_96data/mdOrderLog_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    startTm = datetime.datetime.now()\n",
    "    OrderLogSZ = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "\n",
    "    OrderLogSZ[\"OrderType\"] = np.where(OrderLogSZ[\"OrderType\"] == 2, '2', np.where(\n",
    "        OrderLogSZ[\"OrderType\"] == 1, '1', OrderLogSZ['OrderType']))\n",
    "\n",
    "    OrderLogSZ1[\"OrderType\"] = np.where(OrderLogSZ1[\"OrderType\"] == 2, '2', np.where(\n",
    "        OrderLogSZ1[\"OrderType\"] == 1, '1', OrderLogSZ1['OrderType']))\n",
    "\n",
    "    print(len(OrderLogSZ[\"SecurityID\"].unique()))\n",
    "    print(len(OrderLogSZ1[\"SecurityID\"].unique()))\n",
    "    print(len(set(OrderLogSZ[\"SecurityID\"].unique()) - set(OrderLogSZ1[\"SecurityID\"].unique())))\n",
    "    print(set(OrderLogSZ[\"SecurityID\"].unique()) - set(OrderLogSZ1[\"SecurityID\"].unique()))\n",
    "\n",
    "    sl = list(set(OrderLogSZ[\"SecurityID\"].unique()) & set(OrderLogSZ1['SecurityID'].unique()))\n",
    "    OrderLogSZ = OrderLogSZ[OrderLogSZ[\"SecurityID\"].isin(sl)]\n",
    "    OrderLogSZ1 = OrderLogSZ1[OrderLogSZ1[\"SecurityID\"].isin(sl)]\n",
    "    print(len(OrderLogSZ[\"SecurityID\"].unique()))\n",
    "    print(len(OrderLogSZ1[\"SecurityID\"].unique()))\n",
    "\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SZ order data:')\n",
    "\n",
    "    columns = [\"ApplSeqNum\", \"TransactTime\", \"Side\", 'OrderType', 'Price', 'OrderQty', \"SecurityID\"]\n",
    "    ree = pd.merge(OrderLogSZ, OrderLogSZ1, on=columns, how=\"outer\", validate='one_to_one')\n",
    "    n1 = ree[\"sequenceNo_x\"].count()\n",
    "    n2 = ree[\"sequenceNo_y\"].count()\n",
    "    len1 = len(ree)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SZ order data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)\n",
    "\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        print(\"test is not complete:\")\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_y\"])])\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_y\"])]))\n",
    "        print(np.sort(ree[np.isnan(ree[\"sequenceNo_y\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_y\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_y\"])][\"SecurityID\"].unique())\n",
    "        re['time'].append(\n",
    "            np.sort(ree[np.isnan(ree[\"sequenceNo_y\"]) & (~ree[\"OrderType\"].isnull())][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(\n",
    "            np.sort(ree[np.isnan(ree[\"sequenceNo_y\"]) & (~ree[\"OrderType\"].isnull())][\"SecurityID\"].unique()))\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        print(\"test is complete, baseline is not complete:\")\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_x\"])])\n",
    "        print(np.sort(ree[np.isnan(ree[\"sequenceNo_x\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_x\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_x\"])][\"SecurityID\"].unique())\n",
    "        print(n2 - n1)\n",
    "        re['time'].append(np.sort(ree[np.isnan(ree[\"sequenceNo_x\"])][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(np.sort(ree[np.isnan(ree[\"sequenceNo_x\"])][\"SecurityID\"].unique()))\n",
    "    del OrderLogSZ\n",
    "    del OrderLogSZ1\n",
    "    del ree\n",
    "\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/' + y + '/***_zt_88_03_day_88data/mdTradeLog_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "\n",
    "    startTm = datetime.datetime.now()\n",
    "    TradeLogSZ1 = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    TradeLogSZ1[\"TradeBSFlag\"] = 'N'\n",
    "\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/' + y + '/***_zs_96_03_day_96data/mdTradeLog_***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "\n",
    "    startTm = datetime.datetime.now()\n",
    "    TradeLogSZ = pd.read_csv(dataPathLs[0])\n",
    "    print(datetime.datetime.now() - startTm)\n",
    "    TradeLogSZ[\"TradeBSFlag\"] = 'N'\n",
    "\n",
    "    print(len(TradeLogSZ[\"SecurityID\"].unique()))\n",
    "    print(len(TradeLogSZ1[\"SecurityID\"].unique()))\n",
    "    print(len(set(TradeLogSZ[\"SecurityID\"].unique()) - set(TradeLogSZ1[\"SecurityID\"].unique())))\n",
    "    print(set(TradeLogSZ[\"SecurityID\"].unique()) - set(TradeLogSZ1[\"SecurityID\"].unique()))\n",
    "\n",
    "    sl = list(set(TradeLogSZ[\"SecurityID\"].unique()) & set(TradeLogSZ1['SecurityID'].unique()))\n",
    "    TradeLogSZ = TradeLogSZ[TradeLogSZ[\"SecurityID\"].isin(sl)]\n",
    "    TradeLogSZ1 = TradeLogSZ1[TradeLogSZ1[\"SecurityID\"].isin(sl)]\n",
    "    print(len(TradeLogSZ[\"SecurityID\"].unique()))\n",
    "    print(len(TradeLogSZ1[\"SecurityID\"].unique()))\n",
    "\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('SZ trade data:')\n",
    "\n",
    "    TradeLogSZ[\"ExecType\"] = TradeLogSZ[\"ExecType\"].apply(lambda x: str(x))\n",
    "    TradeLogSZ1[\"ExecType\"] = TradeLogSZ1[\"ExecType\"].apply(lambda x: str(x))\n",
    "    columns = [\"TransactTime\", \"ApplSeqNum\", \"SecurityID\", \"ExecType\", \"TradeBSFlag\", \"TradePrice\", \"TradeQty\",\n",
    "               \"TradeMoney\", \"BidApplSeqNum\", \"OfferApplSeqNum\"]\n",
    "    ree = pd.merge(TradeLogSZ, TradeLogSZ1, left_on=columns, right_on=columns, how=\"outer\", validate='one_to_one')\n",
    "    n1 = ree[\"sequenceNo_x\"].count()\n",
    "    n2 = ree[\"sequenceNo_y\"].count()\n",
    "    len1 = len(ree)\n",
    "    re['date'].append(y)\n",
    "    re['data'].append('SZ trade data')\n",
    "    re['baseline'].append(n1)\n",
    "    re['test'].append(n2)\n",
    "    re['merge'].append(len1)\n",
    "    if (n1 == len1) & (n2 == len1):\n",
    "        re['time'].append(0)\n",
    "        re['stock_list'].append(0)\n",
    "    print(n1)\n",
    "    print(n2)\n",
    "    print(len1)\n",
    "    print(\"-----------------------------------------------\")\n",
    "    if n2 < len1:\n",
    "        print(\"test is not complete:\")\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_y\"])])\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_y\"])]))\n",
    "        print(np.sort(ree[np.isnan(ree[\"sequenceNo_y\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_y\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_y\"])][\"SecurityID\"].unique())\n",
    "        re['time'].append(np.sort(ree[np.isnan(ree[\"sequenceNo_y\"])][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(ree[np.isnan(ree[\"sequenceNo_y\"])][\"SecurityID\"].unique())\n",
    "    if (len1 == n2) & (n1 < len1):\n",
    "        print(\"baseline is not complete:\")\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_x\"])])\n",
    "        print(np.sort(ree[np.isnan(ree[\"sequenceNo_x\"])][\"TransactTime\"].unique()))\n",
    "        print(len(ree[np.isnan(ree[\"sequenceNo_x\"])][\"SecurityID\"].unique()))\n",
    "        print(ree[np.isnan(ree[\"sequenceNo_x\"])][\"SecurityID\"].unique())\n",
    "        print(n2 - n1)\n",
    "        re['time'].append(np.sort(ree[np.isnan(ree[\"sequenceNo_x\"])][\"TransactTime\"].unique()))\n",
    "        re['stock_list'].append(ree[np.isnan(ree[\"sequenceNo_x\"])][\"SecurityID\"].unique())\n",
    "    del TradeLogSZ\n",
    "    del TradeLogSZ1\n",
    "    del ree\n",
    "\n",
    "\n",
    "    re = pd.DataFrame(re)\n",
    "    re.to_csv('/mnt/e/zs_96_03/' + y + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

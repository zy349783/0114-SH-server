{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:06.429246\n",
      "20200102\n",
      "0:08:56.394861\n",
      "20200103\n",
      "0:18:32.099718\n",
      "20200106\n",
      "0:29:04.369052\n",
      "20200107\n",
      "0:38:35.609644\n",
      "20200108\n",
      "0:48:26.648286\n",
      "20200109\n",
      "0:57:47.632642\n",
      "20200110\n",
      "1:06:35.601718\n",
      "20200113\n",
      "1:15:48.078232\n",
      "20200114\n",
      "1:24:51.487123\n",
      "20200115\n",
      "1:33:33.370049\n",
      "20200116\n",
      "1:42:50.369384\n",
      "20200117\n",
      "1:51:03.531000\n",
      "20200120\n",
      "2:00:23.270373\n",
      "20200121\n",
      "2:09:19.089046\n",
      "20200122\n",
      "2:17:42.666945\n",
      "20200123\n",
      "2:27:42.601999\n",
      "20200203\n",
      "2:34:07.504663\n",
      "20200204\n",
      "2:44:42.997988\n",
      "20200205\n",
      "2:55:14.386457\n",
      "20200206\n",
      "3:05:49.209544\n",
      "20200207\n",
      "3:16:13.389924\n",
      "20200210\n",
      "3:26:24.902273\n",
      "20200211\n",
      "3:36:38.705895\n",
      "20200212\n",
      "3:46:48.731731\n",
      "20200213\n",
      "3:57:07.013534\n",
      "20200214\n",
      "4:07:11.055102\n",
      "20200217\n",
      "4:18:01.674944\n",
      "20200218\n",
      "4:29:21.608830\n",
      "20200219\n",
      "4:40:28.305902\n",
      "20200220\n",
      "4:52:02.455228\n",
      "20200221\n",
      "5:04:20.408856\n",
      "20200224\n",
      "5:16:00.435051\n",
      "20200225\n",
      "5:28:51.425437\n",
      "20200226\n",
      "5:41:30.318710\n",
      "20200227\n",
      "5:52:54.784131\n",
      "20200228\n",
      "6:05:01.198063\n",
      "20200302\n",
      "6:16:08.088652\n",
      "20200303\n",
      "6:27:45.361879\n",
      "20200304\n",
      "6:38:28.055592\n",
      "20200305\n",
      "6:49:51.493386\n",
      "20200306\n",
      "7:01:11.365538\n",
      "20200309\n",
      "7:12:36.173282\n",
      "20200310\n",
      "7:24:05.503977\n",
      "20200311\n",
      "7:34:55.395812\n",
      "20200312\n",
      "7:45:20.253486\n",
      "20200313\n",
      "7:56:27.507790\n",
      "20200316\n",
      "8:07:28.503530\n",
      "20200317\n",
      "8:18:27.976150\n",
      "20200318\n",
      "8:29:29.383580\n",
      "20200319\n",
      "8:40:26.731120\n",
      "20200320\n",
      "8:50:25.765322\n",
      "20200323\n",
      "9:00:02.985188\n",
      "20200324\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "3969  2300019  20200324  145654000000     4881148  10.02  10.01   10.0    800   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "3969   2000  10.02  10.03   8700   6500  \n",
      "          skey      date          time  cum_volume  close  bid1p  bid2p  \\\n",
      "14718  2300019  20200324  145649120000     4880848  10.02  10.02  10.01   \n",
      "\n",
      "       bid1q  bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "14718    300   1300  10.03  10.04   6500   3800  \n",
      "9:10:01.112074\n",
      "20200325\n",
      "9:20:09.493883\n",
      "20200326\n",
      "9:30:17.453172\n",
      "20200327\n",
      "9:39:59.063941\n",
      "20200330\n",
      "9:49:18.459122\n",
      "20200331\n",
      "9:58:40.851254\n",
      "20200401\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "1661  2300651  20200401  145645000000      434010  24.78  24.73  24.72   1000   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "1661    200  24.78  24.89    460    300  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "2413  2300651  20200401  145634300000      431470  24.78  24.78  24.73   2540   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "2413   1000  24.89   24.9    300    300  \n",
      "10:08:32.482545\n",
      "20200402\n",
      "10:17:50.816179\n",
      "20200403\n",
      "10:27:02.787508\n",
      "20200407\n",
      "10:36:56.048776\n",
      "20200408\n",
      "10:46:48.972515\n",
      "20200409\n",
      "10:56:31.269589\n",
      "20200410\n",
      "11:06:49.048618\n",
      "20200413\n",
      "11:15:53.570686\n",
      "20200414\n",
      "11:24:24.670394\n",
      "20200415\n",
      "11:33:26.792492\n",
      "20200416\n",
      "11:42:04.360747\n",
      "20200417\n",
      "11:51:37.454113\n",
      "20200420\n",
      "12:01:21.324256\n",
      "20200421\n",
      "12:11:21.495526\n",
      "20200422\n",
      "12:21:18.677649\n",
      "20200423\n",
      "12:31:26.589433\n",
      "20200424\n",
      "12:41:21.729496\n",
      "20200427\n",
      "12:50:43.939405\n",
      "20200428\n",
      "13:01:33.653428\n",
      "20200429\n",
      "13:10:58.652614\n",
      "20200430\n",
      "13:20:51.761229\n",
      "20200506\n",
      "13:31:23.495208\n",
      "20200507\n",
      "13:41:27.638142\n",
      "20200508\n",
      "13:51:25.813726\n",
      "20200511\n",
      "14:01:10.744558\n",
      "20200512\n",
      "14:10:50.604020\n",
      "20200513\n",
      "14:20:15.303230\n",
      "20200514\n",
      "14:29:50.322726\n",
      "20200515\n",
      "14:39:51.360076\n",
      "20200518\n",
      "14:49:58.996021\n",
      "20200519\n",
      "14:58:58.426823\n",
      "20200520\n",
      "15:08:54.878636\n",
      "20200521\n",
      "15:18:38.273493\n",
      "20200522\n",
      "15:28:17.917475\n",
      "20200525\n",
      "15:37:15.555322\n",
      "20200526\n",
      "15:47:03.597266\n",
      "20200527\n",
      "15:56:58.681619\n",
      "20200528\n",
      "16:06:39.174086\n",
      "20200529\n",
      "16:16:32.413028\n",
      "20200601\n",
      "16:27:33.382765\n",
      "20200602\n",
      "16:38:26.115633\n",
      "20200603\n",
      "16:48:58.126732\n",
      "20200604\n",
      "16:59:03.239210\n",
      "20200605\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "1473  2300539  20200605  145642000000     1005860   6.87   6.86   6.85    500   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "1473   4000   6.87   6.88   2900  10600  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "2548  2300539  20200605  145637250000     1005760   6.87   6.87   6.86    100   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "2548    500   6.88   6.89  10600   6800  \n",
      "17:08:50.685030\n",
      "20200608\n",
      "17:19:03.689905\n",
      "20200609\n",
      "17:29:28.938862\n",
      "20200610\n",
      "17:39:26.701758\n",
      "20200611\n",
      "17:49:21.836371\n",
      "20200612\n",
      "17:59:46.395799\n",
      "20200615\n",
      "18:10:26.741717\n",
      "20200616\n",
      "18:20:15.887721\n",
      "20200617\n",
      "18:30:56.074385\n",
      "20200618\n",
      "18:41:31.481298\n",
      "20200619\n",
      "18:51:46.365956\n",
      "20200622\n",
      "19:02:09.098511\n",
      "20200623\n",
      "19:11:47.688085\n",
      "20200624\n",
      "19:21:36.967139\n",
      "20200629\n",
      "19:31:29.526766\n",
      "20200630\n",
      "19:41:07.297192\n",
      "20200701\n",
      "19:51:32.187014\n",
      "20200702\n",
      "20:03:18.698032\n",
      "20200703\n",
      "20:15:59.086561\n",
      "20200706\n",
      "20:29:50.707009\n",
      "20200707\n",
      "20:44:40.480839\n",
      "20200708\n",
      "20:58:23.665916\n",
      "20200709\n",
      "21:12:52.318871\n",
      "20200710\n",
      "21:26:27.361016\n",
      "20200713\n",
      "21:39:56.484740\n",
      "20200714\n",
      "21:54:26.521560\n",
      "20200715\n",
      "22:08:16.412007\n",
      "20200716\n",
      "22:22:35.038633\n",
      "20200717\n",
      "mdb data column unupdated\n",
      "2002966\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Index(['cum_trades_cnt'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-44ae64a0d030>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    369\u001b[0m                    \u001b[0;34m'bid7n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bid6n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bid5n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bid4n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bid3n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bid2n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bid1n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ask1n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ask2n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ask3n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                    'ask4n', 'ask5n', 'ask6n', 'ask7n', 'ask8n', 'ask9n', 'ask10n', 'total_bid_quantity', 'total_ask_quantity']\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mmbd1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmbd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0mmbd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmbd1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ApplSeqNum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'ApplSeqNum'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   4809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4810\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4811\u001b[0;31m         \u001b[0mduplicated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   4883\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4885\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4887\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Index(['cum_trades_cnt'], dtype='object')"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "import pymongo\n",
    "import io\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd, version=3):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name, version=version)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db', version=3):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "        self.version = version\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = self.version\n",
    "            ser_data = self.ser(df_seg, version)\n",
    "            seg = {'ver': version, 'data': ser_data, 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "    \n",
    "    def read_raw(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        return collection.find(query)\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        elif version == 3:\n",
    "            # 32-bit number needs more space than 64-bit for parquet\n",
    "            for col_name in s.columns:\n",
    "                col = s[col_name]\n",
    "                if col.dtype == np.int32:\n",
    "                    s[col_name] = col.astype(np.int64)\n",
    "                elif col.dtype == np.uint32:\n",
    "                    s[col_name] = col.astype(np.uint64)\n",
    "            tbl = pa.Table.from_pandas(s)\n",
    "            f = io.BytesIO()\n",
    "            pq.write_table(tbl, f, use_dictionary=False, compression='ZSTD', compression_level=0)\n",
    "            f.seek(0)\n",
    "            data = f.read()\n",
    "            return data\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        elif version == 3:\n",
    "            f = io.BytesIO()\n",
    "            f.write(s)\n",
    "            f.seek(0)\n",
    "            return pq.read_table(f, use_threads=False).to_pandas()\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "def dailyDB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    url = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    client = pymongo.MongoClient(url, maxPoolSize=None)\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def read_stock_daily(db, name, start_date=None, end_date=None, skey=None, index_name=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if index_name is not None:\n",
    "        query['index_name'] = {'$in': index_name}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date', 'skey'])\n",
    "    return df   \n",
    "\n",
    "def read_memb_daily(db, name, start_date=None, end_date=None, skey=None, index_id=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date', 'index_id'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if index_id is not None:\n",
    "        query['index_id'] = {'$in': index_id}\n",
    "    if interval is not None:\n",
    "        query['interval'] = {'$in': interval}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date', 'index_id', 'skey'])\n",
    "    return df \n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "year = \"2020\"\n",
    "startDate = '20200102'\n",
    "endDate = '20200731'\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "db2 = dailyDB(\"192.168.10.178\", database_name, user, password)\n",
    "save = {}\n",
    "save['date'] = []\n",
    "save['secid'] = []\n",
    "mdOrderLog = db1.read('md_order', start_date=startDate, end_date=endDate, symbol=[2000001])\n",
    "datelist = mdOrderLog['date'].unique()\n",
    "ss = pd.read_csv('/mnt/ShareWithServer/result/shangshi.csv')\n",
    "ss['skey'] = np.where(ss['证券代码'].str[-2:] == 'SZ', ss['证券代码'].str[:6].astype(int) + 2000000, ss['证券代码'].str[:6].astype(int) + 1000000)\n",
    "ss['date'] = (ss['上市日期'].str[:4] + ss['上市日期'].str[5:7] + ss['上市日期'].str[8:10]).astype(int)\n",
    "print(datetime.datetime.now() - startTm)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "for d in datelist:\n",
    "    print(d)\n",
    "    sl1 = read_memb_daily(db2, 'index_memb', index_id=[1000852], start_date=20170901, end_date=20201203)['skey'].unique()\n",
    "    sl1 = sl1[sl1 > 2000000]\n",
    "    sl2 = db1.read('md_order', start_date=str(d), end_date=str(d))['skey'].unique()\n",
    "    sl1 = list(set(sl2) - set(sl1))\n",
    "    data1 = db1.read('md_snapshot_l2', start_date=str(d), end_date=str(d), symbol=list(sl1))\n",
    "    sl1 = data1['skey'].unique()\n",
    "    op = read_stock_daily(db2, 'mdbar1d_tr', start_date=int(d), end_date=int(d))\n",
    "#     sl1 = data1[(data1['cum_volume'] > 0) & (data1['time'] <= 145655000000) & (data1['ApplSeqNum'] == -1)]['skey'].unique()\n",
    "#     print(sl1)\n",
    "    if len(sl1) != 0:\n",
    "        for s in sl1:\n",
    "            mbd = db1.read('md_snapshot_mbd', start_date=str(d), end_date=str(d), symbol=s)\n",
    "            if mbd is None:\n",
    "                if ss[ss['skey'] == s]['date'].iloc[0] == d:\n",
    "                    continue\n",
    "                else:\n",
    "                    save['date'].append(d)\n",
    "                    save['secid'].append(s)\n",
    "                    print(s)\n",
    "                    continue\n",
    "            try:\n",
    "                assert(mbd.shape[1] == 82)\n",
    "            except:\n",
    "                print('mdb data column unupdated')\n",
    "                print(s)\n",
    "            try:\n",
    "                op1 = op[op['skey'] == s]['open'].iloc[0]\n",
    "                assert(mbd[mbd['cum_volume'] > 0]['open'].iloc[0] == op1)\n",
    "            except:\n",
    "                print('%s have no information in mdbar1d_tr' % str(s))\n",
    "            l2 = data1[data1['skey'] == s]\n",
    "            cols = ['skey', 'date', 'cum_volume', 'prev_close', 'open', 'close', 'cum_trades_cnt', 'bid10p', 'bid9p',\n",
    "                   'bid8p', 'bid7p', 'bid6p', 'bid5p', 'bid4p', 'bid3p', 'bid2p', 'bid1p', 'ask1p', 'ask2p',\n",
    "                   'ask3p', 'ask4p', 'ask5p', 'ask6p', 'ask7p', 'ask8p', 'ask9p', 'ask10p', 'bid10q', 'bid9q', \n",
    "                   'bid8q', 'bid7q', 'bid6q', 'bid5q', 'bid4q', 'bid3q', 'bid2q', 'bid1q', 'ask1q', 'ask2q', 'ask3q', \n",
    "                   'ask4q', 'ask5q', 'ask6q','ask7q', 'ask8q', 'ask9q', 'ask10q', 'bid10n', 'bid9n', 'bid8n',\n",
    "                   'bid7n', 'bid6n', 'bid5n', 'bid4n', 'bid3n', 'bid2n', 'bid1n', 'ask1n', 'ask2n', 'ask3n', \n",
    "                   'ask4n', 'ask5n', 'ask6n', 'ask7n', 'ask8n', 'ask9n', 'ask10n', 'total_bid_quantity', 'total_ask_quantity']\n",
    "            mbd1 = mbd.drop_duplicates(cols, keep='first')\n",
    "            mbd = mbd1[cols+['ApplSeqNum']]\n",
    "            if 'ApplSeqNum' in l2.columns:\n",
    "                l2 = l2[list(l2.columns[l2.columns != 'ApplSeqNum'])]\n",
    "            rl2 = pd.merge(l2, mbd, on=cols, how='left')\n",
    "            try:\n",
    "                assert(rl2[(rl2['ApplSeqNum'].isnull()) & (rl2['cum_volume'] > 0) & (rl2['time'] <= 145655000000)].shape[0] == 0)\n",
    "            except:\n",
    "                print(rl2[(rl2['ApplSeqNum'].isnull()) & (rl2['cum_volume'] > 0) & (rl2['time'] <= 145655000000)][['skey', 'date', 'time', 'cum_volume', 'close', 'bid1p', 'bid2p','bid1q', 'bid2q', 'ask1p', 'ask2p', 'ask1q', 'ask2q']])\n",
    "                print(mbd1.tail(1)[['skey', 'date', 'time', 'cum_volume', 'close', 'bid1p', 'bid2p','bid1q', 'bid2q', 'ask1p', 'ask2p', 'ask1q', 'ask2q']])\n",
    "            rl2.loc[rl2['ApplSeqNum'].isnull(), 'ApplSeqNum'] = -1\n",
    "            rl2['ApplSeqNum'] = rl2['ApplSeqNum'].astype('int32') \n",
    "            assert(rl2.shape[0] == l2.shape[0])\n",
    "            db1.write('md_snapshot_l2', rl2)\n",
    "        print(datetime.datetime.now() - startTm)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:07.572662\n",
      "20190102\n",
      "0:14:11.053416\n",
      "20190103\n",
      "0:22:45.169123\n",
      "20190104\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "2097  2002887  20190104  145648000000     1026300  16.27  16.27  16.26    300   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "2097  14000  16.28  16.29   7000   3500  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "2783  2002887  20190104  145645670000     1024600  16.27  16.26  16.25  14000   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "2783   5700  16.27  16.28   1700   7000  \n",
      "0:31:51.782294\n",
      "20190107\n",
      "0:40:37.404780\n",
      "20190108\n",
      "0:47:59.268686\n",
      "20190109\n",
      "0:56:07.952417\n",
      "20190110\n",
      "1:03:39.048227\n",
      "20190111\n",
      "1:10:56.862487\n",
      "20190114\n",
      "1:18:29.372232\n",
      "20190115\n",
      "1:26:22.610058\n",
      "20190116\n",
      "1:34:05.075990\n",
      "20190117\n",
      "1:45:58.562506\n",
      "20190118\n",
      "2:04:16.749541\n",
      "20190121\n",
      "2:23:02.454022\n",
      "20190122\n",
      "2:40:53.395870\n",
      "20190123\n",
      "2:56:06.435204\n",
      "20190124\n",
      "3:08:11.758142\n",
      "20190125\n",
      "3:15:33.497212\n",
      "20190128\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "4790  2000786  20190128  145654000000    16095050  15.69  15.68  15.67  12700   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "4790  23582  15.69   15.7   1100  46200  \n",
      "          skey      date          time  cum_volume  close  bid1p  bid2p  \\\n",
      "29970  2000786  20190128  145653720000    16094650   15.7  15.69  15.68   \n",
      "\n",
      "       bid1q  bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "29970    400  12700   15.7  15.71  46200   6000  \n",
      "3:23:15.707215\n",
      "20190129\n",
      "3:31:00.981537\n",
      "20190130\n",
      "3:38:36.527176\n",
      "20190131\n",
      "3:46:25.911167\n",
      "20190201\n",
      "3:54:04.662761\n",
      "20190211\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "1322  2002599  20190211  145651000000     1801770   9.42   9.42   9.39    100   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "1322   2500   9.43   9.44   3400   8700  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "1536  2002599  20190211  145648240000     1792870   9.42   9.39   9.38   2500   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "1536    500   9.42   9.43   8900   3400  \n",
      "6:09:21.876020\n",
      "20190212\n",
      "8:01:48.590591\n",
      "20190213\n",
      "8:15:59.444551\n",
      "20190214\n",
      "8:24:14.880465\n",
      "20190215\n",
      "8:32:33.301163\n",
      "20190218\n",
      "8:41:48.541004\n",
      "20190219\n",
      "8:51:02.074441\n",
      "20190220\n",
      "8:59:28.610314\n",
      "20190221\n",
      "9:08:37.920926\n",
      "20190222\n",
      "9:17:57.501175\n",
      "20190225\n",
      "9:28:40.774019\n",
      "20190226\n",
      "9:39:41.610788\n",
      "20190227\n",
      "9:50:09.495029\n",
      "20190228\n",
      "9:59:28.906410\n",
      "20190301\n",
      "10:08:28.816919\n",
      "20190304\n",
      "10:18:41.981848\n",
      "20190305\n",
      "10:28:45.178708\n",
      "20190306\n",
      "10:39:39.198192\n",
      "20190307\n",
      "10:50:45.390564\n",
      "20190308\n",
      "11:02:09.624190\n",
      "20190311\n",
      "11:12:17.614972\n",
      "20190312\n",
      "11:23:25.710194\n",
      "20190313\n",
      "11:34:02.404759\n",
      "20190314\n",
      "11:44:05.026336\n",
      "20190315\n",
      "11:53:22.940679\n",
      "20190318\n",
      "12:02:37.954249\n",
      "20190319\n",
      "12:12:08.739001\n",
      "20190320\n",
      "12:21:48.703815\n",
      "20190321\n",
      "13:05:37.021464\n",
      "20190322\n",
      "14:00:38.502721\n",
      "20190325\n",
      "14:32:14.744048\n",
      "20190326\n",
      "14:44:46.145563\n",
      "20190327\n",
      "14:55:21.785261\n",
      "20190328\n",
      "15:06:00.600345\n",
      "20190329\n",
      "15:17:10.518721\n",
      "20190401\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "3694  2002520  20190401  145654000000     7518143   8.87   8.86   8.85  56500   \n",
      "\n",
      "       bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "3694  104300   8.87   8.88  19350   5000  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "8364  2002520  20190401  145651350000     7506193   8.87   8.87   8.86  11950   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "8364  56500   8.88   8.89   5000  16050  \n",
      "15:29:04.404967\n",
      "20190402\n",
      "15:40:51.966149\n",
      "20190403\n",
      "15:52:14.140527\n",
      "20190404\n",
      "16:03:05.545321\n",
      "20190408\n",
      "16:14:21.401939\n",
      "20190409\n",
      "16:26:24.858937\n",
      "20190410\n",
      "16:37:32.172967\n",
      "20190411\n",
      "16:47:51.762815\n",
      "20190412\n",
      "16:58:08.206005\n",
      "20190415\n",
      "17:07:48.734819\n",
      "20190416\n",
      "17:17:51.916271\n",
      "20190417\n",
      "17:27:43.570835\n",
      "20190418\n",
      "17:37:53.303095\n",
      "20190419\n",
      "2300683\n",
      "17:47:25.513236\n",
      "20190422\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "2206  2000526  20190422  145651000000      853900  25.74  25.72  25.71   1600   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "2206    900  25.74  25.78   2500   2300  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "3963  2000526  20190422  145650030000      853300  25.74  25.74  25.72    600   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "3963   1600  25.78   25.8   2300   5700  \n",
      "17:57:02.113099\n",
      "20190423\n",
      "18:06:40.427554\n",
      "20190424\n",
      "18:16:05.036709\n",
      "20190425\n",
      "18:25:59.960496\n",
      "20190426\n",
      "18:35:47.052411\n",
      "20190429\n",
      "18:45:18.722785\n",
      "20190430\n",
      "18:53:47.823004\n",
      "20190506\n",
      "19:03:24.300702\n",
      "20190507\n",
      "19:12:40.103648\n",
      "20190508\n",
      "19:21:35.906048\n",
      "20190509\n",
      "19:30:43.776096\n",
      "20190510\n",
      "19:40:50.520940\n",
      "20190513\n",
      "19:49:25.084422\n",
      "20190514\n",
      "19:58:22.435458\n",
      "20190515\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "2867  2002295  20190515  145648000000     3247300   9.07   9.07   9.06    200   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "2867  10700   9.08   9.09   1800  30300  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "6105  2002295  20190515  145639850000     3246500   9.07   9.06   9.05  10700   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "6105  11000   9.07   9.08    800   1800  \n",
      "20:07:20.143106\n",
      "20190516\n",
      "20:15:56.491130\n",
      "20190517\n",
      "20:26:13.541215\n",
      "20190520\n",
      "20:35:52.467451\n",
      "20190521\n",
      "20:44:46.653268\n",
      "20190522\n",
      "20:53:43.727049\n",
      "20190523\n",
      "21:02:54.495914\n",
      "20190524\n",
      "21:11:36.327644\n",
      "20190527\n",
      "21:20:49.949112\n",
      "20190528\n",
      "21:29:18.538080\n",
      "20190529\n",
      "21:38:06.792300\n",
      "20190530\n",
      "21:47:35.468855\n",
      "20190531\n",
      "21:56:14.847900\n",
      "20190603\n",
      "22:05:35.983408\n",
      "20190604\n",
      "22:14:20.724259\n",
      "20190605\n",
      "22:23:06.423356\n",
      "20190606\n",
      "22:32:26.897532\n",
      "20190610\n",
      "22:41:04.654776\n",
      "20190611\n",
      "22:51:18.097932\n",
      "20190612\n",
      "23:01:18.208547\n",
      "20190613\n",
      "23:10:22.502095\n",
      "20190614\n",
      "23:20:22.133074\n",
      "20190617\n",
      "23:29:16.676421\n",
      "20190618\n",
      "23:38:00.373566\n",
      "20190619\n",
      "23:47:29.861212\n",
      "20190620\n",
      "23:58:05.673394\n",
      "20190621\n",
      "1 day, 0:08:23.453814\n",
      "20190624\n",
      "1 day, 0:18:07.837915\n",
      "20190625\n",
      "1 day, 0:27:59.544267\n",
      "20190626\n",
      "1 day, 0:37:15.785226\n",
      "20190627\n",
      "1 day, 0:46:41.115269\n",
      "20190628\n",
      "1 day, 0:55:41.672683\n",
      "20190701\n",
      "1 day, 1:05:03.321538\n",
      "20190702\n",
      "1 day, 1:14:28.816816\n",
      "20190703\n",
      "1 day, 1:23:58.105353\n",
      "20190704\n",
      "1 day, 1:32:45.147753\n",
      "20190705\n",
      "1 day, 1:41:15.122014\n",
      "20190708\n",
      "1 day, 1:50:48.369248\n",
      "20190709\n",
      "1 day, 1:59:25.231516\n",
      "20190710\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "3264  2002849  20190710  145654000000     3911518  16.47  16.46  16.45   3200   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "3264   2299  16.47  16.48    300  17500  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "8454  2002849  20190710  145652710000     3909818  16.48  16.47  16.46   1700   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "8454   3200  16.48  16.49  17500   8600  \n",
      "1 day, 2:08:08.647534\n",
      "20190711\n",
      "1 day, 2:16:57.114527\n",
      "20190712\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "3223  2002595  20190712  145654000000     1605340  20.16  20.13  20.12  10300   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "3223   1900  20.16  20.17   2800   3500  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "9724  2002595  20190712  145652610000     1605140  20.16  20.16  20.13    200   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "9724  10300  20.17  20.18   3500   3000  \n",
      "1 day, 2:24:56.864620\n",
      "20190715\n",
      "1 day, 2:34:06.822531\n",
      "20190716\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "1606  2002857  20190716  145654000000      465460  13.55  13.54  13.53   4600   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "1606   1900  13.55   13.6    900  15600  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "2491  2002857  20190716  145650370000      465260   13.6  13.55  13.54    200   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "2491   4600   13.6  13.61  15600   9200  \n",
      "1 day, 2:42:54.013266\n",
      "20190717\n",
      "1 day, 2:51:29.226977\n",
      "20190718\n",
      "1 day, 2:59:40.134789\n",
      "20190719\n",
      "1 day, 3:07:45.522964\n",
      "20190722\n",
      "1 day, 3:16:25.239767\n",
      "20190723\n",
      "1 day, 3:24:22.089306\n",
      "20190724\n",
      "1 day, 3:32:48.203385\n",
      "20190725\n",
      "1 day, 3:41:24.085757\n",
      "20190726\n",
      "1 day, 3:49:40.040686\n",
      "20190729\n",
      "1 day, 3:57:28.938574\n",
      "20190730\n",
      "1 day, 4:06:04.914271\n",
      "20190731\n",
      "1 day, 4:14:11.132648\n",
      "20190801\n",
      "1 day, 4:22:36.337710\n",
      "20190802\n",
      "1 day, 4:31:15.609648\n",
      "20190805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 day, 4:39:20.809475\n",
      "20190806\n",
      "1 day, 4:48:10.457057\n",
      "20190807\n",
      "1 day, 4:56:54.958950\n",
      "20190808\n",
      "1 day, 5:05:05.702499\n",
      "20190809\n",
      "1 day, 5:13:29.213993\n",
      "20190812\n",
      "1 day, 5:21:16.029396\n",
      "20190813\n",
      "1 day, 5:29:26.183023\n",
      "20190814\n",
      "1 day, 5:37:56.881945\n",
      "20190815\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "1433  2300341  20190815  145648000000     1209100   4.89   4.89   4.88   3400   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "1433  90800    4.9   4.91  27900  11500  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "2040  2300341  20190815  145640480000     1207200   4.89   4.88   4.87  90800   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "2040   7000   4.89    4.9   1900  27900  \n",
      "1 day, 5:46:11.031241\n",
      "20190816\n",
      "1 day, 5:54:44.479897\n",
      "20190819\n",
      "1 day, 6:03:40.681111\n",
      "20190820\n",
      "1 day, 6:12:54.583169\n",
      "20190821\n",
      "1 day, 6:21:23.756012\n",
      "20190822\n",
      "1 day, 6:29:57.330029\n",
      "20190823\n",
      "1 day, 6:38:20.859510\n",
      "20190826\n",
      "1 day, 6:46:41.449702\n",
      "20190827\n",
      "1 day, 6:55:46.609257\n",
      "20190828\n",
      "1 day, 7:04:27.913840\n",
      "20190829\n",
      "1 day, 7:13:09.915054\n",
      "20190830\n",
      "1 day, 7:23:06.013090\n",
      "20190902\n",
      "1 day, 7:32:15.082403\n",
      "20190903\n",
      "1 day, 7:41:23.070110\n",
      "20190904\n",
      "1 day, 7:50:30.927544\n",
      "20190905\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "3360  2300402  20190905  145654000000     5065217  10.68  10.67  10.66   5400   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "3360  19800  10.68  10.69   2800    200  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "7183  2300402  20190905  145647500000     5061917  10.68  10.68  10.67   3300   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "7183   5400  10.69   10.7    200  23100  \n",
      "1 day, 8:00:39.846291\n",
      "20190906\n",
      "1 day, 8:10:06.209843\n",
      "20190909\n",
      "1 day, 8:19:24.962412\n",
      "20190910\n",
      "1 day, 8:29:12.988258\n",
      "20190911\n",
      "1 day, 8:38:34.619072\n",
      "20190912\n",
      "1 day, 8:47:15.240205\n",
      "20190916\n",
      "1 day, 8:56:11.422751\n",
      "20190917\n",
      "1 day, 9:05:18.981705\n",
      "20190918\n",
      "1 day, 9:14:05.790996\n",
      "20190919\n",
      "1 day, 9:23:01.215693\n",
      "20190920\n",
      "1 day, 9:31:22.400070\n",
      "20190923\n",
      "1 day, 9:39:25.387707\n",
      "20190924\n",
      "1 day, 9:47:36.669605\n",
      "20190925\n",
      "1 day, 9:55:51.725658\n",
      "20190926\n",
      "1 day, 10:04:17.202042\n",
      "20190927\n",
      "1 day, 10:11:47.602902\n",
      "20190930\n",
      "1 day, 10:19:13.038937\n",
      "20191008\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "2264  2300535  20191008  145645000000     1075802  13.89  13.86  13.83    400   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "2264    900  13.89  13.93    200   5300  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "6651  2300535  20191008  145634770000     1075702  13.93  13.89  13.86    100   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "6651    400  13.93  13.94   5300   1300  \n",
      "1 day, 10:26:32.220682\n",
      "20191009\n",
      "1 day, 10:33:44.626218\n",
      "20191010\n",
      "1 day, 10:41:10.518611\n",
      "20191011\n",
      "1 day, 10:48:50.104228\n",
      "20191014\n",
      "1 day, 10:56:47.628466\n",
      "20191015\n",
      "1 day, 11:04:50.690861\n",
      "20191016\n",
      "1 day, 11:12:28.044761\n",
      "20191017\n",
      "1 day, 11:19:44.904357\n",
      "20191018\n",
      "1 day, 11:27:40.178702\n",
      "20191021\n",
      "1 day, 11:35:17.525457\n",
      "20191022\n",
      "1 day, 11:43:04.354607\n",
      "20191023\n",
      "1 day, 11:50:59.107227\n",
      "20191024\n",
      "1 day, 11:58:30.885429\n",
      "20191025\n",
      "1 day, 12:06:45.371209\n",
      "20191028\n",
      "1 day, 12:15:17.157642\n",
      "20191029\n",
      "1 day, 12:24:00.617924\n",
      "20191030\n",
      "1 day, 12:32:26.255730\n",
      "20191031\n",
      "1 day, 12:40:54.224027\n",
      "20191101\n",
      "1 day, 12:49:27.488223\n",
      "20191104\n",
      "1 day, 12:57:52.880865\n",
      "20191105\n",
      "1 day, 13:06:20.367247\n",
      "20191106\n",
      "1 day, 13:14:43.601432\n",
      "20191107\n",
      "1 day, 13:22:48.353042\n",
      "20191108\n",
      "1 day, 13:31:03.489320\n",
      "20191111\n",
      "1 day, 13:39:12.024853\n",
      "20191112\n",
      "1 day, 13:47:32.917562\n",
      "20191113\n",
      "1 day, 13:55:09.734957\n",
      "20191114\n",
      "1 day, 14:02:54.083508\n",
      "20191115\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "3274  2002846  20191115  145654000000     3204517  13.41   13.4  13.39  13700   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "3274  13800  13.41  13.42   1700   1700  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "7741  2002846  20191115  145652010000     3201717  13.42  13.41   13.4   2800   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "7741  13700  13.42  13.43   1700   9400  \n",
      "1 day, 14:10:43.656025\n",
      "20191118\n",
      "1 day, 14:18:18.933025\n",
      "20191119\n",
      "1 day, 14:26:08.878577\n",
      "20191120\n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "4618  2000538  20191120  145654000000     3444055  93.52  93.51   93.5   7400   \n",
      "\n",
      "      bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "4618  75900  93.52  93.53    500   9900  \n",
      "          skey      date          time  cum_volume  close  bid1p  bid2p  \\\n",
      "30593  2000538  20191120  145652200000     3443755  93.52  93.52  93.51   \n",
      "\n",
      "       bid1q  bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "30593    300   7400  93.53  93.54   9900   1400  \n",
      "         skey      date          time  cum_volume  close  bid1p  bid2p  bid1q  \\\n",
      "4594  2002902  20191120  145654000000     6069156  24.02  24.01   24.0  23200   \n",
      "\n",
      "       bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "4594  111400  24.02  24.03   9700    400  \n",
      "          skey      date          time  cum_volume  close  bid1p  bid2p  \\\n",
      "20230  2002902  20191120  145653920000     6068856  24.03  24.02  24.01   \n",
      "\n",
      "       bid1q  bid2q  ask1p  ask2p  ask1q  ask2q  \n",
      "20230    300  23200  24.03  24.04    400   8700  \n",
      "1 day, 14:34:03.378054\n",
      "20191121\n",
      "1 day, 14:41:33.403283\n",
      "20191122\n",
      "1 day, 14:50:09.689027\n",
      "20191125\n",
      "1 day, 14:58:11.691158\n",
      "20191126\n",
      "1 day, 15:06:06.939667\n",
      "20191127\n",
      "1 day, 15:14:05.993998\n",
      "20191128\n",
      "1 day, 15:21:39.645426\n",
      "20191129\n",
      "1 day, 15:29:00.328223\n",
      "20191202\n",
      "1 day, 15:36:28.642624\n",
      "20191203\n",
      "1 day, 15:44:06.705857\n",
      "20191204\n",
      "1 day, 15:51:49.423012\n",
      "20191205\n",
      "1 day, 15:59:45.380124\n",
      "20191206\n",
      "1 day, 16:07:29.733860\n",
      "20191209\n",
      "1 day, 16:15:36.751562\n",
      "20191210\n",
      "1 day, 16:23:53.415447\n",
      "20191211\n",
      "1 day, 16:32:19.990757\n",
      "20191212\n",
      "1 day, 16:40:39.095787\n",
      "20191213\n",
      "1 day, 16:49:40.261186\n",
      "20191216\n",
      "1 day, 16:58:49.743875\n",
      "20191217\n",
      "1 day, 17:08:43.026282\n",
      "20191218\n",
      "1 day, 17:18:09.999662\n",
      "20191219\n",
      "1 day, 17:27:05.207445\n",
      "20191220\n",
      "1 day, 17:36:16.890332\n",
      "20191223\n",
      "1 day, 17:45:01.784858\n",
      "20191224\n",
      "1 day, 17:53:17.850058\n",
      "20191225\n",
      "1 day, 18:01:46.591443\n",
      "20191226\n",
      "1 day, 18:10:19.437200\n",
      "20191227\n",
      "1 day, 18:19:26.163039\n",
      "20191230\n",
      "1 day, 18:28:37.667408\n",
      "20191231\n",
      "1 day, 18:37:05.775080\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "import pymongo\n",
    "import io\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd, version=3):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name, version=version)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db', version=3):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "        self.version = version\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = self.version\n",
    "            ser_data = self.ser(df_seg, version)\n",
    "            seg = {'ver': version, 'data': ser_data, 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "    \n",
    "    def read_raw(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        return collection.find(query)\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        elif version == 3:\n",
    "            # 32-bit number needs more space than 64-bit for parquet\n",
    "            for col_name in s.columns:\n",
    "                col = s[col_name]\n",
    "                if col.dtype == np.int32:\n",
    "                    s[col_name] = col.astype(np.int64)\n",
    "                elif col.dtype == np.uint32:\n",
    "                    s[col_name] = col.astype(np.uint64)\n",
    "            tbl = pa.Table.from_pandas(s)\n",
    "            f = io.BytesIO()\n",
    "            pq.write_table(tbl, f, use_dictionary=False, compression='ZSTD', compression_level=0)\n",
    "            f.seek(0)\n",
    "            data = f.read()\n",
    "            return data\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        elif version == 3:\n",
    "            f = io.BytesIO()\n",
    "            f.write(s)\n",
    "            f.seek(0)\n",
    "            return pq.read_table(f, use_threads=False).to_pandas()\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "def dailyDB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    url = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    client = pymongo.MongoClient(url, maxPoolSize=None)\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def read_stock_daily(db, name, start_date=None, end_date=None, skey=None, index_name=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if index_name is not None:\n",
    "        query['index_name'] = {'$in': index_name}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date', 'skey'])\n",
    "    return df   \n",
    "\n",
    "def read_memb_daily(db, name, start_date=None, end_date=None, skey=None, index_id=None, interval=None, col=None, return_sdi=True):\n",
    "    collection = db[name]\n",
    "    # Build projection\n",
    "    prj = {'_id': 0}\n",
    "    if col is not None:\n",
    "        if return_sdi:\n",
    "            col = ['skey', 'date', 'index_id'] + col\n",
    "        for col_name in col:\n",
    "            prj[col_name] = 1\n",
    "\n",
    "    # Build query\n",
    "    query = {}\n",
    "    if skey is not None:\n",
    "        query['skey'] = {'$in': skey}\n",
    "    if index_id is not None:\n",
    "        query['index_id'] = {'$in': index_id}\n",
    "    if interval is not None:\n",
    "        query['interval'] = {'$in': interval}\n",
    "    if start_date is not None:\n",
    "        if end_date is not None:\n",
    "            query['date'] = {'$gte': start_date, '$lte': end_date}\n",
    "        else:\n",
    "            query['date'] = {'$gte': start_date}\n",
    "    elif end_date is not None:\n",
    "        query['date'] = {'$lte': end_date}\n",
    "\n",
    "    # Load data\n",
    "    cur = collection.find(query, prj)\n",
    "    df = pd.DataFrame.from_records(cur)\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        df = df.sort_values(by=['date', 'index_id', 'skey'])\n",
    "    return df \n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "year = \"2019\"\n",
    "startDate = '20190101'\n",
    "endDate = '20191231'\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "db1 = DB(\"192.168.10.178\", database_name, user, password)\n",
    "db2 = dailyDB(\"192.168.10.178\", database_name, user, password)\n",
    "save = {}\n",
    "save['date'] = []\n",
    "save['secid'] = []\n",
    "mdOrderLog = db1.read('md_order', start_date=startDate, end_date=endDate, symbol=[2000001])\n",
    "datelist = mdOrderLog['date'].unique()\n",
    "ss = pd.read_csv('/mnt/ShareWithServer/result/shangshi.csv')\n",
    "ss['skey'] = np.where(ss['证券代码'].str[-2:] == 'SZ', ss['证券代码'].str[:6].astype(int) + 2000000, ss['证券代码'].str[:6].astype(int) + 1000000)\n",
    "ss['date'] = (ss['上市日期'].str[:4] + ss['上市日期'].str[5:7] + ss['上市日期'].str[8:10]).astype(int)\n",
    "print(datetime.datetime.now() - startTm)\n",
    "\n",
    "startTm = datetime.datetime.now()\n",
    "for d in datelist:\n",
    "    print(d)\n",
    "    sl1 = read_memb_daily(db2, 'index_memb', index_id=[1000852], start_date=20170901, end_date=20201203)['skey'].unique()\n",
    "    sl1 = sl1[sl1 > 2000000]\n",
    "    sl2 = db1.read('md_order', start_date=str(d), end_date=str(d))['skey'].unique()\n",
    "    sl1 = list(set(sl2) - set(sl1))\n",
    "    data1 = db1.read('md_snapshot_l2', start_date=str(d), end_date=str(d), symbol=list(sl1))\n",
    "    sl1 = data1['skey'].unique()\n",
    "    op = read_stock_daily(db2, 'mdbar1d_tr', start_date=int(d), end_date=int(d))\n",
    "#     sl1 = data1[(data1['cum_volume'] > 0) & (data1['time'] <= 145655000000) & (data1['ApplSeqNum'] == -1)]['skey'].unique()\n",
    "#     print(sl1)\n",
    "    if len(sl1) != 0:\n",
    "        for s in sl1:\n",
    "            mbd = db1.read('md_snapshot_mbd', start_date=str(d), end_date=str(d), symbol=s)\n",
    "            if mbd is None:\n",
    "                if ss[ss['skey'] == s]['date'].iloc[0] == d:\n",
    "                    continue\n",
    "                else:\n",
    "                    save['date'].append(d)\n",
    "                    save['secid'].append(s)\n",
    "                    print(s)\n",
    "                    continue\n",
    "            try:\n",
    "                assert(mbd.shape[1] == 82)\n",
    "            except:\n",
    "                print('mdb data column unupdated')\n",
    "                print(s)\n",
    "            try:\n",
    "                op1 = op[op['skey'] == s]['open'].iloc[0]\n",
    "                assert(mbd[mbd['cum_volume'] > 0]['open'].iloc[0] == op1)\n",
    "            except:\n",
    "                print('%s have no information in mdbar1d_tr' % str(s))\n",
    "            l2 = data1[data1['skey'] == s]\n",
    "            cols = ['skey', 'date', 'cum_volume', 'prev_close', 'open', 'close', 'cum_trades_cnt', 'bid10p', 'bid9p',\n",
    "                   'bid8p', 'bid7p', 'bid6p', 'bid5p', 'bid4p', 'bid3p', 'bid2p', 'bid1p', 'ask1p', 'ask2p',\n",
    "                   'ask3p', 'ask4p', 'ask5p', 'ask6p', 'ask7p', 'ask8p', 'ask9p', 'ask10p', 'bid10q', 'bid9q', \n",
    "                   'bid8q', 'bid7q', 'bid6q', 'bid5q', 'bid4q', 'bid3q', 'bid2q', 'bid1q', 'ask1q', 'ask2q', 'ask3q', \n",
    "                   'ask4q', 'ask5q', 'ask6q','ask7q', 'ask8q', 'ask9q', 'ask10q', 'bid10n', 'bid9n', 'bid8n',\n",
    "                   'bid7n', 'bid6n', 'bid5n', 'bid4n', 'bid3n', 'bid2n', 'bid1n', 'ask1n', 'ask2n', 'ask3n', \n",
    "                   'ask4n', 'ask5n', 'ask6n', 'ask7n', 'ask8n', 'ask9n', 'ask10n', 'total_bid_quantity', 'total_ask_quantity']\n",
    "            mbd1 = mbd.drop_duplicates(cols, keep='first')\n",
    "            mbd = mbd1[cols+['ApplSeqNum']]\n",
    "            if 'ApplSeqNum' in l2.columns:\n",
    "                l2 = l2[list(l2.columns[l2.columns != 'ApplSeqNum'])]\n",
    "            rl2 = pd.merge(l2, mbd, on=cols, how='left')\n",
    "            try:\n",
    "                assert(rl2[(rl2['ApplSeqNum'].isnull()) & (rl2['cum_volume'] > 0) & (rl2['time'] <= 145655000000)].shape[0] == 0)\n",
    "            except:\n",
    "                print(rl2[(rl2['ApplSeqNum'].isnull()) & (rl2['cum_volume'] > 0) & (rl2['time'] <= 145655000000)][['skey', 'date', 'time', 'cum_volume', 'close', 'bid1p', 'bid2p','bid1q', 'bid2q', 'ask1p', 'ask2p', 'ask1q', 'ask2q']])\n",
    "                print(mbd1.tail(1)[['skey', 'date', 'time', 'cum_volume', 'close', 'bid1p', 'bid2p','bid1q', 'bid2q', 'ask1p', 'ask2p', 'ask1q', 'ask2q']])\n",
    "            rl2.loc[rl2['ApplSeqNum'].isnull(), 'ApplSeqNum'] = -1\n",
    "            rl2['ApplSeqNum'] = rl2['ApplSeqNum'].astype('int32') \n",
    "            assert(rl2.shape[0] == l2.shape[0])\n",
    "            db1.write('md_snapshot_l2', rl2)\n",
    "        print(datetime.datetime.now() - startTm)\n",
    "    else:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------\n",
      "20200909\n",
      "SH lv2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "skey\n",
       "1688095    4858\n",
       "1601702    4992\n",
       "1605003    5136\n",
       "1688559    5147\n",
       "Name: date, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/work516/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:267: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zt_88 finished\n",
      "-------------------------------------------------------------------------------------------\n",
      "SZ lv2\n",
      "             date     skey          time  cum_volume  cum_amount_x  numTrades  \\\n",
      "88834    20200909  2000029   93200000000           0           0.0          0   \n",
      "88835    20200909  2000029   93300000000           0           0.0          0   \n",
      "88836    20200909  2000029   93400000000           0           0.0          0   \n",
      "88837    20200909  2000029   93500000000           0           0.0          0   \n",
      "88838    20200909  2000029   93600000000           0           0.0          0   \n",
      "...           ...      ...           ...         ...           ...        ...   \n",
      "8567680  20200909  2300678  145403000000           0           0.0          0   \n",
      "8567681  20200909  2300678  145503000000           0           0.0          0   \n",
      "8567682  20200909  2300678  145603000000           0           0.0          0   \n",
      "8567684  20200909  2300678  145803000000           0           0.0          0   \n",
      "8567685  20200909  2300678  145903000000           0           0.0          0   \n",
      "\n",
      "         close  bid1p  bid2p  bid3p  bid4p  bid5p  bid1q  bid2q  bid3q  bid4q  \\\n",
      "88834      0.0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "88835      0.0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "88836      0.0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "88837      0.0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "88838      0.0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "8567680    0.0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "8567681    0.0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "8567682    0.0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "8567684    0.0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "8567685    0.0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "\n",
      "         bid5q  ask1p  ask2p  ask3p  ask4p  ask5p  ask1q  ask2q  ask3q  ask4q  \\\n",
      "88834        0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "88835        0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "88836        0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "88837        0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "88838        0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "8567680      0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "8567681      0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "8567682      0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "8567684      0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "8567685      0    0.0    0.0    0.0    0.0    0.0      0      0      0      0   \n",
      "\n",
      "         ask5q  open          num  clockAtArrival  sequenceNo  cum_amount_y  \n",
      "88834        0   0.0  20000290033             NaN         NaN           NaN  \n",
      "88835        0   0.0  20000290034             NaN         NaN           NaN  \n",
      "88836        0   0.0  20000290035             NaN         NaN           NaN  \n",
      "88837        0   0.0  20000290036             NaN         NaN           NaN  \n",
      "88838        0   0.0  20000290037             NaN         NaN           NaN  \n",
      "...        ...   ...          ...             ...         ...           ...  \n",
      "8567680      0   0.0  23006780355             NaN         NaN           NaN  \n",
      "8567681      0   0.0  23006780356             NaN         NaN           NaN  \n",
      "8567682      0   0.0  23006780357             NaN         NaN           NaN  \n",
      "8567684      0   0.0  23006780359             NaN         NaN           NaN  \n",
      "8567685      0   0.0  23006780360             NaN         NaN           NaN  \n",
      "\n",
      "[4825 rows x 32 columns]\n",
      "zt_88 finished\n",
      "----------------------------------------------------------------------------------------------\n",
      "SH & SZ trade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work516/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "skey\n",
       "2002912        1\n",
       "2002946        1\n",
       "2002950        1\n",
       "2300745        1\n",
       "2002982        1\n",
       "           ...  \n",
       "2300441       27\n",
       "1601702      716\n",
       "1688095    10983\n",
       "1605003    32716\n",
       "1688559    71521\n",
       "Name: date, Length: 371, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fa448376cefc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrade\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skey'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrade1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skey'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     assert((len(set(sl) - set(re3[re3['sequenceNo'].isnull()]['skey'].unique())) == 0) & \n\u001b[0;32m--> 371\u001b[0;31m        (len(set(re3[re3['sequenceNo'].isnull()]['skey'].unique()) - set(sl)) == 0))\n\u001b[0m\u001b[1;32m    372\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mre3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequenceNo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mre3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mre3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequenceNo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequenceNo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0mre3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mre3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequenceNo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sequenceNo'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import gzip\n",
    "import lzma\n",
    "import pytz\n",
    "\n",
    "\n",
    "def DB(host, db_name, user, passwd):\n",
    "    auth_db = db_name if user not in ('admin', 'root') else 'admin'\n",
    "    uri = 'mongodb://%s:%s@%s/?authSource=%s' % (user, passwd, host, auth_db)\n",
    "    return DBObj(uri, db_name=db_name)\n",
    "\n",
    "\n",
    "class DBObj(object):\n",
    "    def __init__(self, uri, symbol_column='skey', db_name='white_db'):\n",
    "        self.db_name = db_name\n",
    "        self.uri = uri\n",
    "        self.client = pymongo.MongoClient(self.uri)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.chunk_size = 20000\n",
    "        self.symbol_column = symbol_column\n",
    "        self.date_column = 'date'\n",
    "\n",
    "    def parse_uri(self, uri):\n",
    "        # mongodb://user:password@example.com\n",
    "        return uri.strip().replace('mongodb://', '').strip('/').replace(':', ' ').replace('@', ' ').split(' ')\n",
    "\n",
    "    def drop_table(self, table_name):\n",
    "        self.db.drop_collection(table_name)\n",
    "\n",
    "    def rename_table(self, old_table, new_table):\n",
    "        self.db[old_table].rename(new_table)\n",
    "\n",
    "    def write(self, table_name, df):\n",
    "        if len(df) == 0: return\n",
    "\n",
    "        multi_date = False\n",
    "\n",
    "        if self.date_column in df.columns:\n",
    "            date = str(df.head(1)[self.date_column].iloc[0])\n",
    "            multi_date = len(df[self.date_column].unique()) > 1\n",
    "        else:\n",
    "            raise Exception('DataFrame should contain date column')\n",
    "\n",
    "        collection = self.db[table_name]\n",
    "        collection.create_index([('date', pymongo.ASCENDING), ('symbol', pymongo.ASCENDING)], background=True)\n",
    "        collection.create_index([('symbol', pymongo.ASCENDING), ('date', pymongo.ASCENDING)], background=True)\n",
    "\n",
    "        if multi_date:\n",
    "            for (date, symbol), sub_df in df.groupby([self.date_column, self.symbol_column]):\n",
    "                date = str(date)\n",
    "                symbol = int(symbol)\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "        else:\n",
    "            for symbol, sub_df in df.groupby([self.symbol_column]):\n",
    "                collection.delete_many({'date': date, 'symbol': symbol})\n",
    "                self.write_single(collection, date, symbol, sub_df)\n",
    "\n",
    "    def write_single(self, collection, date, symbol, df):\n",
    "        for start in range(0, len(df), self.chunk_size):\n",
    "            end = min(start + self.chunk_size, len(df))\n",
    "            df_seg = df[start:end]\n",
    "            version = 1\n",
    "            seg = {'ver': version, 'data': self.ser(df_seg, version), 'date': date, 'symbol': symbol, 'start': start}\n",
    "            collection.insert_one(seg)\n",
    "\n",
    "    def build_query(self, start_date=None, end_date=None, symbol=None):\n",
    "        query = {}\n",
    "\n",
    "        def parse_date(x):\n",
    "            if type(x) == str:\n",
    "                if len(x) != 8:\n",
    "                    raise Exception(\"`date` must be YYYYMMDD format\")\n",
    "                return x\n",
    "            elif type(x) == datetime.datetime or type(x) == datetime.date:\n",
    "                return x.strftime(\"%Y%m%d\")\n",
    "            elif type(x) == int:\n",
    "                return parse_date(str(x))\n",
    "            else:\n",
    "                raise Exception(\"invalid `date` type: \" + str(type(x)))\n",
    "\n",
    "        if start_date is not None or end_date is not None:\n",
    "            query['date'] = {}\n",
    "            if start_date is not None:\n",
    "                query['date']['$gte'] = parse_date(start_date)\n",
    "            if end_date is not None:\n",
    "                query['date']['$lte'] = parse_date(end_date)\n",
    "\n",
    "        def parse_symbol(x):\n",
    "            if type(x) == int:\n",
    "                return x\n",
    "            else:\n",
    "                return int(x)\n",
    "\n",
    "        if symbol:\n",
    "            if type(symbol) == list or type(symbol) == tuple:\n",
    "                query['symbol'] = {'$in': [parse_symbol(x) for x in symbol]}\n",
    "            else:\n",
    "                query['symbol'] = parse_symbol(symbol)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def delete(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot delete the whole table')\n",
    "            return None\n",
    "\n",
    "        collection.delete_many(query)\n",
    "\n",
    "    def read(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "\n",
    "        query = self.build_query(start_date, end_date, symbol)\n",
    "        if not query:\n",
    "            print('cannot read the whole table')\n",
    "            return None\n",
    "\n",
    "        segs = []\n",
    "        for x in collection.find(query):\n",
    "            x['data'] = self.deser(x['data'], x['ver'])\n",
    "            segs.append(x)\n",
    "        segs.sort(key=lambda x: (x['symbol'], x['date'], x['start']))\n",
    "        return pd.concat([x['data'] for x in segs], ignore_index=True) if segs else None\n",
    "\n",
    "    def list_tables(self):\n",
    "        return self.db.collection_names()\n",
    "\n",
    "    def list_dates(self, table_name, start_date=None, end_date=None, symbol=None):\n",
    "        collection = self.db[table_name]\n",
    "        dates = set()\n",
    "        if start_date is None:\n",
    "            start_date = '00000000'\n",
    "        if end_date is None:\n",
    "            end_date = '99999999'\n",
    "        for x in collection.find(self.build_query(start_date, end_date, symbol), {\"date\": 1, '_id': 0}):\n",
    "            dates.add(x['date'])\n",
    "        return sorted(list(dates))\n",
    "\n",
    "    def ser(self, s, version):\n",
    "        pickle_protocol = 4\n",
    "        if version == 1:\n",
    "            return gzip.compress(pickle.dumps(s, protocol=pickle_protocol), compresslevel=2)\n",
    "        elif version == 2:\n",
    "            return lzma.compress(pickle.dumps(s, protocol=pickle_protocol), preset=1)\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "    def deser(self, s, version):\n",
    "        def unpickle(s):\n",
    "            return pickle.loads(s)\n",
    "\n",
    "        if version == 1:\n",
    "            return unpickle(gzip.decompress(s))\n",
    "        elif version == 2:\n",
    "            return unpickle(lzma.decompress(s))\n",
    "        else:\n",
    "            raise Exception('unknown version')\n",
    "\n",
    "\n",
    "def patch_pandas_pickle():\n",
    "    if pd.__version__ < '0.24':\n",
    "        import sys\n",
    "        from types import ModuleType\n",
    "        from pandas.core.internals import BlockManager\n",
    "        pkg_name = 'pandas.core.internals.managers'\n",
    "        if pkg_name not in sys.modules:\n",
    "            m = ModuleType(pkg_name)\n",
    "            m.BlockManager = BlockManager\n",
    "            sys.modules[pkg_name] = m\n",
    "patch_pandas_pickle()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "pd.set_option(\"max_columns\", 200)\n",
    "\n",
    "\n",
    "startDate = 20200909\n",
    "endDate = 20200918\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "\n",
    "db = DB(\"192.168.10.178\", database_name, user, password)\n",
    "test = db.read('md_index', start_date=startDate, end_date=endDate, symbol=[1000300])\n",
    "date_list = test['date'].unique()\n",
    "del test\n",
    "\n",
    "new_trade_data = []\n",
    "new_order_data = []\n",
    "\n",
    "for i in date_list:\n",
    "    print('--------------------------------------------------------------------------------------------')\n",
    "    print(i)\n",
    "    print('SH lv2')\n",
    "    startDate = str(i)\n",
    "    endDate = str(i)\n",
    "    db = DB(\"192.168.10.178\", database_name, user, password)\n",
    "    SH = db.read('md_snapshot_l2', start_date=startDate, end_date=endDate)\n",
    "    SZ = SH[SH['skey'] > 2000000]\n",
    "    SH = SH[SH['skey'] < 2000000]\n",
    "    assert(SH['ordering'].max() < 10000)\n",
    "    assert(SZ['ordering'].max() < 10000)\n",
    "    SH['num'] = SH['skey'] * 10000 + SH['ordering']\n",
    "    SZ['num'] = SZ['skey'] * 10000 + SZ['ordering']\n",
    "    \n",
    "    SH = SH[['date', 'skey', 'time', 'cum_volume', 'cum_amount', 'cum_trades_cnt', \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "               \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "               \"ask4q\", \"ask5q\", \"open\", 'num']]\n",
    "    SH = SH.rename(columns={'cum_trades_cnt': 'numTrades'})\n",
    "    SZ = SZ[['date', 'skey', 'time', 'cum_volume', 'cum_amount', 'cum_trades_cnt', \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "               \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "               \"ask4q\", \"ask5q\", \"open\", 'num']]\n",
    "    SZ = SZ.rename(columns={'cum_trades_cnt': 'numTrades'})\n",
    "\n",
    "    startDate = str(i)\n",
    "    endDate = str(i)\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "    path1 = np.array(glob.glob(dataPathLs[0] + '/***_zt_88_03_day_88data.tar.gz/mdLog_SH_***'))\n",
    "    SH1 = pd.read_csv(path1[0])\n",
    "    index1 = SH1[SH1['StockID'].isin([16, 300, 852, 905])]\n",
    "    SH1 = SH1[SH1['source'] == 23]\n",
    "\n",
    "    SH1['skey'] = SH1['StockID'] + 1000000\n",
    "    SH1 = SH1.rename(columns={\"openPrice\":\"open\"})\n",
    "    SH1[\"open\"] = np.where(SH1[\"cum_volume\"] > 0, SH1.groupby(\"skey\")[\"open\"].transform(\"max\"), SH1[\"open\"])\n",
    "    SH1[\"time\"] = SH1[\"time\"].apply(lambda x: int((x.replace(':', \"\")).replace(\".\", \"\")) * 1000)\n",
    "\n",
    "    SH1 = SH1[['clockAtArrival', 'sequenceNo', 'skey', 'time', 'cum_volume', 'cum_amount', \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "               \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "               \"ask4q\", \"ask5q\", \"open\", 'numTrades']]\n",
    "    for cols in ['cum_amount', \"close\", 'open']:\n",
    "        SH1[cols] = SH1[cols].round(2)\n",
    "    cols = ['skey', 'time', 'cum_volume', 'cum_amount', \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "            \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "            \"ask4q\", \"ask5q\", 'numTrades']\n",
    "    SH1 = SH1[SH1['skey'].isin(SH['skey'].unique())]\n",
    "    re = pd.merge(SH, SH1, on=cols, how='left')\n",
    "    display(re[re['sequenceNo'].isnull()].groupby('skey')['date'].size().sort_values())\n",
    "    assert(re.shape[0] == re[~re['date'].isnull()].shape[0])\n",
    "    sl = list(set(SH['skey'].unique()) - set(SH1['skey'].unique()))\n",
    "    assert((len(set(sl) - set(re[re['sequenceNo'].isnull()]['skey'].unique())) == 0) & \n",
    "               (len(set(re[re['sequenceNo'].isnull()]['skey'].unique()) - set(sl)) == 0))\n",
    "    \n",
    "    if re[re.duplicated('num', keep=False)].shape[0] != 0:\n",
    "        p1 = re[re['num'].duplicated(keep=False)]\n",
    "        p2 = re.drop_duplicates(['num'], keep=False)\n",
    "        p1[\"order1\"] = p1.groupby([\"num\"]).cumcount()\n",
    "        p1[\"order2\"] = p1.groupby([\"sequenceNo\"]).cumcount()\n",
    "        p1 = p1[p1['order1'] == p1['order2']]\n",
    "        p1.drop(['order1', 'order2'],axis=1,inplace=True)\n",
    "        re = pd.concat([p1, p2])\n",
    "\n",
    "    re1 = re.sort_values(by='num')\n",
    "    assert(re1.shape[0] == SH.shape[0])   \n",
    "    assert(re1[~re1['sequenceNo'].isnull()].shape[0] == re1[~re1['sequenceNo'].isnull()]['sequenceNo'].nunique())\n",
    "    re1.loc[re['sequenceNo'].isnull(), 'sequenceNo'] = -1\n",
    "    re1['nan'] = 0\n",
    "    re1['count'] = 0\n",
    "    re1 = re1[['skey', 'date', 'num', 'sequenceNo', 'clockAtArrival', 'nan', 'count']]\n",
    "    print('zt_88 finished')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "    print('SZ lv2')\n",
    "    startDate = str(i)\n",
    "    endDate = str(i)\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "    path1 = np.array(glob.glob(dataPathLs[0] + '/***_zt_88_03_day_88data.tar.gz/mdLog_SZ_***'))\n",
    "    SZ1 = pd.read_csv(path1[0])\n",
    "    SZ1 = SZ1[SZ1['source'] == 12]\n",
    "    SZ1['skey'] = SZ1['StockID'] + 2000000\n",
    "    SZ1 = SZ1.rename(columns={\"openPrice\":\"open\"})\n",
    "    SZ1[\"open\"] = np.where(SZ1[\"cum_volume\"] > 0, SZ1.groupby(\"skey\")[\"open\"].transform(\"max\"), SZ1[\"open\"])\n",
    "    SZ1[\"time\"] = SZ1[\"time\"].apply(lambda x: int(x.replace(':', \"\")) * 1000000)\n",
    "\n",
    "    SZ1 = SZ1[['clockAtArrival', 'sequenceNo', 'skey', 'time', 'cum_volume', 'cum_amount', \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "               \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "               \"ask4q\", \"ask5q\", \"open\", 'numTrades']]\n",
    "    for cols in ['cum_amount']:\n",
    "        SZ1[cols] = SZ1[cols].round(2)\n",
    "    cols = ['skey', 'time', 'cum_volume', \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "               \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "               \"ask4q\", \"ask5q\", \"open\", 'numTrades']\n",
    "    SZ1 = SZ1[SZ1['skey'].isin(SZ['skey'].unique())]\n",
    "    re = pd.merge(SZ, SZ1, on=cols, how='left')\n",
    "    try:\n",
    "        assert(re[re['sequenceNo'].isnull()].shape[0] == 0)\n",
    "    except:\n",
    "        print(re[re['sequenceNo'].isnull()])\n",
    "        assert(SZ[SZ['skey'].isin(re[re['sequenceNo'].isnull()]['skey'].unique())]['cum_volume'].unique() == [0])\n",
    "        \n",
    "    if re[re.duplicated('num', keep=False)].shape[0] != 0:\n",
    "        p1 = re[re['num'].duplicated(keep=False)]\n",
    "        p2 = re.drop_duplicates(['num'], keep=False)\n",
    "        p1[\"order1\"] = p1.groupby([\"num\"]).cumcount()\n",
    "        p1[\"order2\"] = p1.groupby([\"sequenceNo\"]).cumcount()\n",
    "        p1 = p1[p1['order1'] == p1['order2']]\n",
    "        p1.drop(['order1', 'order2'],axis=1,inplace=True)\n",
    "        re = pd.concat([p1, p2])\n",
    "    re2 = re.sort_values(by='num')\n",
    "    assert(re2.shape[0] == SZ.shape[0])\n",
    "    assert(re2[~re2['sequenceNo'].isnull()].shape[0] == re2[~re2['sequenceNo'].isnull()]['sequenceNo'].nunique())\n",
    "    re2['nan'] = 0\n",
    "    re2['count'] = 0\n",
    "    re2.loc[re2['sequenceNo'].isnull(), 'sequenceNo'] = -1\n",
    "    re2 = re2[['skey', 'date', 'num', 'sequenceNo', 'clockAtArrival', 'nan', 'count']]\n",
    "    print('zt_88 finished')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('----------------------------------------------------------------------------------------------')\n",
    "    print('SH & SZ trade')\n",
    "    \n",
    "    startDate = str(i)\n",
    "    endDate = str(i)\n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    db = DB(\"192.168.10.178\", database_name, user, password)\n",
    "    trade = db.read('md_trade', start_date=startDate, end_date=endDate)[['skey', 'date', 'ApplSeqNum']]\n",
    "\n",
    "    startDate = str(i)\n",
    "    endDate = str(i)\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "    path1 = np.array(glob.glob(dataPathLs[0] + '/***_zt_88_03_day_88data.tar.gz/mdTradeLog***'))\n",
    "    trade1 = pd.read_csv(path1[0])\n",
    "    trade1['skey'] = np.where(trade1['exchId'] == 2, trade1['SecurityID'] + 2000000, trade1['SecurityID'] + 1000000)\n",
    "    trade1 = trade1[trade1['skey'].isin(trade['skey'].unique())]\n",
    "    re = pd.merge(trade, trade1[['skey', 'ApplSeqNum', 'sequenceNo', 'clockAtArrival']], on=['skey', 'ApplSeqNum'],\n",
    "                 how='left')\n",
    "    display(re[re['sequenceNo'].isnull()].groupby('skey')['date'].size().sort_values())\n",
    "    assert(re.shape[0] == trade.shape[0])\n",
    "    re3 = re.sort_values(by=['skey', 'ApplSeqNum'])\n",
    "    sl = list(set(trade['skey'].unique()) - set(trade1['skey'].unique()))\n",
    "    assert((len(set(sl) - set(re3[re3['sequenceNo'].isnull()]['skey'].unique())) == 0) & \n",
    "       (len(set(re3[re3['sequenceNo'].isnull()]['skey'].unique()) - set(sl)) == 0))\n",
    "    assert(re3[~re3['sequenceNo'].isnull()].shape[0] == re3[~re3['sequenceNo'].isnull()]['sequenceNo'].nunique())\n",
    "    re3.loc[re3['sequenceNo'].isnull(), 'sequenceNo'] = -1\n",
    "    re3['nan'] = 0\n",
    "    re3['count'] = 0\n",
    "    re3 = re3[['clockAtArrival', 'date', 'sequenceNo', 'skey', 'ApplSeqNum', 'nan', 'count']]\n",
    "    print('zt_88 finished')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('--------------------------------------------------------------------------------------------------')\n",
    "    print('SZ order data')\n",
    "\n",
    "    startDate = str(i)\n",
    "    endDate = str(i)\n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    db = DB(\"192.168.10.178\", database_name, user, password)\n",
    "    order = db.read('md_order', start_date=startDate, end_date=endDate)[['skey', 'date', 'ApplSeqNum']]\n",
    "\n",
    "    startDate = str(i)\n",
    "    endDate = str(i)\n",
    "\n",
    "    readPath = '/mnt/e/new_record_data/***'\n",
    "    dataPathLs = np.array(glob.glob(readPath))\n",
    "    dateLs = np.array([os.path.basename(i) for i in dataPathLs])\n",
    "    dataPathLs = dataPathLs[(dateLs >= startDate) & (dateLs <= endDate)]\n",
    "\n",
    "    path1 = np.array(glob.glob(dataPathLs[0] + '/***_zt_88_03_day_88data.tar.gz/mdOrderLog***'))\n",
    "    order1 = pd.read_csv(path1[0])\n",
    "    order1['skey'] = order1['SecurityID'] + 2000000\n",
    "    order1 = order1[order1['skey'].isin(order['skey'].unique())]\n",
    "    re = pd.merge(order, order1[['skey', 'ApplSeqNum', 'sequenceNo', 'clockAtArrival']], on=['skey', 'ApplSeqNum'],\n",
    "                 how='left')\n",
    "    try:\n",
    "        assert(re[re['sequenceNo'].isnull()].shape[0] == 0)\n",
    "        re4 = re.sort_values(by=['skey', 'ApplSeqNum'])\n",
    "        assert(re4.shape[0] == order.shape[0])\n",
    "        assert(re4[~re4['sequenceNo'].isnull()].shape[0] == re4[~re4['sequenceNo'].isnull()]['sequenceNo'].nunique())\n",
    "        re4['nan'] = 0\n",
    "        re4['count'] = 0\n",
    "    except:\n",
    "        print('Attention!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!There are ticks missing in order data')\n",
    "        print(re[re['sequenceNo'].isnull()])\n",
    "        re4 = re.sort_values(by=['skey', 'ApplSeqNum'])\n",
    "        assert(re4.shape[0] == order.shape[0])\n",
    "        assert(re4[~re4['sequenceNo'].isnull()].shape[0] == re4[~re4['sequenceNo'].isnull()]['sequenceNo'].nunique())\n",
    "        re4['nan'] = np.where(re4['sequenceNo'].isnull(), 1, 0)\n",
    "        re4['sequenceNo'] = re4.groupby('skey')['sequenceNo'].ffill().bfill()\n",
    "        re4['count1'] = re4.groupby(['sequenceNo']).cumcount()\n",
    "        re4['count2'] = re4.groupby(['sequenceNo'])['count1'].transform('nunique')\n",
    "        re4['min_seq'] = re4.groupby('sequenceNo')['sequenceNo'].transform('min')\n",
    "        re4['count'] = np.where(re4['sequenceNo'] != re4['min_seq'], re4['count1'], re4['count1']+1-re4['count2'])\n",
    "\n",
    "    re4 = re4[['skey', 'date', 'ApplSeqNum', 'sequenceNo', 'clockAtArrival', 'nan', 'count']]\n",
    "    print('zt_88 finished')   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------------------')\n",
    "    print('SH index data')\n",
    "    \n",
    "    startDate = str(i)\n",
    "    endDate = str(i)\n",
    "    database_name = 'com_md_eq_cn'\n",
    "    user = \"zhenyuy\"\n",
    "    password = \"bnONBrzSMGoE\"\n",
    "\n",
    "    db = DB(\"192.168.10.178\", database_name, user, password)\n",
    "    index = db.read('md_index', start_date=startDate, end_date=endDate)\n",
    "    index = index[index['skey'].isin([1000016, 1000300, 1000852, 1000905])]\n",
    "\n",
    "    index1['skey'] = index1['StockID'] + 1000000\n",
    "    index1 = index1.rename(columns={\"openPrice\":\"open\"})\n",
    "    index1[\"open\"] = np.where(index1[\"cum_volume\"] > 0, index1.groupby(\"skey\")[\"open\"].transform(\"max\"), index1[\"open\"])\n",
    "    index1['close'] = np.where(index1['cum_volume'] == 0, 0, index1['close'])\n",
    "    index1[\"time\"] = index1[\"time\"].apply(lambda x: int((x.replace(':', \"\")).replace(\".\", \"\")) * 1000)\n",
    "    index['close'] = np.where(index['cum_volume'] == 0, 0, index['close'])\n",
    "    index['num'] = index['skey'] * 10000 + index['ordering']\n",
    "    index = index[['skey', 'date', 'cum_volume', 'cum_amount', \"close\", \"open\", 'num', 'time']]\n",
    "    index1 = index1[['clockAtArrival', 'sequenceNo', 'skey', 'cum_volume', 'cum_amount', \"close\", \"open\", \"time\"]]\n",
    "    for cols in ['cum_amount']:\n",
    "        index1[cols] = index1[cols].round(1)\n",
    "    cols = ['skey', 'cum_volume', 'cum_amount', \"close\", \"open\"]\n",
    "    index1 = index1[index1['skey'].isin(index['skey'].unique())]\n",
    "    re = pd.merge(index, index1, on=cols, how='outer')\n",
    "    try:\n",
    "        assert(re[re['date'].isnull()]['cum_volume'].unique() == [0])\n",
    "    except:\n",
    "        print('Attention here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! api data have more ticks in SH index')\n",
    "        print(re[(re['date'].isnull()) & (re['cum_volume'] > 0)])\n",
    "        print(index1[index1['sequenceNo'].isin(re[(re['date'].isnull()) & (re['cum_volume'] > 0)]['sequenceNo'].unique())])\n",
    "        index1 = index1[~index1['sequenceNo'].isin(re[(re['date'].isnull()) & (re['cum_volume'] > 0)]['sequenceNo'].unique())]\n",
    "    assert(re[re['sequenceNo'].isnull()].shape[0] == 0)\n",
    "    index1 = index1[index1['cum_volume'] > 0]\n",
    "    re = pd.concat([index1, index])\n",
    "    re = re.sort_values(by=['skey', 'time'])\n",
    "    re['sequenceNo'] = re.groupby('skey')['sequenceNo'].ffill()\n",
    "    re['clockAtArrival'] = re.groupby('skey')['clockAtArrival'].ffill()\n",
    "    re['count'] = re.groupby(['skey', 'sequenceNo']).cumcount()\n",
    "    re['sequenceNo'] = re['sequenceNo'].fillna(-1)\n",
    "    re.loc[re['count'] > 1, 'sequenceNo'] = -1\n",
    "    re.loc[re['count'] > 1, 'clockAtArrival'] = np.nan\n",
    "    re5 = re[~re['date'].isnull()]\n",
    "    assert(re5.shape[0] == index.shape[0])\n",
    "    re5['nan'] = 0\n",
    "    re5['count'] = 0\n",
    "    re5 = re5[['skey', 'date', 'num', 'sequenceNo', 'clockAtArrival', 'nan', 'count']]\n",
    "    print('zt_88 finished')\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('----------------------------------------------------------------------------------------------------')\n",
    "    print('final concat zt88')\n",
    "    try:\n",
    "        assert(len(set(SZ1['sequenceNo']) & set(SH1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SZ1[SZ1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(SH1['sequenceNo'])))])\n",
    "        display(SH1[SH1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(SH1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SZ1['sequenceNo']) & set(trade1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SZ1[SZ1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(trade1['sequenceNo'])))])\n",
    "        display(trade1[trade1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(trade1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SZ1['sequenceNo']) & set(order1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SZ1[SZ1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "        display(order1[order1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SZ1['sequenceNo']) & set(index1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SZ1[SZ1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(index1['sequenceNo'])))])\n",
    "        display(index1[index1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(index1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SH1['sequenceNo']) & set(index1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SH1[SH1['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(index1['sequenceNo'])))])\n",
    "        display(index1[index1['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(index1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SH1['sequenceNo']) & set(trade1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SH1[SH1['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(trade1['sequenceNo'])))])\n",
    "        display(trade1[trade1['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(trade1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SH1['sequenceNo']) & set(order1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SH1[SH1['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "        display(order1[order1['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(trade1['sequenceNo']) & set(order1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(trade1[trade1['sequenceNo'].isin(list(set(trade1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "        display(order1[order1['sequenceNo'].isin(list(set(trade1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(trade1['sequenceNo']) & set(index1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(trade1[trade1['sequenceNo'].isin(list(set(trade1['sequenceNo']) & set(index1['sequenceNo'])))])\n",
    "        display(index1[index1['sequenceNo'].isin(list(set(trade1['sequenceNo']) & set(index1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(index1['sequenceNo']) & set(order1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(index1[index1['sequenceNo'].isin(list(set(index1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "        display(order1[order1['sequenceNo'].isin(list(set(index1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "    print('SH lv2')\n",
    "    \n",
    "    path1 = np.array(glob.glob(dataPathLs[0] + '/***_zs_96_03_day_96data.tar.gz/mdLog_SH_***'))\n",
    "    SH1 = pd.read_csv(path1[0])\n",
    "    index11 = SH1[SH1['StockID'].isin([16, 300, 852, 905])]\n",
    "    SH1 = SH1[SH1['source'] == 13]\n",
    "\n",
    "    SH1['skey'] = SH1['StockID'] + 1000000\n",
    "    SH1 = SH1.rename(columns={\"openPrice\":\"open\"})\n",
    "    SH1[\"open\"] = np.where(SH1[\"cum_volume\"] > 0, SH1.groupby(\"skey\")[\"open\"].transform(\"max\"), SH1[\"open\"])\n",
    "    SH1[\"time\"] = SH1[\"time\"].apply(lambda x: int((x.replace(':', \"\")).replace(\".\", \"\")) * 1000)\n",
    "\n",
    "    SH1 = SH1[['clockAtArrival', 'sequenceNo', 'skey', 'time', 'cum_volume', 'cum_amount', \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "               \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "               \"ask4q\", \"ask5q\", \"open\", 'numTrades']]\n",
    "    for cols in ['cum_amount', \"close\", 'open']:\n",
    "        SH1[cols] = SH1[cols].round(2)\n",
    "    cols = ['skey', 'time', 'cum_volume', 'cum_amount', \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "            \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "            \"ask4q\", \"ask5q\", 'open', 'numTrades']\n",
    "    SH1 = SH1[SH1['skey'].isin(SH['skey'].unique())]\n",
    "    re = pd.merge(SH, SH1, on=cols, how='left')\n",
    "    display(re[re['sequenceNo'].isnull()].groupby('skey')['date'].size().sort_values())\n",
    "    # For KCB orders, zs96 shows snapshot data after 15:00 which is different from the data shows in database.\n",
    "    assert(re.shape[0] == re[~re['date'].isnull()].shape[0])\n",
    "    sl = list(set(SH['skey'].unique()) - set(SH1['skey'].unique()))\n",
    "    \n",
    "    if re[re.duplicated('num', keep=False)].shape[0] != 0:\n",
    "        p1 = re[re['num'].duplicated(keep=False)]\n",
    "        p2 = re.drop_duplicates(['num'], keep=False)\n",
    "        p1[\"order1\"] = p1.groupby([\"num\"]).cumcount()\n",
    "        p1[\"order2\"] = p1.groupby([\"sequenceNo\"]).cumcount()\n",
    "        p1 = p1[p1['order1'] == p1['order2']]\n",
    "        p1.drop(['order1', 'order2'],axis=1,inplace=True)\n",
    "        re = pd.concat([p1, p2])\n",
    "\n",
    "    ree1 = re.sort_values(by='num')\n",
    "    assert(ree1.shape[0] == SH.shape[0])\n",
    "    assert(ree1[~ree1['sequenceNo'].isnull()].shape[0] == ree1[~ree1['sequenceNo'].isnull()]['sequenceNo'].nunique())\n",
    "    ree1['nan'] = np.where(ree1['sequenceNo'].isnull(), 1, 0)\n",
    "    ree1['sequenceNo'] = ree1.groupby('skey')['sequenceNo'].ffill().bfill()\n",
    "    ree1.loc[ree1['skey'].isin(sl), 'sequenceNo'] = np.nan\n",
    "    \n",
    "    assert((len(set(sl) - set(ree1[ree1['sequenceNo'].isnull()]['skey'].unique())) == 0) & \n",
    "           (len(set(ree1[ree1['sequenceNo'].isnull()]['skey'].unique()) - set(sl)) == 0))\n",
    "    ree1.loc[ree1['sequenceNo'].isnull(), 'sequenceNo'] = -1\n",
    "    ree1 = ree1[['skey', 'date', 'num', 'sequenceNo', 'clockAtArrival', 'nan']]\n",
    "    print('zs_96 finished')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "    print('SZ lv2')    \n",
    "    \n",
    "    path1 = np.array(glob.glob(dataPathLs[0] + '/***_zs_96_03_day_96data.tar.gz/mdLog_SZ_***'))\n",
    "    SZ1 = pd.read_csv(path1[0])\n",
    "    SZ1 = SZ1[SZ1['source'] == 24]\n",
    "    SZ1['skey'] = SZ1['StockID'] + 2000000\n",
    "    SZ1 = SZ1.rename(columns={\"openPrice\":\"open\"})\n",
    "    SZ1[\"open\"] = np.where(SZ1[\"cum_volume\"] > 0, SZ1.groupby(\"skey\")[\"open\"].transform(\"max\"), SZ1[\"open\"])\n",
    "    SZ1[\"time\"] = SZ1[\"time\"].apply(lambda x: int((x.replace(':', \"\")).replace(\".\", \"\")) * 1000)\n",
    "\n",
    "    SZ1 = SZ1[['clockAtArrival', 'sequenceNo', 'skey', 'time', 'cum_volume', 'cum_amount', \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "               \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "               \"ask4q\", \"ask5q\", \"open\", 'numTrades']]\n",
    "    for cols in ['cum_amount']:\n",
    "        SZ1[cols] = SZ1[cols].round(2)\n",
    "    cols = ['skey', 'time', 'cum_volume', 'cum_amount', \"close\", \"bid1p\", \"bid2p\", \"bid3p\", \"bid4p\", \"bid5p\", \"bid1q\", \"bid2q\",\n",
    "               \"bid3q\", \"bid4q\", \"bid5q\", \"ask1p\", \"ask2p\", \"ask3p\", \"ask4p\", \"ask5p\", \"ask1q\", \"ask2q\", \"ask3q\",\n",
    "               \"ask4q\", \"ask5q\", \"open\", 'numTrades']\n",
    "    SZ1 = SZ1[SZ1['skey'].isin(SZ['skey'].unique())]\n",
    "    re = pd.merge(SZ, SZ1, on=cols, how='left')\n",
    "    display(re[re['sequenceNo'].isnull()].groupby('skey')['date'].size().sort_values())\n",
    "    assert(re.shape[0] == re[~re['date'].isnull()].shape[0])\n",
    "    sl = list(set(SZ['skey'].unique()) - set(SZ1['skey'].unique()))\n",
    "    assert((len(set(sl) - set(re[re['sequenceNo'].isnull()]['skey'].unique())) == 0) & \n",
    "               (len(set(re[re['sequenceNo'].isnull()]['skey'].unique()) - set(sl)) == 0))\n",
    "    \n",
    "    if re[re.duplicated('num', keep=False)].shape[0] != 0:\n",
    "        p1 = re[re['num'].duplicated(keep=False)]\n",
    "        p2 = re.drop_duplicates(['num'], keep=False)\n",
    "        p1[\"order1\"] = p1.groupby([\"num\"]).cumcount()\n",
    "        p1[\"order2\"] = p1.groupby([\"sequenceNo\"]).cumcount()\n",
    "        p1 = p1[p1['order1'] == p1['order2']]\n",
    "        p1.drop(['order1', 'order2'],axis=1,inplace=True)\n",
    "        re = pd.concat([p1, p2])\n",
    "\n",
    "    ree2 = re.sort_values(by='num')\n",
    "    assert(ree2.shape[0] == SZ.shape[0])\n",
    "    assert(ree2[~ree2['sequenceNo'].isnull()].shape[0] == ree2[~ree2['sequenceNo'].isnull()]['sequenceNo'].nunique())\n",
    "    ree2['nan'] = 0\n",
    "    ree2.loc[ree2['sequenceNo'].isnull(), 'sequenceNo'] = -1\n",
    "    ree2 = ree2[['skey', 'date', 'num', 'sequenceNo', 'clockAtArrival', 'nan']]\n",
    "    print('zs_96 finished')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "    print('SH & SZ trade')     \n",
    "        \n",
    "    path1 = np.array(glob.glob(dataPathLs[0] + '/***_zs_96_03_day_96data.tar.gz/mdTradeLog***'))\n",
    "    trade1 = pd.read_csv(path1[0])\n",
    "    trade1['skey'] = np.where(trade1['exchId'] == 2, trade1['SecurityID'] + 2000000, trade1['SecurityID'] + 1000000)\n",
    "    trade1 = trade1[trade1['skey'].isin(trade['skey'].unique())]\n",
    "    assert(trade1[trade1['ChannelNo'] == 103]['TransactTime'].min() > 150000000)\n",
    "    assert(trade1[trade1['ChannelNo'] == 103]['skey'].min() > 1688000)\n",
    "    trade1 = trade1[trade1['ChannelNo'] != 103]\n",
    "    \n",
    "    re = pd.merge(trade, trade1[['skey', 'ApplSeqNum', 'sequenceNo', 'clockAtArrival']], on=['skey', 'ApplSeqNum'],\n",
    "                 how='left')\n",
    "    display(re[re['sequenceNo'].isnull()].groupby('skey')['date'].size().sort_values())\n",
    "    assert(re.shape[0] == trade.shape[0])\n",
    "    ree3 = re.sort_values(by=['skey', 'ApplSeqNum'])\n",
    "    sl = list(set(trade['skey'].unique()) - set(trade1['skey'].unique()))\n",
    "    assert((len(set(sl) - set(ree3[ree3['sequenceNo'].isnull()]['skey'].unique())) == 0) & \n",
    "       (len(set(ree3[ree3['sequenceNo'].isnull()]['skey'].unique()) - set(sl)) == 0))\n",
    "    assert(ree3[~ree3['sequenceNo'].isnull()].shape[0] == ree3[~ree3['sequenceNo'].isnull()]['sequenceNo'].nunique())\n",
    "    ree3.loc[ree3['sequenceNo'].isnull(), 'sequenceNo'] = -1\n",
    "    ree3['nan'] = 0\n",
    "    ree3 = ree3[['clockAtArrival', 'date', 'sequenceNo', 'skey', 'ApplSeqNum', 'nan']]\n",
    "    print('zs_96 finished')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "    print('SZ order data') \n",
    "    \n",
    "    path1 = np.array(glob.glob(dataPathLs[0] + '/***_zs_96_03_day_96data.tar.gz/mdOrderLog***'))\n",
    "    order1 = pd.read_csv(path1[0])\n",
    "    order1['skey'] = order1['SecurityID'] + 2000000\n",
    "    order1 = order1[order1['skey'].isin(order['skey'].unique())]\n",
    "    re = pd.merge(order, order1[['skey', 'ApplSeqNum', 'sequenceNo', 'clockAtArrival']], on=['skey', 'ApplSeqNum'],\n",
    "                 how='left')\n",
    "    display(re[re['sequenceNo'].isnull()].groupby('skey')['date'].size().sort_values())\n",
    "    assert(re.shape[0] == order.shape[0])\n",
    "    ree4 = re.sort_values(by=['skey', 'ApplSeqNum'])\n",
    "    sl = list(set(order['skey'].unique()) - set(order1['skey'].unique()))\n",
    "    assert((len(set(sl) - set(ree4[ree4['sequenceNo'].isnull()]['skey'].unique())) == 0) & \n",
    "       (len(set(ree4[ree4['sequenceNo'].isnull()]['skey'].unique()) - set(sl)) == 0))\n",
    "    assert(ree4[~ree4['sequenceNo'].isnull()].shape[0] == ree4[~ree4['sequenceNo'].isnull()]['sequenceNo'].nunique())\n",
    "    ree4['nan'] = 0\n",
    "    ree4.loc[ree4['sequenceNo'].isnull(), 'sequenceNo'] = -1\n",
    "    ree4 = ree4[['clockAtArrival', 'date', 'sequenceNo', 'skey', 'ApplSeqNum', 'nan']]\n",
    "    print('zs_96 finished')\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------------')\n",
    "    print('SH index data')\n",
    "    \n",
    "    index11['skey'] = index11['StockID'] + 1000000\n",
    "    index11 = index11.rename(columns={\"openPrice\":\"open\"})\n",
    "    index11[\"open\"] = np.where(index11[\"cum_volume\"] > 0, index11.groupby(\"skey\")[\"open\"].transform(\"max\"), index11[\"open\"])\n",
    "    index11['close'] = np.where(index11['cum_volume'] == 0, 0, index11['close'])\n",
    "    index11[\"time\"] = index11[\"time\"].apply(lambda x: int((x.replace(':', \"\")).replace(\".\", \"\")) * 1000)\n",
    "    index11 = index11[['clockAtArrival', 'sequenceNo', 'skey', 'cum_volume', 'cum_amount', \"close\", \"open\", \"time\"]]\n",
    "    for cols in ['cum_amount']:\n",
    "        index11[cols] = index11[cols].round(1)\n",
    "    cols = ['skey', 'cum_volume', 'cum_amount', \"close\", \"open\"]\n",
    "    index11 = index11[index11['skey'].isin(index['skey'].unique())]\n",
    "    re = pd.merge(index, index11, on=cols, how='outer')\n",
    "    try:\n",
    "        assert(re[re['date'].isnull()]['cum_volume'].unique() == [0])\n",
    "    except:\n",
    "        print('Attention here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! api data have more ticks in SH index')\n",
    "        print(re[(re['date'].isnull()) & (re['cum_volume'] > 0)])\n",
    "        print(index11[index11['sequenceNo'].isin(re[(re['date'].isnull()) & (re['cum_volume'] > 0)]['sequenceNo'].unique())])\n",
    "        index11 = index11[~index11['sequenceNo'].isin(re[(re['date'].isnull()) & (re['cum_volume'] > 0)]['sequenceNo'].unique())]\n",
    "    assert(re[re['sequenceNo'].isnull()].shape[0] == 0)\n",
    "    index11 = index11[index11['cum_volume'] > 0]\n",
    "    re = pd.concat([index11, index])\n",
    "    re = re.sort_values(by=['skey', 'time'])\n",
    "    re['sequenceNo'] = re.groupby('skey')['sequenceNo'].ffill()\n",
    "    re['clockAtArrival'] = re.groupby('skey')['clockAtArrival'].ffill()\n",
    "    re['count'] = re.groupby(['skey', 'sequenceNo']).cumcount()\n",
    "    re['sequenceNo'] = re['sequenceNo'].fillna(-1)\n",
    "    re.loc[re['count'] > 1, 'sequenceNo'] = -1\n",
    "    re.loc[re['count'] > 1, 'clockAtArrival'] = np.nan\n",
    "    ree5 = re[~re['date'].isnull()]\n",
    "    assert(ree5.shape[0] == index.shape[0])\n",
    "    ree5['nan'] = 0\n",
    "    ree5 = ree5[['skey', 'date', 'num', 'sequenceNo', 'clockAtArrival', 'nan']]\n",
    "    print('zs_96 finished')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('----------------------------------------------------------------------------------------------------')\n",
    "    print('final concat zs96')\n",
    "    try:\n",
    "        assert(len(set(SZ1['sequenceNo']) & set(SH1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SZ1[SZ1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(SH1['sequenceNo'])))])\n",
    "        display(SH1[SH1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(SH1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SZ1['sequenceNo']) & set(trade1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SZ1[SZ1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(trade1['sequenceNo'])))])\n",
    "        display(trade1[trade1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(trade1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SZ1['sequenceNo']) & set(order1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SZ1[SZ1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "        display(order1[order1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SZ1['sequenceNo']) & set(index1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SZ1[SZ1['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(index11['sequenceNo'])))])\n",
    "        display(index11[index11['sequenceNo'].isin(list(set(SZ1['sequenceNo']) & set(index11['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SH1['sequenceNo']) & set(index1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SH1[SH1['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(index11['sequenceNo'])))])\n",
    "        display(index11[index11['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(index11['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SH1['sequenceNo']) & set(trade1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SH1[SH1['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(trade1['sequenceNo'])))])\n",
    "        display(trade1[trade1['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(trade1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(SH1['sequenceNo']) & set(order1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(SH1[SH1['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "        display(order1[order1['sequenceNo'].isin(list(set(SH1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(trade1['sequenceNo']) & set(order1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(trade1[trade1['sequenceNo'].isin(list(set(trade1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "        display(order1[order1['sequenceNo'].isin(list(set(trade1['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(trade1['sequenceNo']) & set(index1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(trade1[trade1['sequenceNo'].isin(list(set(trade1['sequenceNo']) & set(index11['sequenceNo'])))])\n",
    "        display(index11[index11['sequenceNo'].isin(list(set(trade1['sequenceNo']) & set(index11['sequenceNo'])))])\n",
    "    try:\n",
    "        assert(len(set(index11['sequenceNo']) & set(order1['sequenceNo'])) == 0)\n",
    "    except:\n",
    "        display(index11[index11['sequenceNo'].isin(list(set(index11['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "        display(order1[order1['sequenceNo'].isin(list(set(index11['sequenceNo']) & set(order1['sequenceNo'])))])\n",
    "        \n",
    "    \n",
    "\n",
    "    del SH\n",
    "    del SH1\n",
    "    del SZ\n",
    "    del SZ1\n",
    "    del trade\n",
    "    del trade1\n",
    "    del order\n",
    "    del order1\n",
    "    del index\n",
    "    del index1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ree1['tag'] = 'SH'\n",
    "    ree2['tag'] = 'SZ'\n",
    "    ree3['tag'] = 'trade'\n",
    "    ree4['tag'] = 'order'\n",
    "    ree5['tag'] = 'index'\n",
    "    re1['tag'] = 'SH'\n",
    "    re2['tag'] = 'SZ'\n",
    "    re3['tag'] = 'trade'\n",
    "    re4['tag'] = 'order'\n",
    "    re5['tag'] = 'index'\n",
    "\n",
    "    fr1 = []\n",
    "    fr2 = []\n",
    "    fr1 += [ree1]\n",
    "    fr2 += [re1]\n",
    "    del ree1\n",
    "    del re1\n",
    "    display('1. here~')\n",
    "    fr1 += [ree2]\n",
    "    fr2 += [re2]\n",
    "    del ree2\n",
    "    del re2\n",
    "    display('2. here~')\n",
    "    fr1 += [ree3]\n",
    "    fr2 += [re3]\n",
    "    del ree3\n",
    "    del re3\n",
    "    display('3. here~')\n",
    "    fr1 += [ree4]\n",
    "    fr2 += [re4]\n",
    "    del ree4\n",
    "    del re4\n",
    "    display('4. here~')\n",
    "    fr1 += [ree5]\n",
    "    fr2 += [re5]\n",
    "    del ree5\n",
    "    del re5\n",
    "    display('5. here~')\n",
    "    fr1 = pd.concat(fr1).reset_index(drop=True)\n",
    "    fr1 = fr1.sort_values(by=['sequenceNo', 'num'])\n",
    "    fr1['sum_nan'] = fr1['nan'].cumsum()\n",
    "    fr1['sequenceNo'] = np.where(fr1['sequenceNo'] != -1, fr1['sequenceNo'] + fr1['sum_nan'], fr1['sequenceNo'])\n",
    "    \n",
    "    fr2 = pd.concat(fr2).reset_index(drop=True)\n",
    "    fr2 = fr2.sort_values(by=['sequenceNo', 'num'])\n",
    "    fr2['sum_nan'] = fr2['nan'].cumsum()\n",
    "    fr2['sequenceNo'] = np.where(fr2['sequenceNo'] != -1, fr2['sequenceNo'] + fr2['sum_nan'] + fr2['count'], fr2['sequenceNo'])\n",
    "\n",
    "    assert(fr1[fr1['sequenceNo'] != -1][fr1[fr1['sequenceNo'] != -1].duplicated('sequenceNo', keep=False)].shape[0] == 0)\n",
    "    assert(fr2[fr2['sequenceNo'] != -1][fr2[fr2['sequenceNo'] != -1].duplicated('sequenceNo', keep=False)].shape[0] == 0)\n",
    "    assert(sum(~fr1[fr1['sequenceNo'] == -1]['clockAtArrival'].isnull()) == 0)\n",
    "    assert(sum(~fr2[fr2['sequenceNo'] == -1]['clockAtArrival'].isnull()) == 0)\n",
    "    \n",
    "    \n",
    "    import pickle\n",
    "    os.mkdir('/mnt/e/result/' + startDate)\n",
    "    SH = fr1[fr1['tag'] == 'SH'][[\"skey\", \"date\", \"num\", 'sequenceNo', \"clockAtArrival\"]]\n",
    "    SH = SH.rename(columns={'sequenceNo':'sequenceNo_96', 'clockAtArrival':\"clockAtArrival_96\"})\n",
    "    SH1 = fr2[fr2['tag'] == 'SH'][[\"skey\", \"date\", \"num\", 'sequenceNo', \"clockAtArrival\"]]\n",
    "    SH1 = SH1.rename(columns={'sequenceNo':'sequenceNo_88', 'clockAtArrival':\"clockAtArrival_88\"})\n",
    "    SH = pd.merge(SH, SH1, on=['skey', 'date', 'num'])\n",
    "    assert(SH.shape[0] == SH1.shape[0])\n",
    "    SH.to_pickle('/mnt/e/result/' + startDate + '/SH.pkl')\n",
    "    del SH\n",
    "\n",
    "    SZ = fr1[fr1['tag'] == 'SZ'][[\"skey\", \"date\", \"num\", 'sequenceNo', \"clockAtArrival\"]]\n",
    "    SZ = SZ.rename(columns={'sequenceNo':'sequenceNo_96', 'clockAtArrival':\"clockAtArrival_96\"})\n",
    "    SZ1 = fr2[fr2['tag'] == 'SZ'][[\"skey\", \"date\", \"num\", 'sequenceNo', \"clockAtArrival\"]]\n",
    "    SZ1 = SZ1.rename(columns={'sequenceNo':'sequenceNo_88', 'clockAtArrival':\"clockAtArrival_88\"})\n",
    "    SZ = pd.merge(SZ, SZ1, on=['skey', 'date', 'num'])\n",
    "    assert(SZ.shape[0] == SZ1.shape[0])\n",
    "    SZ.to_pickle('/mnt/e/result/' + startDate + '/SZ.pkl')\n",
    "    del SZ\n",
    "    \n",
    "    trade = fr1[fr1['tag'] == 'trade'][[\"skey\", \"date\", \"ApplSeqNum\", 'sequenceNo', \"clockAtArrival\"]]\n",
    "    trade = trade.rename(columns={'sequenceNo':'sequenceNo_96', 'clockAtArrival':\"clockAtArrival_96\"})\n",
    "    trade1 = fr2[fr2['tag'] == 'trade'][[\"skey\", \"date\", \"ApplSeqNum\", 'sequenceNo', \"clockAtArrival\"]]\n",
    "    trade1 = trade1.rename(columns={'sequenceNo':'sequenceNo_88', 'clockAtArrival':\"clockAtArrival_88\"})\n",
    "    trade = pd.merge(trade, trade1, on=[\"skey\", \"date\", \"ApplSeqNum\"])\n",
    "    assert(trade.shape[0] == trade1.shape[0])\n",
    "    trade.to_pickle('/mnt/e/result/' + startDate + '/trade.pkl')\n",
    "    del trade\n",
    "    \n",
    "    \n",
    "    order = fr1[fr1['tag'] == 'order'][[\"skey\", \"date\", \"ApplSeqNum\", 'sequenceNo', \"clockAtArrival\"]]\n",
    "    order = order.rename(columns={'sequenceNo':'sequenceNo_96', 'clockAtArrival':\"clockAtArrival_96\"})\n",
    "    order1 = fr2[fr2['tag'] == 'order'][[\"skey\", \"date\", \"ApplSeqNum\", 'sequenceNo', \"clockAtArrival\"]]\n",
    "    order1 = order1.rename(columns={'sequenceNo':'sequenceNo_88', 'clockAtArrival':\"clockAtArrival_88\"})\n",
    "    order = pd.merge(order, order1, on=[\"skey\", \"date\", \"ApplSeqNum\"])\n",
    "    assert(order.shape[0] == order1.shape[0])\n",
    "    order.to_pickle('/mnt/e/result/' + startDate + '/order.pkl')\n",
    "    del order\n",
    "    \n",
    "    index = fr1[fr1['tag'] == 'index'][[\"skey\", \"date\", \"num\", 'sequenceNo', \"clockAtArrival\"]]\n",
    "    index = index.rename(columns={'sequenceNo':'sequenceNo_96', 'clockAtArrival':\"clockAtArrival_96\"})\n",
    "    index1 = fr2[fr2['tag'] == 'index'][[\"skey\", \"date\", \"num\", 'sequenceNo', \"clockAtArrival\"]]\n",
    "    index1 = index1.rename(columns={'sequenceNo':'sequenceNo_88', 'clockAtArrival':\"clockAtArrival_88\"})\n",
    "    index = pd.merge(index, index1, on=[\"skey\", \"date\", \"num\"])\n",
    "    assert(index.shape[0] == index1.shape[0])\n",
    "    index.to_pickle('/mnt/e/result/' + startDate + '/index.pkl')\n",
    "    del index\n",
    "    del fr2\n",
    "    del fr1\n",
    "    \n",
    "    print(str(i) + ' finished')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>date</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>sequenceNo</th>\n",
       "      <th>clockAtArrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [skey, date, ApplSeqNum, sequenceNo, clockAtArrival]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re3[(re3['skey'] == 1600000) & (re3['sequenceNo'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68874433"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68874432"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1601702, 1605003, 1688095], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re[re['clockAtArrival'].isnull()]['skey'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clockAtArrival</th>\n",
       "      <th>sequenceNo</th>\n",
       "      <th>exchId</th>\n",
       "      <th>securityType</th>\n",
       "      <th>__isRepeated</th>\n",
       "      <th>TransactTime</th>\n",
       "      <th>ChannelNo</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>SecurityID</th>\n",
       "      <th>secid</th>\n",
       "      <th>mdSource</th>\n",
       "      <th>ExecType</th>\n",
       "      <th>TradeBSFlag</th>\n",
       "      <th>__origTickSeq</th>\n",
       "      <th>TradePrice</th>\n",
       "      <th>TradeQty</th>\n",
       "      <th>TradeMoney</th>\n",
       "      <th>BidApplSeqNum</th>\n",
       "      <th>OfferApplSeqNum</th>\n",
       "      <th>skey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>1599528315255486</td>\n",
       "      <td>3345407</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92500000</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>688012</td>\n",
       "      <td>1688012</td>\n",
       "      <td>13</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>-1</td>\n",
       "      <td>1638000</td>\n",
       "      <td>300</td>\n",
       "      <td>491400000</td>\n",
       "      <td>147264</td>\n",
       "      <td>148633</td>\n",
       "      <td>1688012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68845317</th>\n",
       "      <td>1599549079728565</td>\n",
       "      <td>271026861</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>151104470</td>\n",
       "      <td>103</td>\n",
       "      <td>58</td>\n",
       "      <td>688012</td>\n",
       "      <td>1688012</td>\n",
       "      <td>13</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>-1</td>\n",
       "      <td>1617600</td>\n",
       "      <td>200</td>\n",
       "      <td>323520000</td>\n",
       "      <td>113</td>\n",
       "      <td>284</td>\n",
       "      <td>1688012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            clockAtArrival  sequenceNo  exchId  securityType  __isRepeated  \\\n",
       "40452     1599528315255486     3345407       1             1             0   \n",
       "68845317  1599549079728565   271026861       1             1             0   \n",
       "\n",
       "          TransactTime  ChannelNo  ApplSeqNum  SecurityID    secid  mdSource  \\\n",
       "40452         92500000          6          58      688012  1688012        13   \n",
       "68845317     151104470        103          58      688012  1688012        13   \n",
       "\n",
       "         ExecType TradeBSFlag  __origTickSeq  TradePrice  TradeQty  \\\n",
       "40452           F           N             -1     1638000       300   \n",
       "68845317        F           S             -1     1617600       200   \n",
       "\n",
       "          TradeMoney  BidApplSeqNum  OfferApplSeqNum     skey  \n",
       "40452      491400000         147264           148633  1688012  \n",
       "68845317   323520000            113              284  1688012  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade1[trade1.duplicated(['skey', 'ApplSeqNum'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1688002"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade1[trade1['ChannelNo'] == 103]['skey'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChannelNo\n",
       "1        3103361\n",
       "2        3191336\n",
       "3        3479197\n",
       "4        1986083\n",
       "5        3607769\n",
       "6        3219022\n",
       "103          120\n",
       "2011    12691691\n",
       "2012    12955625\n",
       "2013    12525553\n",
       "2014    12085628\n",
       "Name: secid, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade1['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade[trade.duplicated(['skey', 'ApplSeqNum'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skey</th>\n",
       "      <th>date</th>\n",
       "      <th>ApplSeqNum</th>\n",
       "      <th>sequenceNo</th>\n",
       "      <th>clockAtArrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600000</td>\n",
       "      <td>20200908</td>\n",
       "      <td>1449</td>\n",
       "      <td>3644786.0</td>\n",
       "      <td>1.599528e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600000</td>\n",
       "      <td>20200908</td>\n",
       "      <td>1450</td>\n",
       "      <td>3644787.0</td>\n",
       "      <td>1.599528e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1600000</td>\n",
       "      <td>20200908</td>\n",
       "      <td>1451</td>\n",
       "      <td>3644788.0</td>\n",
       "      <td>1.599528e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600000</td>\n",
       "      <td>20200908</td>\n",
       "      <td>1452</td>\n",
       "      <td>3644789.0</td>\n",
       "      <td>1.599528e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1600000</td>\n",
       "      <td>20200908</td>\n",
       "      <td>1453</td>\n",
       "      <td>3644790.0</td>\n",
       "      <td>1.599528e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      skey      date  ApplSeqNum  sequenceNo  clockAtArrival\n",
       "0  1600000  20200908        1449   3644786.0    1.599528e+15\n",
       "1  1600000  20200908        1450   3644787.0    1.599528e+15\n",
       "2  1600000  20200908        1451   3644788.0    1.599528e+15\n",
       "3  1600000  20200908        1452   3644789.0    1.599528e+15\n",
       "4  1600000  20200908        1453   3644790.0    1.599528e+15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = 20200901\n",
    "endDate = 20200918\n",
    "database_name = 'com_md_eq_cn'\n",
    "user = \"zhenyuy\"\n",
    "password = \"bnONBrzSMGoE\"\n",
    "\n",
    "print('start to add four columns in database')\n",
    "dl = db.read('md_index', start_date = startDate, end_date = endDate, 1000300)['date'].unique()\n",
    "for d in dl:\n",
    "    SH = db.read('md_snapshot_l2', start_date=str(d), end_date=str(d))\n",
    "    SZ = SH[SH['skey'] > 2000000]\n",
    "    SH = SH[SH['skey'] < 2000000]\n",
    "    SH['num'] = SH['skey'] * 10000 + SH['ordering']\n",
    "    SZ['num'] = SZ['skey'] * 10000 + SZ['ordering']\n",
    "\n",
    "    SH1 = pd.read_pickle('/mnt/e/result/' + str(d) + '/SH.pkl')\n",
    "\n",
    "    assert(SH.shape[0] == SH1.shape[0])\n",
    "\n",
    "    SH = pd.merge(SH, SH1, on=['skey', 'date', 'num'], how='outer')\n",
    "    assert(SH[SH['sequenceNo_88'].isnull()].shape[0] == 0)\n",
    "    assert(SH[SH['time'].isnull()].shape[0] == 0)\n",
    "    SH.drop(['num'],axis=1,inplace=True)\n",
    "    SH = SH.sort_values(by=['skey', 'ordering'])\n",
    "    \n",
    "    db.write('md_snapshot_l2', SH)\n",
    "    print('finish write snapshot SH data')\n",
    "    \n",
    "    \n",
    "    SZ1 = pd.read_pickle('/mnt/e/result/' + str(d) + '/SZ.pkl')\n",
    "\n",
    "    assert(SZ.shape[0] == SZ1.shape[0])\n",
    "\n",
    "    SZ = pd.merge(SZ, SZ1, on=['skey', 'date', 'num'], how='outer')\n",
    "    assert(SZ[SZ['sequenceNo_88'].isnull()].shape[0] == 0)\n",
    "    assert(SZ[SZ['time'].isnull()].shape[0] == 0)\n",
    "    SZ.drop(['num'],axis=1,inplace=True)\n",
    "    SZ = SZ.sort_values(by=['skey', 'ordering'])\n",
    "\n",
    "    db.write('md_snapshot_l2', SZ)\n",
    "    print('finish write snapshot SZ data')\n",
    "    \n",
    "    \n",
    "    trade = db.read('md_trade', start_date=str(d), end_date=str(d))\n",
    "\n",
    "    trade1 = pd.read_pickle('/mnt/e/result/' + str(d) + '/trade.pkl')\n",
    "\n",
    "    assert(trade.shape[0] == trade1.shape[0])\n",
    "\n",
    "    trade = pd.merge(trade, trade1, on=[\"skey\", \"date\", \"ApplSeqNum\"], how='outer')\n",
    "    assert(trade[trade['sequenceNo_88'].isnull()].shape[0] == 0)\n",
    "    assert(trade[trade['time'].isnull()].shape[0] == 0)\n",
    "    trade = trade.sort_values(by=['skey', 'ApplSeqNum'])\n",
    "\n",
    "    db.write('md_trade', trade)\n",
    "    print('finish write trade data')\n",
    "    \n",
    "    \n",
    "    \n",
    "    order = db.read('md_order', start_date=str(d), end_date=str(d))\n",
    "\n",
    "    order1 = pd.read_pickle('/mnt/e/result/' + str(d) + '/order.pkl')\n",
    "\n",
    "    assert(order.shape[0] == order1.shape[0])\n",
    "    order = pd.merge(order, order1, on=[\"skey\", \"date\", \"ApplSeqNum\"], how='outer')\n",
    "    assert(order[order['sequenceNo_88'].isnull()].shape[0] == 0)\n",
    "    assert(order[order['time'].isnull()].shape[0] == 0)\n",
    "    order = order.sort_values(by=['skey', 'ApplSeqNum'])\n",
    "\n",
    "    db.write('md_order', order)\n",
    "    print('finish write order data')\n",
    "    \n",
    "    \n",
    "    index = db.read('md_index', start_date=str(d), end_date=str(d))\n",
    "    index['num'] = index['skey'] * 10000 + index['ordering']\n",
    "\n",
    "    index1 = pd.read_pickle('/mnt/e/result/' + str(d) + '/index.pkl')\n",
    "\n",
    "    assert(index.shape[0] == index1.shape[0])\n",
    "    index = pd.merge(index, index1, on=['skey', 'date', 'num'], how='outer')\n",
    "    assert(index[index['sequenceNo_88'].isnull()].shape[0] == 0)\n",
    "    assert(index[index['time'].isnull()].shape[0] == 0)\n",
    "    index.drop(['num'],axis=1,inplace=True)\n",
    "    index = index.sort_values(by=['skey', 'ordering'])\n",
    "\n",
    "    db.write('md_index', index)\n",
    "    print('finish write index data')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
